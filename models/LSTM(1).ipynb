{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcKyre3FQlRK"
      },
      "source": [
        "<h2>LSTM</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8QeJyKegoAw",
        "outputId": "bbb2636a-2b7e-4343-9e58-5b248bea83c7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-26 23:36:14.011239: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-04-26 23:36:14.087127: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-04-26 23:36:14.088484: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-26 23:36:15.558148: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import json\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout, Embedding\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load intents\n",
        "data_file = open('intents.json').read()\n",
        "intents = json.loads(data_file)\n",
        "\n",
        "# Extract text and labels from intents\n",
        "texts = []\n",
        "labels = []\n",
        "\n",
        "for intent in intents['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        texts.append(pattern)\n",
        "        labels.append(intent['tag'])\n",
        "\n",
        "# Tokenize the text data\n",
        "max_words = 1000\n",
        "tokenizer = Tokenizer(num_words=max_words, lower=True, split=\" \")\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# Pad sequences\n",
        "max_sequence_length = max([len(seq) for seq in sequences])\n",
        "data = pad_sequences(sequences, maxlen=max_sequence_length)\n",
        "\n",
        "# Load testing intents\n",
        "data_file_test = open('intents_testing.json').read()\n",
        "intents_test = json.loads(data_file_test)\n",
        "\n",
        "# Extract text and labels from testing intents\n",
        "texts_test = []\n",
        "labels_test = []\n",
        "\n",
        "for intent in intents_test['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        texts_test.append(pattern)\n",
        "        labels_test.append(intent['tag'])\n",
        "\n",
        "# Tokenize and pad the testing text data\n",
        "sequences_test = tokenizer.texts_to_sequences(texts_test)\n",
        "data_test = pad_sequences(sequences_test, maxlen=max_sequence_length)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rtOfQRtihQdo"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-26 23:37:51.588854: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-04-26 23:37:51.591739: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-04-26 23:37:51.594928: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-26 23:37:51.966262: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-04-26 23:37:51.969971: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-04-26 23:37:51.973237: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "/home/student/.local/lib/python3.10/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n",
            "2023-04-26 23:37:52.510119: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-04-26 23:37:52.513794: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-04-26 23:37:52.515947: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-04-26 23:37:52.819015: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-04-26 23:37:52.821249: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-04-26 23:37:52.824317: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-04-26 23:37:53.919129: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-04-26 23:37:53.921278: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-04-26 23:37:53.923573: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-04-26 23:37:54.357360: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-04-26 23:37:54.361242: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-04-26 23:37:54.363190: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "109/109 [==============================] - ETA: 0s - loss: 3.8476 - accuracy: 0.0722"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-26 23:38:00.899568: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-04-26 23:38:00.903721: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-04-26 23:38:00.905573: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-04-26 23:38:01.195390: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-04-26 23:38:01.197431: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-04-26 23:38:01.199305: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "109/109 [==============================] - 10s 53ms/step - loss: 3.8476 - accuracy: 0.0722 - val_loss: 3.8694 - val_accuracy: 0.0263\n",
            "Epoch 2/100\n",
            "109/109 [==============================] - 4s 40ms/step - loss: 3.5864 - accuracy: 0.1055 - val_loss: 3.7339 - val_accuracy: 0.0395\n",
            "Epoch 3/100\n",
            "109/109 [==============================] - 4s 41ms/step - loss: 3.3435 - accuracy: 0.1158 - val_loss: 3.6626 - val_accuracy: 0.0789\n",
            "Epoch 4/100\n",
            "109/109 [==============================] - 4s 41ms/step - loss: 3.1872 - accuracy: 0.1548 - val_loss: 3.5346 - val_accuracy: 0.0658\n",
            "Epoch 5/100\n",
            "109/109 [==============================] - 4s 40ms/step - loss: 3.0115 - accuracy: 0.2030 - val_loss: 3.4317 - val_accuracy: 0.0921\n",
            "Epoch 6/100\n",
            "109/109 [==============================] - 5s 42ms/step - loss: 2.8336 - accuracy: 0.2557 - val_loss: 3.3654 - val_accuracy: 0.1053\n",
            "Epoch 7/100\n",
            "109/109 [==============================] - 5s 41ms/step - loss: 2.6522 - accuracy: 0.2970 - val_loss: 3.2847 - val_accuracy: 0.1579\n",
            "Epoch 8/100\n",
            "109/109 [==============================] - 4s 41ms/step - loss: 2.4900 - accuracy: 0.3475 - val_loss: 3.2284 - val_accuracy: 0.1184\n",
            "Epoch 9/100\n",
            "109/109 [==============================] - 5s 46ms/step - loss: 2.3765 - accuracy: 0.3842 - val_loss: 3.1856 - val_accuracy: 0.1447\n",
            "Epoch 10/100\n",
            "109/109 [==============================] - 5s 42ms/step - loss: 2.2418 - accuracy: 0.4266 - val_loss: 3.0832 - val_accuracy: 0.2105\n",
            "Epoch 11/100\n",
            "109/109 [==============================] - 4s 41ms/step - loss: 2.0820 - accuracy: 0.4507 - val_loss: 3.0345 - val_accuracy: 0.1974\n",
            "Epoch 12/100\n",
            "109/109 [==============================] - 5s 42ms/step - loss: 2.0260 - accuracy: 0.4679 - val_loss: 2.9263 - val_accuracy: 0.2237\n",
            "Epoch 13/100\n",
            "109/109 [==============================] - 4s 41ms/step - loss: 1.8681 - accuracy: 0.5172 - val_loss: 2.8083 - val_accuracy: 0.2368\n",
            "Epoch 14/100\n",
            "109/109 [==============================] - 5s 41ms/step - loss: 1.7874 - accuracy: 0.5550 - val_loss: 2.7851 - val_accuracy: 0.2895\n",
            "Epoch 15/100\n",
            "109/109 [==============================] - 5s 43ms/step - loss: 1.6957 - accuracy: 0.5677 - val_loss: 2.7594 - val_accuracy: 0.2763\n",
            "Epoch 16/100\n",
            "109/109 [==============================] - 4s 41ms/step - loss: 1.6259 - accuracy: 0.5929 - val_loss: 2.6943 - val_accuracy: 0.3158\n",
            "Epoch 17/100\n",
            "109/109 [==============================] - 4s 41ms/step - loss: 1.5568 - accuracy: 0.6193 - val_loss: 2.6264 - val_accuracy: 0.3158\n",
            "Epoch 18/100\n",
            "109/109 [==============================] - 4s 41ms/step - loss: 1.5270 - accuracy: 0.6319 - val_loss: 2.7013 - val_accuracy: 0.3421\n",
            "Epoch 19/100\n",
            "109/109 [==============================] - 4s 41ms/step - loss: 1.4656 - accuracy: 0.6422 - val_loss: 2.5803 - val_accuracy: 0.3421\n",
            "Epoch 20/100\n",
            "109/109 [==============================] - 5s 41ms/step - loss: 1.4257 - accuracy: 0.6846 - val_loss: 2.5546 - val_accuracy: 0.3421\n",
            "Epoch 21/100\n",
            "109/109 [==============================] - 5s 41ms/step - loss: 1.3729 - accuracy: 0.7018 - val_loss: 2.5398 - val_accuracy: 0.3816\n",
            "Epoch 22/100\n",
            "109/109 [==============================] - 5s 41ms/step - loss: 1.3066 - accuracy: 0.7282 - val_loss: 2.4922 - val_accuracy: 0.3684\n",
            "Epoch 23/100\n",
            "109/109 [==============================] - 4s 41ms/step - loss: 1.2503 - accuracy: 0.7362 - val_loss: 2.4060 - val_accuracy: 0.4079\n",
            "Epoch 24/100\n",
            "109/109 [==============================] - 4s 41ms/step - loss: 1.2184 - accuracy: 0.7443 - val_loss: 2.4248 - val_accuracy: 0.4342\n",
            "Epoch 25/100\n",
            "109/109 [==============================] - 4s 41ms/step - loss: 1.2044 - accuracy: 0.7420 - val_loss: 2.4186 - val_accuracy: 0.4079\n",
            "Epoch 26/100\n",
            "109/109 [==============================] - 4s 41ms/step - loss: 1.0974 - accuracy: 0.7936 - val_loss: 2.3887 - val_accuracy: 0.5000\n",
            "Epoch 27/100\n",
            "109/109 [==============================] - 5s 47ms/step - loss: 1.0776 - accuracy: 0.7890 - val_loss: 2.4202 - val_accuracy: 0.4474\n",
            "Epoch 28/100\n",
            "109/109 [==============================] - 6s 55ms/step - loss: 1.1030 - accuracy: 0.7821 - val_loss: 2.4671 - val_accuracy: 0.4211\n",
            "Epoch 29/100\n",
            "109/109 [==============================] - 5s 50ms/step - loss: 1.0622 - accuracy: 0.8096 - val_loss: 2.3250 - val_accuracy: 0.4474\n",
            "Epoch 30/100\n",
            "109/109 [==============================] - 4s 41ms/step - loss: 1.0287 - accuracy: 0.8039 - val_loss: 2.1877 - val_accuracy: 0.5263\n",
            "Epoch 31/100\n",
            "109/109 [==============================] - 5s 42ms/step - loss: 1.0558 - accuracy: 0.7993 - val_loss: 2.5003 - val_accuracy: 0.4079\n",
            "Epoch 32/100\n",
            "109/109 [==============================] - 5s 47ms/step - loss: 1.0125 - accuracy: 0.8222 - val_loss: 2.2439 - val_accuracy: 0.5000\n",
            "Epoch 33/100\n",
            "109/109 [==============================] - 5s 49ms/step - loss: 0.9413 - accuracy: 0.8326 - val_loss: 2.2879 - val_accuracy: 0.4342\n",
            "Epoch 34/100\n",
            "109/109 [==============================] - 5s 48ms/step - loss: 0.9160 - accuracy: 0.8440 - val_loss: 2.2503 - val_accuracy: 0.4737\n",
            "Epoch 35/100\n",
            "109/109 [==============================] - 7s 63ms/step - loss: 0.9176 - accuracy: 0.8383 - val_loss: 2.1960 - val_accuracy: 0.4868\n",
            "Epoch 36/100\n",
            "109/109 [==============================] - 7s 62ms/step - loss: 0.8992 - accuracy: 0.8498 - val_loss: 2.2373 - val_accuracy: 0.5000\n",
            "Epoch 37/100\n",
            "109/109 [==============================] - 7s 67ms/step - loss: 0.8753 - accuracy: 0.8440 - val_loss: 2.1486 - val_accuracy: 0.5000\n",
            "Epoch 38/100\n",
            "109/109 [==============================] - 7s 63ms/step - loss: 0.8812 - accuracy: 0.8521 - val_loss: 2.3382 - val_accuracy: 0.4737\n",
            "Epoch 39/100\n",
            "109/109 [==============================] - 6s 60ms/step - loss: 0.8758 - accuracy: 0.8589 - val_loss: 2.1441 - val_accuracy: 0.5132\n",
            "Epoch 40/100\n",
            "109/109 [==============================] - 5s 44ms/step - loss: 0.8522 - accuracy: 0.8589 - val_loss: 2.1942 - val_accuracy: 0.5263\n",
            "Epoch 41/100\n",
            "109/109 [==============================] - 4s 40ms/step - loss: 0.8253 - accuracy: 0.8819 - val_loss: 2.1805 - val_accuracy: 0.4868\n",
            "Epoch 42/100\n",
            "109/109 [==============================] - 4s 40ms/step - loss: 0.7697 - accuracy: 0.8899 - val_loss: 2.1375 - val_accuracy: 0.5395\n",
            "Epoch 43/100\n",
            "109/109 [==============================] - 5s 47ms/step - loss: 0.8094 - accuracy: 0.8589 - val_loss: 2.1559 - val_accuracy: 0.5263\n",
            "Epoch 44/100\n",
            "109/109 [==============================] - 5s 44ms/step - loss: 0.8250 - accuracy: 0.8704 - val_loss: 2.1973 - val_accuracy: 0.5263\n",
            "Epoch 45/100\n",
            "109/109 [==============================] - 5s 46ms/step - loss: 0.7869 - accuracy: 0.8670 - val_loss: 2.0970 - val_accuracy: 0.5263\n",
            "Epoch 46/100\n",
            "109/109 [==============================] - 5s 50ms/step - loss: 0.7647 - accuracy: 0.8807 - val_loss: 2.1940 - val_accuracy: 0.5263\n",
            "Epoch 47/100\n",
            "109/109 [==============================] - 5s 48ms/step - loss: 0.7273 - accuracy: 0.8933 - val_loss: 2.1358 - val_accuracy: 0.5526\n",
            "Epoch 48/100\n",
            "109/109 [==============================] - 5s 45ms/step - loss: 0.7504 - accuracy: 0.8807 - val_loss: 2.2508 - val_accuracy: 0.5395\n",
            "Epoch 49/100\n",
            "109/109 [==============================] - 4s 41ms/step - loss: 0.7373 - accuracy: 0.8911 - val_loss: 2.2069 - val_accuracy: 0.5000\n",
            "Epoch 50/100\n",
            "109/109 [==============================] - 5s 46ms/step - loss: 0.7220 - accuracy: 0.8888 - val_loss: 2.1553 - val_accuracy: 0.5658\n",
            "Epoch 51/100\n",
            "109/109 [==============================] - 5s 42ms/step - loss: 0.7241 - accuracy: 0.9002 - val_loss: 2.1196 - val_accuracy: 0.5132\n",
            "Epoch 52/100\n",
            "109/109 [==============================] - 4s 41ms/step - loss: 0.6854 - accuracy: 0.8968 - val_loss: 2.1355 - val_accuracy: 0.5526\n",
            "Epoch 53/100\n",
            "109/109 [==============================] - 5s 46ms/step - loss: 0.7106 - accuracy: 0.8933 - val_loss: 2.0980 - val_accuracy: 0.5658\n",
            "Epoch 54/100\n",
            "109/109 [==============================] - 5s 44ms/step - loss: 0.6919 - accuracy: 0.9037 - val_loss: 2.0934 - val_accuracy: 0.5789\n",
            "Epoch 55/100\n",
            "109/109 [==============================] - 5s 44ms/step - loss: 0.6968 - accuracy: 0.8945 - val_loss: 2.0784 - val_accuracy: 0.5132\n",
            "Epoch 56/100\n",
            "109/109 [==============================] - 5s 43ms/step - loss: 0.6716 - accuracy: 0.8933 - val_loss: 2.0357 - val_accuracy: 0.5658\n",
            "Epoch 57/100\n",
            "109/109 [==============================] - 5s 44ms/step - loss: 0.6811 - accuracy: 0.9037 - val_loss: 2.0003 - val_accuracy: 0.5395\n",
            "Epoch 58/100\n",
            "109/109 [==============================] - 5s 45ms/step - loss: 0.6670 - accuracy: 0.8991 - val_loss: 2.2245 - val_accuracy: 0.5658\n",
            "Epoch 59/100\n",
            "109/109 [==============================] - 5s 50ms/step - loss: 0.7281 - accuracy: 0.8842 - val_loss: 2.0947 - val_accuracy: 0.5132\n",
            "Epoch 60/100\n",
            "109/109 [==============================] - 5s 43ms/step - loss: 0.6757 - accuracy: 0.9025 - val_loss: 2.0715 - val_accuracy: 0.5526\n",
            "Epoch 61/100\n",
            "109/109 [==============================] - 5s 44ms/step - loss: 0.6820 - accuracy: 0.8945 - val_loss: 2.1361 - val_accuracy: 0.5526\n",
            "Epoch 62/100\n",
            "109/109 [==============================] - 5s 43ms/step - loss: 0.6996 - accuracy: 0.9025 - val_loss: 2.0163 - val_accuracy: 0.5526\n",
            "Epoch 63/100\n",
            "109/109 [==============================] - 5s 43ms/step - loss: 0.6546 - accuracy: 0.9117 - val_loss: 2.0669 - val_accuracy: 0.5789\n",
            "Epoch 64/100\n",
            "109/109 [==============================] - 5s 46ms/step - loss: 0.6329 - accuracy: 0.9186 - val_loss: 2.0471 - val_accuracy: 0.5526\n",
            "Epoch 65/100\n",
            "109/109 [==============================] - 6s 52ms/step - loss: 0.6562 - accuracy: 0.9048 - val_loss: 2.2014 - val_accuracy: 0.5658\n",
            "Epoch 66/100\n",
            "109/109 [==============================] - 6s 58ms/step - loss: 0.6200 - accuracy: 0.9163 - val_loss: 2.0258 - val_accuracy: 0.6053\n",
            "Epoch 67/100\n",
            "109/109 [==============================] - 7s 62ms/step - loss: 0.6021 - accuracy: 0.9128 - val_loss: 2.0705 - val_accuracy: 0.5526\n",
            "Epoch 68/100\n",
            "109/109 [==============================] - 5s 47ms/step - loss: 0.6133 - accuracy: 0.9094 - val_loss: 2.1241 - val_accuracy: 0.5526\n",
            "Epoch 69/100\n",
            "109/109 [==============================] - 5s 45ms/step - loss: 0.6136 - accuracy: 0.9106 - val_loss: 2.1361 - val_accuracy: 0.5395\n",
            "Epoch 70/100\n",
            "109/109 [==============================] - 5s 42ms/step - loss: 0.6092 - accuracy: 0.9128 - val_loss: 1.9864 - val_accuracy: 0.5789\n",
            "Epoch 71/100\n",
            "109/109 [==============================] - 5s 43ms/step - loss: 0.6000 - accuracy: 0.9232 - val_loss: 2.0927 - val_accuracy: 0.5921\n",
            "Epoch 72/100\n",
            "109/109 [==============================] - 5s 42ms/step - loss: 0.6194 - accuracy: 0.9128 - val_loss: 2.0586 - val_accuracy: 0.5263\n",
            "Epoch 73/100\n",
            "109/109 [==============================] - 5s 43ms/step - loss: 0.6422 - accuracy: 0.9106 - val_loss: 2.1891 - val_accuracy: 0.6053\n",
            "Epoch 74/100\n",
            "109/109 [==============================] - 5s 42ms/step - loss: 0.6534 - accuracy: 0.8922 - val_loss: 2.0563 - val_accuracy: 0.5263\n",
            "Epoch 75/100\n",
            "109/109 [==============================] - 5s 45ms/step - loss: 0.6673 - accuracy: 0.9037 - val_loss: 2.0009 - val_accuracy: 0.6053\n",
            "Epoch 76/100\n",
            "109/109 [==============================] - 5s 43ms/step - loss: 0.6454 - accuracy: 0.9094 - val_loss: 2.1157 - val_accuracy: 0.5658\n",
            "Epoch 77/100\n",
            "109/109 [==============================] - 5s 44ms/step - loss: 0.6146 - accuracy: 0.9174 - val_loss: 2.0060 - val_accuracy: 0.6184\n",
            "Epoch 78/100\n",
            "109/109 [==============================] - 5s 43ms/step - loss: 0.5849 - accuracy: 0.9232 - val_loss: 2.0736 - val_accuracy: 0.6053\n",
            "Epoch 79/100\n",
            "109/109 [==============================] - 5s 44ms/step - loss: 0.5485 - accuracy: 0.9232 - val_loss: 2.0761 - val_accuracy: 0.6184\n",
            "Epoch 80/100\n",
            "109/109 [==============================] - 5s 44ms/step - loss: 0.5614 - accuracy: 0.9243 - val_loss: 2.0567 - val_accuracy: 0.5921\n",
            "Epoch 81/100\n",
            "109/109 [==============================] - 5s 44ms/step - loss: 0.5660 - accuracy: 0.9335 - val_loss: 2.0060 - val_accuracy: 0.5921\n",
            "Epoch 82/100\n",
            "109/109 [==============================] - 5s 45ms/step - loss: 0.5750 - accuracy: 0.9048 - val_loss: 2.1142 - val_accuracy: 0.5789\n",
            "Epoch 83/100\n",
            "109/109 [==============================] - 5s 43ms/step - loss: 0.5613 - accuracy: 0.9300 - val_loss: 2.1301 - val_accuracy: 0.5658\n",
            "Epoch 84/100\n",
            "109/109 [==============================] - 5s 43ms/step - loss: 0.5494 - accuracy: 0.9346 - val_loss: 2.1032 - val_accuracy: 0.5789\n",
            "Epoch 85/100\n",
            "109/109 [==============================] - 5s 42ms/step - loss: 0.5375 - accuracy: 0.9220 - val_loss: 1.9877 - val_accuracy: 0.6053\n",
            "Epoch 86/100\n",
            "109/109 [==============================] - 5s 44ms/step - loss: 0.5452 - accuracy: 0.9186 - val_loss: 2.0786 - val_accuracy: 0.5921\n",
            "Epoch 87/100\n",
            "109/109 [==============================] - 5s 44ms/step - loss: 0.5429 - accuracy: 0.9300 - val_loss: 2.0627 - val_accuracy: 0.5526\n",
            "Epoch 88/100\n",
            "109/109 [==============================] - 5s 44ms/step - loss: 0.5229 - accuracy: 0.9415 - val_loss: 2.0611 - val_accuracy: 0.5789\n",
            "Epoch 89/100\n",
            "109/109 [==============================] - 5s 43ms/step - loss: 0.5370 - accuracy: 0.9266 - val_loss: 2.1442 - val_accuracy: 0.5658\n",
            "Epoch 90/100\n",
            "109/109 [==============================] - 5s 43ms/step - loss: 0.5555 - accuracy: 0.9209 - val_loss: 2.1477 - val_accuracy: 0.5921\n",
            "Epoch 91/100\n",
            "109/109 [==============================] - 5s 45ms/step - loss: 0.5436 - accuracy: 0.9323 - val_loss: 2.1772 - val_accuracy: 0.5658\n",
            "Epoch 92/100\n",
            "109/109 [==============================] - 5s 49ms/step - loss: 0.5224 - accuracy: 0.9266 - val_loss: 2.1592 - val_accuracy: 0.5395\n",
            "Epoch 93/100\n",
            "109/109 [==============================] - 5s 45ms/step - loss: 0.5078 - accuracy: 0.9323 - val_loss: 2.1444 - val_accuracy: 0.5526\n",
            "Epoch 94/100\n",
            "109/109 [==============================] - 5s 46ms/step - loss: 0.5328 - accuracy: 0.9289 - val_loss: 2.0969 - val_accuracy: 0.5658\n",
            "Epoch 95/100\n",
            "109/109 [==============================] - 5s 43ms/step - loss: 0.5199 - accuracy: 0.9289 - val_loss: 2.0011 - val_accuracy: 0.5789\n",
            "Epoch 96/100\n",
            "109/109 [==============================] - 5s 46ms/step - loss: 0.5407 - accuracy: 0.9232 - val_loss: 1.9384 - val_accuracy: 0.6053\n",
            "Epoch 97/100\n",
            "109/109 [==============================] - 5s 47ms/step - loss: 0.5097 - accuracy: 0.9381 - val_loss: 2.1238 - val_accuracy: 0.6053\n",
            "Epoch 98/100\n",
            "109/109 [==============================] - 5s 46ms/step - loss: 0.5310 - accuracy: 0.9266 - val_loss: 1.9832 - val_accuracy: 0.5658\n",
            "Epoch 99/100\n",
            "109/109 [==============================] - 6s 59ms/step - loss: 0.5370 - accuracy: 0.9278 - val_loss: 2.0698 - val_accuracy: 0.5395\n",
            "Epoch 100/100\n",
            "109/109 [==============================] - 6s 52ms/step - loss: 0.5737 - accuracy: 0.9209 - val_loss: 1.9958 - val_accuracy: 0.6316\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Encode testing labels\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "encoded_labels = le.fit_transform(labels)\n",
        "num_classes = len(le.classes_)\n",
        "encoded_labels_test = le.transform(labels_test)\n",
        "\n",
        "# Define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, 128, input_length=max_sequence_length))\n",
        "model.add(LSTM(128, return_sequences=True, kernel_regularizer=l2(0.001)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(64, kernel_regularizer=l2(0.001)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax', kernel_regularizer=l2(0.001)))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(lr=0.001)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# hist=model.fit(data, encoded_labels, epochs=100, batch_size=8, verbose=1)\n",
        "hist = model.fit(data, encoded_labels, validation_data=(data_test, encoded_labels_test), epochs=100, batch_size=8, verbose=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5au7pNBFQ0Xr",
        "outputId": "f387b993-dcb3-4611-bb17-9418d927be47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train accuracy: 0.9529816508293152\n",
            "Test accuracy: 0.6184210777282715\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the training set\n",
        "train_loss, train_acc = model.evaluate(data, encoded_labels, verbose=0)\n",
        "print('Train accuracy:', train_acc)\n",
        "\n",
        "# Evaluate the model on the testing set\n",
        "test_loss, test_acc = model.evaluate(data_test, encoded_labels_test, verbose=0)\n",
        "print('Test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiHBK1u_cGPg",
        "outputId": "e6006615-6299-4db5-f606-74949336cb68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "28/28 [==============================] - 1s 23ms/step\n",
            "3/3 [==============================] - 0s 24ms/step\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Make predictions on the training and testing set\n",
        "y_train_pred = model.predict(data)\n",
        "y_test_pred = model.predict(data_test)\n",
        "\n",
        "# Convert predicted probabilities to binary predictions\n",
        "y_train_pred_binary = np.argmax(y_train_pred, axis=1)\n",
        "y_test_pred_binary = np.argmax(y_test_pred, axis=1)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgRGlPXbftqU",
        "outputId": "d2486d74-7fe4-4c61-cb8d-a19635299794"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Set Metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00        11\n",
            "           2       1.00      1.00      1.00        10\n",
            "           3       1.00      1.00      1.00        11\n",
            "           4       1.00      1.00      1.00        13\n",
            "           5       1.00      1.00      1.00        13\n",
            "           6       1.00      0.82      0.90        11\n",
            "           7       1.00      1.00      1.00         9\n",
            "           8       1.00      0.90      0.95        20\n",
            "           9       1.00      0.64      0.78        11\n",
            "          10       1.00      1.00      1.00         9\n",
            "          11       0.90      0.95      0.92        19\n",
            "          12       1.00      0.88      0.93        16\n",
            "          13       1.00      0.91      0.95        11\n",
            "          14       0.95      1.00      0.97        38\n",
            "          15       0.92      1.00      0.96        24\n",
            "          16       1.00      1.00      1.00        17\n",
            "          17       0.93      1.00      0.96        13\n",
            "          18       0.95      1.00      0.98        20\n",
            "          19       1.00      1.00      1.00        21\n",
            "          20       1.00      1.00      1.00        20\n",
            "          21       1.00      1.00      1.00        11\n",
            "          22       0.95      0.97      0.96        64\n",
            "          23       0.91      0.96      0.93        52\n",
            "          24       0.91      0.88      0.90        94\n",
            "          25       1.00      0.70      0.82        20\n",
            "          26       0.85      0.95      0.90        42\n",
            "          27       1.00      1.00      1.00        25\n",
            "          28       1.00      0.96      0.98        24\n",
            "          29       0.95      1.00      0.97        36\n",
            "          30       0.92      1.00      0.96        12\n",
            "          31       0.71      0.83      0.77         6\n",
            "          32       0.90      1.00      0.95         9\n",
            "          33       1.00      1.00      1.00        10\n",
            "          34       1.00      0.95      0.98        42\n",
            "          35       1.00      1.00      1.00        13\n",
            "          36       1.00      0.94      0.97        16\n",
            "          37       1.00      1.00      1.00        16\n",
            "          38       0.87      1.00      0.93        26\n",
            "          39       1.00      0.96      0.98        27\n",
            "\n",
            "    accuracy                           0.95       872\n",
            "   macro avg       0.97      0.95      0.96       872\n",
            "weighted avg       0.96      0.95      0.95       872\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print classification report for training set\n",
        "print('Training Set Metrics:')\n",
        "print(classification_report(encoded_labels, y_train_pred_binary))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtPL6yLxfvBB",
        "outputId": "523443c7-92af-4f70-b134-9df20012e776"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing Set Metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67         2\n",
            "           1       1.00      1.00      1.00         2\n",
            "           2       0.50      1.00      0.67         2\n",
            "           3       0.50      1.00      0.67         2\n",
            "           4       0.67      1.00      0.80         2\n",
            "           5       1.00      1.00      1.00         2\n",
            "           6       1.00      0.50      0.67         2\n",
            "           7       0.00      0.00      0.00         1\n",
            "           8       0.00      0.00      0.00         2\n",
            "           9       0.50      0.50      0.50         2\n",
            "          10       1.00      1.00      1.00         2\n",
            "          11       0.00      0.00      0.00         2\n",
            "          12       0.00      0.00      0.00         2\n",
            "          13       0.67      1.00      0.80         2\n",
            "          14       0.50      1.00      0.67         2\n",
            "          15       1.00      0.50      0.67         2\n",
            "          16       0.00      0.00      0.00         2\n",
            "          17       0.33      1.00      0.50         1\n",
            "          18       0.25      0.50      0.33         2\n",
            "          19       1.00      0.50      0.67         2\n",
            "          20       0.00      0.00      0.00         1\n",
            "          21       1.00      1.00      1.00         2\n",
            "          22       1.00      0.50      0.67         2\n",
            "          23       1.00      0.50      0.67         2\n",
            "          24       0.00      0.00      0.00         2\n",
            "          25       0.00      0.00      0.00         2\n",
            "          26       0.50      0.50      0.50         2\n",
            "          27       0.50      0.50      0.50         2\n",
            "          28       0.67      1.00      0.80         2\n",
            "          29       0.50      1.00      0.67         1\n",
            "          30       1.00      1.00      1.00         2\n",
            "          31       0.00      0.00      0.00         2\n",
            "          32       0.33      0.50      0.40         2\n",
            "          33       0.67      1.00      0.80         2\n",
            "          34       0.00      0.00      0.00         2\n",
            "          35       1.00      0.50      0.67         2\n",
            "          36       1.00      1.00      1.00         2\n",
            "          37       0.67      1.00      0.80         2\n",
            "          38       0.50      1.00      0.67         2\n",
            "          39       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           0.62        76\n",
            "   macro avg       0.54      0.61      0.54        76\n",
            "weighted avg       0.56      0.62      0.56        76\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Print classification report for testing set\n",
        "print('Testing Set Metrics:')\n",
        "print(classification_report(encoded_labels_test, y_test_pred_binary))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "uYQEytbaGrlf",
        "outputId": "e9d3dca4-a596-494f-eb71-ccef8652bcc8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the training and validation accuracy over time\n",
        "plt.plot(hist.history['accuracy'], label='Training accuracy')\n",
        "plt.plot(hist.history['val_accuracy'], label='Validation accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "6V8JdEMMM8OG",
        "outputId": "b62f5952-c739-43cb-a562-7c9bce0985c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f6de5209220>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# Plot the training and validation loss over time\n",
        "plt.plot(hist.history['loss'], label='Training loss')\n",
        "plt.plot(hist.history['val_loss'], label='Validation loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "Qat5TEF5Nf5H",
        "outputId": "24dbc2d0-8645-4bb8-da0b-094a975bf9d6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 480x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "cm = confusion_matrix(encoded_labels_test, y_test_pred_binary)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.matshow(cm)\n",
        "plt.colorbar()\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "th9Ak2FKOL7t",
        "outputId": "aa397bb8-b010-468f-bba6-ff6d154864f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (1.2.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.22.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1xLmgWHSqav"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "\n",
        "class KerasModel(BaseEstimator, ClassifierMixin):\n",
        "    def fit(self, X, y):\n",
        "        model = keras.Sequential([\n",
        "            layers.LSTM(64, input_shape=(X.shape[1], 1)),\n",
        "            layers.Dense(128, kernel_regularizer=l2(0.001)),\n",
        "            layers.Dropout(0.5),\n",
        "            layers.Dense(1, activation=\"relu\"),\n",
        "            layers.Dense(64, kernel_regularizer=l2(0.001)),\n",
        "            layers.Dropout(0.5),\n",
        "            layers.Dense(1, activation=\"relu\"), \n",
        "            ])\n",
        "        model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "        model.fit(X, y, epochs=275, batch_size=7)\n",
        "        self.model = model\n",
        "        return self\n",
        "\n",
        "    def score(self, X, y):\n",
        "        return accuracy_score(y, (self.model.predict(X) > 0.5).flatten())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oc5b8l3NX4LI",
        "outputId": "e574e4e7-c03c-441d-e97b-10b7c1baf6da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/275\n",
            "12/12 [==============================] - 3s 12ms/step - loss: 4.5272 - accuracy: 0.5000\n",
            "Epoch 2/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.4579 - accuracy: 0.5000\n",
            "Epoch 3/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.2980 - accuracy: 0.5000\n",
            "Epoch 4/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.1746 - accuracy: 0.5000\n",
            "Epoch 5/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.0904 - accuracy: 0.5000\n",
            "Epoch 6/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.0489 - accuracy: 0.5000\n",
            "Epoch 7/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.0011 - accuracy: 0.5000\n",
            "Epoch 8/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.8743 - accuracy: 0.5375\n",
            "Epoch 9/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.7664 - accuracy: 0.5750\n",
            "Epoch 10/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.1901 - accuracy: 0.4875\n",
            "Epoch 11/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7612 - accuracy: 0.6125\n",
            "Epoch 12/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.8154 - accuracy: 0.5375\n",
            "Epoch 13/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.9498 - accuracy: 0.6125\n",
            "Epoch 14/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.7305 - accuracy: 0.6000\n",
            "Epoch 15/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.8849 - accuracy: 0.6375\n",
            "Epoch 16/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.6768 - accuracy: 0.6375\n",
            "Epoch 17/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7425 - accuracy: 0.6750\n",
            "Epoch 18/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.8182 - accuracy: 0.5625\n",
            "Epoch 19/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.7003 - accuracy: 0.6000\n",
            "Epoch 20/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.7218 - accuracy: 0.6250\n",
            "Epoch 21/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.6687 - accuracy: 0.6625\n",
            "Epoch 22/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.6935 - accuracy: 0.6750\n",
            "Epoch 23/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.8070 - accuracy: 0.6875\n",
            "Epoch 24/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6041 - accuracy: 0.7375\n",
            "Epoch 25/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.8307 - accuracy: 0.6500\n",
            "Epoch 26/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.8563 - accuracy: 0.6625\n",
            "Epoch 27/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6550 - accuracy: 0.6875\n",
            "Epoch 28/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7758 - accuracy: 0.7250\n",
            "Epoch 29/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6638 - accuracy: 0.6625\n",
            "Epoch 30/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6445 - accuracy: 0.7125\n",
            "Epoch 31/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6989 - accuracy: 0.6375\n",
            "Epoch 32/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.6590 - accuracy: 0.6875\n",
            "Epoch 33/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.5791 - accuracy: 0.7250\n",
            "Epoch 34/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.5706 - accuracy: 0.7125\n",
            "Epoch 35/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.6733 - accuracy: 0.8000\n",
            "Epoch 36/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.8643 - accuracy: 0.7750\n",
            "Epoch 37/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 1.0088 - accuracy: 0.8250\n",
            "Epoch 38/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6731 - accuracy: 0.8000\n",
            "Epoch 39/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.5499 - accuracy: 0.7250\n",
            "Epoch 40/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.4768 - accuracy: 0.8000\n",
            "Epoch 41/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.5254 - accuracy: 0.8125\n",
            "Epoch 42/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.6165 - accuracy: 0.7000\n",
            "Epoch 43/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.5904 - accuracy: 0.7250\n",
            "Epoch 44/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.5264 - accuracy: 0.7625\n",
            "Epoch 45/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.7035 - accuracy: 0.7375\n",
            "Epoch 46/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.8084 - accuracy: 0.8125\n",
            "Epoch 47/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.8139 - accuracy: 0.8125\n",
            "Epoch 48/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.6055 - accuracy: 0.8250\n",
            "Epoch 49/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6594 - accuracy: 0.7875\n",
            "Epoch 50/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.5275 - accuracy: 0.7875\n",
            "Epoch 51/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5962 - accuracy: 0.6750\n",
            "Epoch 52/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.5867 - accuracy: 0.7125\n",
            "Epoch 53/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.5041 - accuracy: 0.8000\n",
            "Epoch 54/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4724 - accuracy: 0.8000\n",
            "Epoch 55/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4274 - accuracy: 0.8125\n",
            "Epoch 56/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.4072 - accuracy: 0.8500\n",
            "Epoch 57/275\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.6465 - accuracy: 0.7875\n",
            "Epoch 58/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4022 - accuracy: 0.8625\n",
            "Epoch 59/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.9451 - accuracy: 0.7125\n",
            "Epoch 60/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.6737 - accuracy: 0.6875\n",
            "Epoch 61/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.8565 - accuracy: 0.6625\n",
            "Epoch 62/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5762 - accuracy: 0.7375\n",
            "Epoch 63/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6500 - accuracy: 0.8000\n",
            "Epoch 64/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5939 - accuracy: 0.8250\n",
            "Epoch 65/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.7576 - accuracy: 0.8500\n",
            "Epoch 66/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5617 - accuracy: 0.8750\n",
            "Epoch 67/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.5593 - accuracy: 0.8250\n",
            "Epoch 68/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6215 - accuracy: 0.8125\n",
            "Epoch 69/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.5676 - accuracy: 0.8500\n",
            "Epoch 70/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3858 - accuracy: 0.8375\n",
            "Epoch 71/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5595 - accuracy: 0.8500\n",
            "Epoch 72/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6009 - accuracy: 0.8375\n",
            "Epoch 73/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5692 - accuracy: 0.8375\n",
            "Epoch 74/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3943 - accuracy: 0.8500\n",
            "Epoch 75/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6089 - accuracy: 0.8250\n",
            "Epoch 76/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3933 - accuracy: 0.8375\n",
            "Epoch 77/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5047 - accuracy: 0.7625\n",
            "Epoch 78/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.4444 - accuracy: 0.8125\n",
            "Epoch 79/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6014 - accuracy: 0.8500\n",
            "Epoch 80/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5568 - accuracy: 0.8500\n",
            "Epoch 81/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6008 - accuracy: 0.8125\n",
            "Epoch 82/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5167 - accuracy: 0.8750\n",
            "Epoch 83/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5639 - accuracy: 0.8250\n",
            "Epoch 84/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6166 - accuracy: 0.8125\n",
            "Epoch 85/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.8521 - accuracy: 0.7125\n",
            "Epoch 86/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 1.2173 - accuracy: 0.6625\n",
            "Epoch 87/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.8647 - accuracy: 0.6750\n",
            "Epoch 88/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.8171 - accuracy: 0.6750\n",
            "Epoch 89/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.5812 - accuracy: 0.7375\n",
            "Epoch 90/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4906 - accuracy: 0.8125\n",
            "Epoch 91/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6326 - accuracy: 0.8125\n",
            "Epoch 92/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4405 - accuracy: 0.7750\n",
            "Epoch 93/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7887 - accuracy: 0.8125\n",
            "Epoch 94/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.5971 - accuracy: 0.8375\n",
            "Epoch 95/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.6109 - accuracy: 0.8250\n",
            "Epoch 96/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5947 - accuracy: 0.8125\n",
            "Epoch 97/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6101 - accuracy: 0.8250\n",
            "Epoch 98/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6063 - accuracy: 0.8375\n",
            "Epoch 99/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4002 - accuracy: 0.8625\n",
            "Epoch 100/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.4478 - accuracy: 0.8375\n",
            "Epoch 101/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5989 - accuracy: 0.8500\n",
            "Epoch 102/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4274 - accuracy: 0.8375\n",
            "Epoch 103/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4140 - accuracy: 0.8250\n",
            "Epoch 104/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5985 - accuracy: 0.8250\n",
            "Epoch 105/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4250 - accuracy: 0.8500\n",
            "Epoch 106/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5395 - accuracy: 0.8625\n",
            "Epoch 107/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3741 - accuracy: 0.8625\n",
            "Epoch 108/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3762 - accuracy: 0.8625\n",
            "Epoch 109/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.4029 - accuracy: 0.8250\n",
            "Epoch 110/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6994 - accuracy: 0.8750\n",
            "Epoch 111/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.5260 - accuracy: 0.8750\n",
            "Epoch 112/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5271 - accuracy: 0.8500\n",
            "Epoch 113/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5519 - accuracy: 0.8625\n",
            "Epoch 114/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.5841 - accuracy: 0.8750\n",
            "Epoch 115/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.7452 - accuracy: 0.6500\n",
            "Epoch 116/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.8371 - accuracy: 0.6625\n",
            "Epoch 117/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5661 - accuracy: 0.7125\n",
            "Epoch 118/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5127 - accuracy: 0.7625\n",
            "Epoch 119/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.4299 - accuracy: 0.8000\n",
            "Epoch 120/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6374 - accuracy: 0.8250\n",
            "Epoch 121/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.5845 - accuracy: 0.8125\n",
            "Epoch 122/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.5926 - accuracy: 0.8625\n",
            "Epoch 123/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.7292 - accuracy: 0.8625\n",
            "Epoch 124/275\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.5507 - accuracy: 0.8500\n",
            "Epoch 125/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4793 - accuracy: 0.8750\n",
            "Epoch 126/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 1.0811 - accuracy: 0.5125\n",
            "Epoch 127/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 1.2270 - accuracy: 0.4875\n",
            "Epoch 128/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.9395 - accuracy: 0.4750\n",
            "Epoch 129/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.8366 - accuracy: 0.5000\n",
            "Epoch 130/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.8215 - accuracy: 0.4625\n",
            "Epoch 131/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.8079 - accuracy: 0.4250\n",
            "Epoch 132/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.8074 - accuracy: 0.5500\n",
            "Epoch 133/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.7408 - accuracy: 0.6125\n",
            "Epoch 134/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.7292 - accuracy: 0.5500\n",
            "Epoch 135/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.7872 - accuracy: 0.4875\n",
            "Epoch 136/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7695 - accuracy: 0.5000\n",
            "Epoch 137/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7327 - accuracy: 0.6000\n",
            "Epoch 138/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.7416 - accuracy: 0.5250\n",
            "Epoch 139/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.7315 - accuracy: 0.5500\n",
            "Epoch 140/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.7684 - accuracy: 0.4750\n",
            "Epoch 141/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7427 - accuracy: 0.5875\n",
            "Epoch 142/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7497 - accuracy: 0.5375\n",
            "Epoch 143/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7959 - accuracy: 0.5000\n",
            "Epoch 144/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7138 - accuracy: 0.5875\n",
            "Epoch 145/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.7310 - accuracy: 0.5875\n",
            "Epoch 146/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.8531 - accuracy: 0.6250\n",
            "Epoch 147/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7332 - accuracy: 0.5500\n",
            "Epoch 148/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7035 - accuracy: 0.6000\n",
            "Epoch 149/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7251 - accuracy: 0.5625\n",
            "Epoch 150/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6671 - accuracy: 0.6500\n",
            "Epoch 151/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.6694 - accuracy: 0.6000\n",
            "Epoch 152/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7003 - accuracy: 0.6250\n",
            "Epoch 153/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6606 - accuracy: 0.6000\n",
            "Epoch 154/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6914 - accuracy: 0.6625\n",
            "Epoch 155/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6697 - accuracy: 0.6375\n",
            "Epoch 156/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6826 - accuracy: 0.5750\n",
            "Epoch 157/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7749 - accuracy: 0.7000\n",
            "Epoch 158/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6677 - accuracy: 0.6250\n",
            "Epoch 159/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5933 - accuracy: 0.6500\n",
            "Epoch 160/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6298 - accuracy: 0.6875\n",
            "Epoch 161/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6805 - accuracy: 0.6750\n",
            "Epoch 162/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6951 - accuracy: 0.6000\n",
            "Epoch 163/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.7047 - accuracy: 0.5750\n",
            "Epoch 164/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.6657 - accuracy: 0.6125\n",
            "Epoch 165/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.6156 - accuracy: 0.6750\n",
            "Epoch 166/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6393 - accuracy: 0.7000\n",
            "Epoch 167/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6335 - accuracy: 0.6875\n",
            "Epoch 168/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5733 - accuracy: 0.7750\n",
            "Epoch 169/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.6404 - accuracy: 0.6875\n",
            "Epoch 170/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6593 - accuracy: 0.6375\n",
            "Epoch 171/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6478 - accuracy: 0.6125\n",
            "Epoch 172/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.5740 - accuracy: 0.7125\n",
            "Epoch 173/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6094 - accuracy: 0.6750\n",
            "Epoch 174/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6027 - accuracy: 0.7375\n",
            "Epoch 175/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5780 - accuracy: 0.7125\n",
            "Epoch 176/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5777 - accuracy: 0.7125\n",
            "Epoch 177/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7374 - accuracy: 0.7875\n",
            "Epoch 178/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.5500 - accuracy: 0.7375\n",
            "Epoch 179/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.5246 - accuracy: 0.8000\n",
            "Epoch 180/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5120 - accuracy: 0.7875\n",
            "Epoch 181/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4767 - accuracy: 0.8125\n",
            "Epoch 182/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5062 - accuracy: 0.7875\n",
            "Epoch 183/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.5083 - accuracy: 0.8000\n",
            "Epoch 184/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.7068 - accuracy: 0.8250\n",
            "Epoch 185/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.5216 - accuracy: 0.7250\n",
            "Epoch 186/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5153 - accuracy: 0.8000\n",
            "Epoch 187/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.5189 - accuracy: 0.8125\n",
            "Epoch 188/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6442 - accuracy: 0.7875\n",
            "Epoch 189/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4773 - accuracy: 0.7750\n",
            "Epoch 190/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4663 - accuracy: 0.8125\n",
            "Epoch 191/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.4721 - accuracy: 0.8250\n",
            "Epoch 192/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6753 - accuracy: 0.7750\n",
            "Epoch 193/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.4187 - accuracy: 0.8250\n",
            "Epoch 194/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4369 - accuracy: 0.8375\n",
            "Epoch 195/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.9513 - accuracy: 0.8625\n",
            "Epoch 196/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.7777 - accuracy: 0.8250\n",
            "Epoch 197/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.7088 - accuracy: 0.8750\n",
            "Epoch 198/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.7378 - accuracy: 0.8250\n",
            "Epoch 199/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.6163 - accuracy: 0.7875\n",
            "Epoch 200/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.3586 - accuracy: 0.8250\n",
            "Epoch 201/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.7987 - accuracy: 0.8125\n",
            "Epoch 202/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5542 - accuracy: 0.8375\n",
            "Epoch 203/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5551 - accuracy: 0.8250\n",
            "Epoch 204/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6999 - accuracy: 0.8875\n",
            "Epoch 205/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6769 - accuracy: 0.8500\n",
            "Epoch 206/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5352 - accuracy: 0.8375\n",
            "Epoch 207/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6952 - accuracy: 0.8625\n",
            "Epoch 208/275\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.8667 - accuracy: 0.8500\n",
            "Epoch 209/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.3554 - accuracy: 0.8625\n",
            "Epoch 210/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.3039 - accuracy: 0.8750\n",
            "Epoch 211/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5453 - accuracy: 0.8250\n",
            "Epoch 212/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.2886 - accuracy: 0.9250\n",
            "Epoch 213/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5170 - accuracy: 0.8750\n",
            "Epoch 214/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.6877 - accuracy: 0.8625\n",
            "Epoch 215/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3376 - accuracy: 0.8625\n",
            "Epoch 216/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5583 - accuracy: 0.8750\n",
            "Epoch 217/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5522 - accuracy: 0.8500\n",
            "Epoch 218/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.2802 - accuracy: 0.9125\n",
            "Epoch 219/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3203 - accuracy: 0.8750\n",
            "Epoch 220/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4906 - accuracy: 0.9125\n",
            "Epoch 221/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4884 - accuracy: 0.8875\n",
            "Epoch 222/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4435 - accuracy: 0.9250\n",
            "Epoch 223/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.4758 - accuracy: 0.9125\n",
            "Epoch 224/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4681 - accuracy: 0.8875\n",
            "Epoch 225/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4673 - accuracy: 0.9125\n",
            "Epoch 226/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4434 - accuracy: 0.9250\n",
            "Epoch 227/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.8047 - accuracy: 0.9000\n",
            "Epoch 228/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.8240 - accuracy: 0.8500\n",
            "Epoch 229/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4579 - accuracy: 0.8750\n",
            "Epoch 230/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.5168 - accuracy: 0.8750\n",
            "Epoch 231/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.3365 - accuracy: 0.8750\n",
            "Epoch 232/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.6153 - accuracy: 0.8250\n",
            "Epoch 233/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.3694 - accuracy: 0.8500\n",
            "Epoch 234/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4196 - accuracy: 0.8375\n",
            "Epoch 235/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4697 - accuracy: 0.8875\n",
            "Epoch 236/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.2900 - accuracy: 0.9000\n",
            "Epoch 237/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6222 - accuracy: 0.9000\n",
            "Epoch 238/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4908 - accuracy: 0.8875\n",
            "Epoch 239/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.4769 - accuracy: 0.8875\n",
            "Epoch 240/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.4700 - accuracy: 0.9125\n",
            "Epoch 241/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6237 - accuracy: 0.9000\n",
            "Epoch 242/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6186 - accuracy: 0.8875\n",
            "Epoch 243/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.4859 - accuracy: 0.8875\n",
            "Epoch 244/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.4803 - accuracy: 0.8875\n",
            "Epoch 245/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.4488 - accuracy: 0.9000\n",
            "Epoch 246/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4197 - accuracy: 0.9250\n",
            "Epoch 247/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4400 - accuracy: 0.9000\n",
            "Epoch 248/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6014 - accuracy: 0.9000\n",
            "Epoch 249/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.4319 - accuracy: 0.9125\n",
            "Epoch 250/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4709 - accuracy: 0.8875\n",
            "Epoch 251/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.4296 - accuracy: 0.9375\n",
            "Epoch 252/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4313 - accuracy: 0.9250\n",
            "Epoch 253/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4042 - accuracy: 0.9125\n",
            "Epoch 254/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.4461 - accuracy: 0.9125\n",
            "Epoch 255/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4712 - accuracy: 0.8750\n",
            "Epoch 256/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4729 - accuracy: 0.8625\n",
            "Epoch 257/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.4464 - accuracy: 0.8875\n",
            "Epoch 258/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6076 - accuracy: 0.9250\n",
            "Epoch 259/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.5828 - accuracy: 0.9250\n",
            "Epoch 260/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.4299 - accuracy: 0.9125\n",
            "Epoch 261/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.4275 - accuracy: 0.9375\n",
            "Epoch 262/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.4891 - accuracy: 0.9125\n",
            "Epoch 263/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.4788 - accuracy: 0.8750\n",
            "Epoch 264/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.4476 - accuracy: 0.9000\n",
            "Epoch 265/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4133 - accuracy: 0.9125\n",
            "Epoch 266/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.5866 - accuracy: 0.9375\n",
            "Epoch 267/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.4549 - accuracy: 0.9125\n",
            "Epoch 268/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4150 - accuracy: 0.9375\n",
            "Epoch 269/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4068 - accuracy: 0.9125\n",
            "Epoch 270/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4334 - accuracy: 0.9250\n",
            "Epoch 271/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4097 - accuracy: 0.9250\n",
            "Epoch 272/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4152 - accuracy: 0.9250\n",
            "Epoch 273/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4085 - accuracy: 0.9250\n",
            "Epoch 274/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.6045 - accuracy: 0.9250\n",
            "Epoch 275/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.9630 - accuracy: 0.7750\n",
            "1/1 [==============================] - 0s 442ms/step\n",
            "Epoch 1/275\n",
            "12/12 [==============================] - 4s 19ms/step - loss: 2.3971 - accuracy: 0.5000\n",
            "Epoch 2/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 1.3077 - accuracy: 0.5000\n",
            "Epoch 3/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 1.1932 - accuracy: 0.5000\n",
            "Epoch 4/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 1.1305 - accuracy: 0.5000\n",
            "Epoch 5/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 1.0760 - accuracy: 0.5000\n",
            "Epoch 6/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.0282 - accuracy: 0.5000\n",
            "Epoch 7/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.9785 - accuracy: 0.5000\n",
            "Epoch 8/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.9437 - accuracy: 0.5000\n",
            "Epoch 9/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.9201 - accuracy: 0.5000\n",
            "Epoch 10/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.8779 - accuracy: 0.5000\n",
            "Epoch 11/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.8620 - accuracy: 0.5000\n",
            "Epoch 12/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.8483 - accuracy: 0.5000\n",
            "Epoch 13/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.8274 - accuracy: 0.5000\n",
            "Epoch 14/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7920 - accuracy: 0.5000\n",
            "Epoch 15/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.8137 - accuracy: 0.5000\n",
            "Epoch 16/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.8071 - accuracy: 0.5125\n",
            "Epoch 17/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.7752 - accuracy: 0.5000\n",
            "Epoch 18/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7660 - accuracy: 0.5250\n",
            "Epoch 19/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.7726 - accuracy: 0.4875\n",
            "Epoch 20/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7476 - accuracy: 0.5500\n",
            "Epoch 21/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7808 - accuracy: 0.4750\n",
            "Epoch 22/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.7557 - accuracy: 0.5000\n",
            "Epoch 23/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.7593 - accuracy: 0.4875\n",
            "Epoch 24/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7512 - accuracy: 0.5375\n",
            "Epoch 25/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7398 - accuracy: 0.5125\n",
            "Epoch 26/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7412 - accuracy: 0.6125\n",
            "Epoch 27/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7582 - accuracy: 0.5125\n",
            "Epoch 28/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7566 - accuracy: 0.3875\n",
            "Epoch 29/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7282 - accuracy: 0.6000\n",
            "Epoch 30/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7644 - accuracy: 0.5000\n",
            "Epoch 31/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7623 - accuracy: 0.4625\n",
            "Epoch 32/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7212 - accuracy: 0.5625\n",
            "Epoch 33/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7984 - accuracy: 0.3750\n",
            "Epoch 34/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7211 - accuracy: 0.5375\n",
            "Epoch 35/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7434 - accuracy: 0.5500\n",
            "Epoch 36/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7362 - accuracy: 0.4875\n",
            "Epoch 37/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7509 - accuracy: 0.4750\n",
            "Epoch 38/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7458 - accuracy: 0.4500\n",
            "Epoch 39/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7410 - accuracy: 0.4875\n",
            "Epoch 40/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7175 - accuracy: 0.5875\n",
            "Epoch 41/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7394 - accuracy: 0.5250\n",
            "Epoch 42/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7354 - accuracy: 0.4875\n",
            "Epoch 43/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6955 - accuracy: 0.6125\n",
            "Epoch 44/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7339 - accuracy: 0.5000\n",
            "Epoch 45/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7527 - accuracy: 0.4125\n",
            "Epoch 46/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7031 - accuracy: 0.5125\n",
            "Epoch 47/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.7531 - accuracy: 0.4000\n",
            "Epoch 48/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.7239 - accuracy: 0.5500\n",
            "Epoch 49/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6865 - accuracy: 0.5750\n",
            "Epoch 50/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7376 - accuracy: 0.5000\n",
            "Epoch 51/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7404 - accuracy: 0.4500\n",
            "Epoch 52/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7696 - accuracy: 0.3875\n",
            "Epoch 53/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7519 - accuracy: 0.4375\n",
            "Epoch 54/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7109 - accuracy: 0.5375\n",
            "Epoch 55/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7205 - accuracy: 0.4625\n",
            "Epoch 56/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7365 - accuracy: 0.5000\n",
            "Epoch 57/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7266 - accuracy: 0.4625\n",
            "Epoch 58/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6991 - accuracy: 0.5750\n",
            "Epoch 59/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7369 - accuracy: 0.5000\n",
            "Epoch 60/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7273 - accuracy: 0.4625\n",
            "Epoch 61/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7176 - accuracy: 0.5250\n",
            "Epoch 62/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7278 - accuracy: 0.4500\n",
            "Epoch 63/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7522 - accuracy: 0.4125\n",
            "Epoch 64/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.7560 - accuracy: 0.4250\n",
            "Epoch 65/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.7118 - accuracy: 0.5500\n",
            "Epoch 66/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.7221 - accuracy: 0.5375\n",
            "Epoch 67/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.7165 - accuracy: 0.4500\n",
            "Epoch 68/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.7039 - accuracy: 0.5875\n",
            "Epoch 69/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.7035 - accuracy: 0.5500\n",
            "Epoch 70/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.7225 - accuracy: 0.4375\n",
            "Epoch 71/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.7345 - accuracy: 0.5000\n",
            "Epoch 72/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6961 - accuracy: 0.6125\n",
            "Epoch 73/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6915 - accuracy: 0.5375\n",
            "Epoch 74/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.7166 - accuracy: 0.4875\n",
            "Epoch 75/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6927 - accuracy: 0.5250\n",
            "Epoch 76/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.6972 - accuracy: 0.5750\n",
            "Epoch 77/275\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.7465 - accuracy: 0.4375\n",
            "Epoch 78/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.7010 - accuracy: 0.5125\n",
            "Epoch 79/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7328 - accuracy: 0.5500\n",
            "Epoch 80/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7299 - accuracy: 0.4875\n",
            "Epoch 81/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7127 - accuracy: 0.4750\n",
            "Epoch 82/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7402 - accuracy: 0.4625\n",
            "Epoch 83/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7447 - accuracy: 0.4375\n",
            "Epoch 84/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7089 - accuracy: 0.5875\n",
            "Epoch 85/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6998 - accuracy: 0.6125\n",
            "Epoch 86/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7253 - accuracy: 0.4750\n",
            "Epoch 87/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7330 - accuracy: 0.4750\n",
            "Epoch 88/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6958 - accuracy: 0.5000\n",
            "Epoch 89/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7007 - accuracy: 0.5500\n",
            "Epoch 90/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6824 - accuracy: 0.6125\n",
            "Epoch 91/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7357 - accuracy: 0.4125\n",
            "Epoch 92/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7145 - accuracy: 0.4875\n",
            "Epoch 93/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7152 - accuracy: 0.4000\n",
            "Epoch 94/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.7090 - accuracy: 0.5500\n",
            "Epoch 95/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.7376 - accuracy: 0.4250\n",
            "Epoch 96/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.7448 - accuracy: 0.3625\n",
            "Epoch 97/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.7168 - accuracy: 0.4875\n",
            "Epoch 98/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.7033 - accuracy: 0.5500\n",
            "Epoch 99/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6855 - accuracy: 0.5625\n",
            "Epoch 100/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.7351 - accuracy: 0.4750\n",
            "Epoch 101/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.7108 - accuracy: 0.5250\n",
            "Epoch 102/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.7048 - accuracy: 0.5375\n",
            "Epoch 103/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.6816 - accuracy: 0.5750\n",
            "Epoch 104/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7081 - accuracy: 0.4750\n",
            "Epoch 105/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6810 - accuracy: 0.6250\n",
            "Epoch 106/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7323 - accuracy: 0.4250\n",
            "Epoch 107/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7084 - accuracy: 0.5250\n",
            "Epoch 108/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7247 - accuracy: 0.5250\n",
            "Epoch 109/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.6973 - accuracy: 0.5125\n",
            "Epoch 110/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7129 - accuracy: 0.5125\n",
            "Epoch 111/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7332 - accuracy: 0.3625\n",
            "Epoch 112/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7219 - accuracy: 0.4250\n",
            "Epoch 113/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7418 - accuracy: 0.4250\n",
            "Epoch 114/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7325 - accuracy: 0.4625\n",
            "Epoch 115/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.6837 - accuracy: 0.6000\n",
            "Epoch 116/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6958 - accuracy: 0.5625\n",
            "Epoch 117/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7180 - accuracy: 0.4625\n",
            "Epoch 118/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6912 - accuracy: 0.5625\n",
            "Epoch 119/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7239 - accuracy: 0.4625\n",
            "Epoch 120/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7156 - accuracy: 0.5000\n",
            "Epoch 121/275\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.7135 - accuracy: 0.5000\n",
            "Epoch 122/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7357 - accuracy: 0.4375\n",
            "Epoch 123/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7272 - accuracy: 0.4625\n",
            "Epoch 124/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.7286 - accuracy: 0.4375\n",
            "Epoch 125/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.7059 - accuracy: 0.5250\n",
            "Epoch 126/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7153 - accuracy: 0.4875\n",
            "Epoch 127/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7149 - accuracy: 0.5000\n",
            "Epoch 128/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7062 - accuracy: 0.4875\n",
            "Epoch 129/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6805 - accuracy: 0.5000\n",
            "Epoch 130/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7136 - accuracy: 0.5875\n",
            "Epoch 131/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7076 - accuracy: 0.4875\n",
            "Epoch 132/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7134 - accuracy: 0.5625\n",
            "Epoch 133/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.6879 - accuracy: 0.5875\n",
            "Epoch 134/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.6906 - accuracy: 0.5625\n",
            "Epoch 135/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6916 - accuracy: 0.5625\n",
            "Epoch 136/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.7011 - accuracy: 0.4875\n",
            "Epoch 137/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.7135 - accuracy: 0.4875\n",
            "Epoch 138/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.7225 - accuracy: 0.4125\n",
            "Epoch 139/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.7192 - accuracy: 0.4750\n",
            "Epoch 140/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6934 - accuracy: 0.6000\n",
            "Epoch 141/275\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.7013 - accuracy: 0.5500\n",
            "Epoch 142/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.7440 - accuracy: 0.4125\n",
            "Epoch 143/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.6916 - accuracy: 0.5750\n",
            "Epoch 144/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.7054 - accuracy: 0.4500\n",
            "Epoch 145/275\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.7023 - accuracy: 0.5000\n",
            "Epoch 146/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.7173 - accuracy: 0.4250\n",
            "Epoch 147/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.7326 - accuracy: 0.3875\n",
            "Epoch 148/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.7121 - accuracy: 0.5250\n",
            "Epoch 149/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.6985 - accuracy: 0.5375\n",
            "Epoch 150/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7199 - accuracy: 0.5000\n",
            "Epoch 151/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6988 - accuracy: 0.5375\n",
            "Epoch 152/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.7027 - accuracy: 0.5500\n",
            "Epoch 153/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6792 - accuracy: 0.5500\n",
            "Epoch 154/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6624 - accuracy: 0.6125\n",
            "Epoch 155/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.6869 - accuracy: 0.5625\n",
            "Epoch 156/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7159 - accuracy: 0.4750\n",
            "Epoch 157/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7126 - accuracy: 0.4500\n",
            "Epoch 158/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7180 - accuracy: 0.4875\n",
            "Epoch 159/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.7091 - accuracy: 0.5000\n",
            "Epoch 160/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7138 - accuracy: 0.4750\n",
            "Epoch 161/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.6757 - accuracy: 0.6375\n",
            "Epoch 162/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6772 - accuracy: 0.5875\n",
            "Epoch 163/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7121 - accuracy: 0.4625\n",
            "Epoch 164/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7167 - accuracy: 0.5000\n",
            "Epoch 165/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6991 - accuracy: 0.5375\n",
            "Epoch 166/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6748 - accuracy: 0.5500\n",
            "Epoch 167/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7347 - accuracy: 0.4000\n",
            "Epoch 168/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7234 - accuracy: 0.4125\n",
            "Epoch 169/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7047 - accuracy: 0.4500\n",
            "Epoch 170/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.6978 - accuracy: 0.5500\n",
            "Epoch 171/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6733 - accuracy: 0.6375\n",
            "Epoch 172/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7122 - accuracy: 0.5250\n",
            "Epoch 173/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.6887 - accuracy: 0.5500\n",
            "Epoch 174/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7168 - accuracy: 0.5250\n",
            "Epoch 175/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7005 - accuracy: 0.5125\n",
            "Epoch 176/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7085 - accuracy: 0.5125\n",
            "Epoch 177/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7429 - accuracy: 0.3500\n",
            "Epoch 178/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7115 - accuracy: 0.4875\n",
            "Epoch 179/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7096 - accuracy: 0.5250\n",
            "Epoch 180/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6951 - accuracy: 0.5000\n",
            "Epoch 181/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7040 - accuracy: 0.4625\n",
            "Epoch 182/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7120 - accuracy: 0.5500\n",
            "Epoch 183/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7082 - accuracy: 0.4875\n",
            "Epoch 184/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6974 - accuracy: 0.4875\n",
            "Epoch 185/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7191 - accuracy: 0.3750\n",
            "Epoch 186/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7006 - accuracy: 0.5250\n",
            "Epoch 187/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.6927 - accuracy: 0.5625\n",
            "Epoch 188/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7014 - accuracy: 0.4750\n",
            "Epoch 189/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6949 - accuracy: 0.5750\n",
            "Epoch 190/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.6993 - accuracy: 0.4750\n",
            "Epoch 191/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7165 - accuracy: 0.4250\n",
            "Epoch 192/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.7072 - accuracy: 0.5000\n",
            "Epoch 193/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.7039 - accuracy: 0.5250\n",
            "Epoch 194/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7123 - accuracy: 0.3875\n",
            "Epoch 195/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7095 - accuracy: 0.5250\n",
            "Epoch 196/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.7161 - accuracy: 0.4000\n",
            "Epoch 197/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7014 - accuracy: 0.5250\n",
            "Epoch 198/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7056 - accuracy: 0.5000\n",
            "Epoch 199/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7004 - accuracy: 0.5000\n",
            "Epoch 200/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6854 - accuracy: 0.5875\n",
            "Epoch 201/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7542 - accuracy: 0.3125\n",
            "Epoch 202/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7092 - accuracy: 0.4625\n",
            "Epoch 203/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6994 - accuracy: 0.5125\n",
            "Epoch 204/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6969 - accuracy: 0.4750\n",
            "Epoch 205/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.6948 - accuracy: 0.5250\n",
            "Epoch 206/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.7308 - accuracy: 0.4375\n",
            "Epoch 207/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.7042 - accuracy: 0.4500\n",
            "Epoch 208/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.7338 - accuracy: 0.3500\n",
            "Epoch 209/275\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.7110 - accuracy: 0.4375\n",
            "Epoch 210/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6778 - accuracy: 0.6750\n",
            "Epoch 211/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.7117 - accuracy: 0.4000\n",
            "Epoch 212/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.7053 - accuracy: 0.4875\n",
            "Epoch 213/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.6990 - accuracy: 0.5250\n",
            "Epoch 214/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.6849 - accuracy: 0.5250\n",
            "Epoch 215/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6859 - accuracy: 0.5875\n",
            "Epoch 216/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.7094 - accuracy: 0.5000\n",
            "Epoch 217/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.7207 - accuracy: 0.4250\n",
            "Epoch 218/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6987 - accuracy: 0.5000\n",
            "Epoch 219/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.6853 - accuracy: 0.4875\n",
            "Epoch 220/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6923 - accuracy: 0.5250\n",
            "Epoch 221/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.6934 - accuracy: 0.4375\n",
            "Epoch 222/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.7012 - accuracy: 0.5000\n",
            "Epoch 223/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6808 - accuracy: 0.6500\n",
            "Epoch 224/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6997 - accuracy: 0.5000\n",
            "Epoch 225/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6863 - accuracy: 0.5625\n",
            "Epoch 226/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6890 - accuracy: 0.6000\n",
            "Epoch 227/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6978 - accuracy: 0.5375\n",
            "Epoch 228/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6888 - accuracy: 0.5625\n",
            "Epoch 229/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7198 - accuracy: 0.4875\n",
            "Epoch 230/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6890 - accuracy: 0.5375\n",
            "Epoch 231/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.7244 - accuracy: 0.4500\n",
            "Epoch 232/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6980 - accuracy: 0.4750\n",
            "Epoch 233/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6891 - accuracy: 0.4750\n",
            "Epoch 234/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7100 - accuracy: 0.4500\n",
            "Epoch 235/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7289 - accuracy: 0.3875\n",
            "Epoch 236/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.7193 - accuracy: 0.4750\n",
            "Epoch 237/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.7046 - accuracy: 0.4750\n",
            "Epoch 238/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7104 - accuracy: 0.5250\n",
            "Epoch 239/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6990 - accuracy: 0.5375\n",
            "Epoch 240/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7044 - accuracy: 0.4250\n",
            "Epoch 241/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6898 - accuracy: 0.5500\n",
            "Epoch 242/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7023 - accuracy: 0.5500\n",
            "Epoch 243/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.7000 - accuracy: 0.5000\n",
            "Epoch 244/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6840 - accuracy: 0.6125\n",
            "Epoch 245/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7152 - accuracy: 0.4250\n",
            "Epoch 246/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7109 - accuracy: 0.4500\n",
            "Epoch 247/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7053 - accuracy: 0.4625\n",
            "Epoch 248/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.6936 - accuracy: 0.5625\n",
            "Epoch 249/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7115 - accuracy: 0.4375\n",
            "Epoch 250/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6963 - accuracy: 0.5000\n",
            "Epoch 251/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7092 - accuracy: 0.4250\n",
            "Epoch 252/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6991 - accuracy: 0.5250\n",
            "Epoch 253/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7011 - accuracy: 0.5250\n",
            "Epoch 254/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.7221 - accuracy: 0.3750\n",
            "Epoch 255/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7129 - accuracy: 0.4250\n",
            "Epoch 256/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6977 - accuracy: 0.5250\n",
            "Epoch 257/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7050 - accuracy: 0.5000\n",
            "Epoch 258/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7013 - accuracy: 0.5250\n",
            "Epoch 259/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6736 - accuracy: 0.5500\n",
            "Epoch 260/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.6863 - accuracy: 0.5625\n",
            "Epoch 261/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6670 - accuracy: 0.6500\n",
            "Epoch 262/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.7160 - accuracy: 0.4875\n",
            "Epoch 263/275\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.6990 - accuracy: 0.5000\n",
            "Epoch 264/275\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.6985 - accuracy: 0.5250\n",
            "Epoch 265/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.6773 - accuracy: 0.5125\n",
            "Epoch 266/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.6914 - accuracy: 0.5250\n",
            "Epoch 267/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.6989 - accuracy: 0.5125\n",
            "Epoch 268/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.7074 - accuracy: 0.4625\n",
            "Epoch 269/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.6970 - accuracy: 0.5125\n",
            "Epoch 270/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6897 - accuracy: 0.5375\n",
            "Epoch 271/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6921 - accuracy: 0.5375\n",
            "Epoch 272/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7051 - accuracy: 0.5500\n",
            "Epoch 273/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6902 - accuracy: 0.5000\n",
            "Epoch 274/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6955 - accuracy: 0.5000\n",
            "Epoch 275/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.6843 - accuracy: 0.5375\n",
            "1/1 [==============================] - 1s 644ms/step\n",
            "Epoch 1/275\n",
            "12/12 [==============================] - 3s 13ms/step - loss: 7.7917 - accuracy: 0.5000\n",
            "Epoch 2/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7766 - accuracy: 0.5000\n",
            "Epoch 3/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7639 - accuracy: 0.5000\n",
            "Epoch 4/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 7.7535 - accuracy: 0.5000\n",
            "Epoch 5/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7450 - accuracy: 0.5000\n",
            "Epoch 6/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7382 - accuracy: 0.5000\n",
            "Epoch 7/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7327 - accuracy: 0.5000\n",
            "Epoch 8/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7282 - accuracy: 0.5000\n",
            "Epoch 9/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7247 - accuracy: 0.5000\n",
            "Epoch 10/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7219 - accuracy: 0.5000\n",
            "Epoch 11/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7198 - accuracy: 0.5000\n",
            "Epoch 12/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7180 - accuracy: 0.5000\n",
            "Epoch 13/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7167 - accuracy: 0.5000\n",
            "Epoch 14/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7157 - accuracy: 0.5000\n",
            "Epoch 15/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7149 - accuracy: 0.5000\n",
            "Epoch 16/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 7.7143 - accuracy: 0.5000\n",
            "Epoch 17/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7138 - accuracy: 0.5000\n",
            "Epoch 18/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7135 - accuracy: 0.5000\n",
            "Epoch 19/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7132 - accuracy: 0.5000\n",
            "Epoch 20/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7130 - accuracy: 0.5000\n",
            "Epoch 21/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7129 - accuracy: 0.5000\n",
            "Epoch 22/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7128 - accuracy: 0.5000\n",
            "Epoch 23/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7127 - accuracy: 0.5000\n",
            "Epoch 24/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7126 - accuracy: 0.5000\n",
            "Epoch 25/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7126 - accuracy: 0.5000\n",
            "Epoch 26/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7126 - accuracy: 0.5000\n",
            "Epoch 27/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 28/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 29/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 30/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 31/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 32/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 33/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 34/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 35/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 36/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 37/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 38/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 39/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 40/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 41/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 42/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 43/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 44/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 45/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 46/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 47/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 48/275\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 49/275\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 50/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 51/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 52/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 53/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 54/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 55/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 56/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 57/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 58/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 59/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 60/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 61/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 62/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 63/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 64/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 65/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 66/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 67/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 68/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 69/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 70/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 71/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 72/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 73/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 74/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 75/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 76/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 77/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 78/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 79/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 80/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 81/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 82/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 83/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 84/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 85/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 86/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 87/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 88/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 89/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 90/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 91/275\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 92/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 93/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 94/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 95/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 96/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 97/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 98/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 99/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 100/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 101/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 102/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 103/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 104/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 105/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 106/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 107/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 108/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 109/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 110/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 111/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 112/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 113/275\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 114/275\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 115/275\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 116/275\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 117/275\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 118/275\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 119/275\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 120/275\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 121/275\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 122/275\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 123/275\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 124/275\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 125/275\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 126/275\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 127/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 128/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 129/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 130/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 131/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 132/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 133/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 134/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 135/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 136/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 137/275\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 138/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 139/275\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 140/275\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 141/275\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 142/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 143/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 144/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 145/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 146/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 147/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 148/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 149/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 150/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 151/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 152/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 153/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 154/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 155/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 156/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 157/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 158/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 159/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 160/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 161/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 162/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 163/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 164/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 165/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 166/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 167/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 168/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 169/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 170/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 171/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 172/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 173/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 174/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 175/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 176/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 177/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 178/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 179/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 180/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 181/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 182/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 183/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 184/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 185/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 186/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 187/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 188/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 189/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 190/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 191/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 192/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 193/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 194/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 195/275\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 196/275\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 197/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 198/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 199/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 200/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 201/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 202/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 203/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 204/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 205/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 206/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 207/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 208/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 209/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 210/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 211/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 212/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 213/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 214/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 215/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 216/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 217/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 218/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 219/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 220/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 221/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 222/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 223/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 224/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 225/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 226/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 227/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 228/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 229/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 230/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 231/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 232/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 233/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 234/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 235/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 236/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 237/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 238/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 239/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 240/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 241/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 242/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 243/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 244/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 245/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 246/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 247/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 248/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 249/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 250/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 251/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 252/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 253/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 254/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 255/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 256/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 257/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 258/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 259/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 260/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 261/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 262/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 263/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 264/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 265/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 266/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 267/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 268/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 269/275\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 270/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 271/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 272/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 273/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 274/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 275/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "1/1 [==============================] - 1s 521ms/step\n",
            "Epoch 1/275\n",
            "12/12 [==============================] - 3s 15ms/step - loss: 7.7933 - accuracy: 0.5000\n",
            "Epoch 2/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7780 - accuracy: 0.5000\n",
            "Epoch 3/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7652 - accuracy: 0.5000\n",
            "Epoch 4/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7546 - accuracy: 0.5000\n",
            "Epoch 5/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7459 - accuracy: 0.5000\n",
            "Epoch 6/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7389 - accuracy: 0.5000\n",
            "Epoch 7/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7333 - accuracy: 0.5000\n",
            "Epoch 8/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7288 - accuracy: 0.5000\n",
            "Epoch 9/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7252 - accuracy: 0.5000\n",
            "Epoch 10/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7223 - accuracy: 0.5000\n",
            "Epoch 11/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7201 - accuracy: 0.5000\n",
            "Epoch 12/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7183 - accuracy: 0.5000\n",
            "Epoch 13/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7169 - accuracy: 0.5000\n",
            "Epoch 14/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7158 - accuracy: 0.5000\n",
            "Epoch 15/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7150 - accuracy: 0.5000\n",
            "Epoch 16/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7144 - accuracy: 0.5000\n",
            "Epoch 17/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7139 - accuracy: 0.5000\n",
            "Epoch 18/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7135 - accuracy: 0.5000\n",
            "Epoch 19/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7133 - accuracy: 0.5000\n",
            "Epoch 20/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7131 - accuracy: 0.5000\n",
            "Epoch 21/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7129 - accuracy: 0.5000\n",
            "Epoch 22/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7128 - accuracy: 0.5000\n",
            "Epoch 23/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7127 - accuracy: 0.5000\n",
            "Epoch 24/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7127 - accuracy: 0.5000\n",
            "Epoch 25/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7126 - accuracy: 0.5000\n",
            "Epoch 26/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7126 - accuracy: 0.5000\n",
            "Epoch 27/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7126 - accuracy: 0.5000\n",
            "Epoch 28/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 29/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 30/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 31/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 32/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 33/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 34/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 35/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 36/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 37/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 38/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 39/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 40/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 41/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 42/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 43/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 44/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 45/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 46/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 47/275\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 48/275\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 49/275\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 50/275\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 51/275\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 52/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 53/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 54/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 55/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 56/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 57/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 58/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 59/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 60/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 61/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 62/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 63/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 64/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 65/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 66/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 67/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 68/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 69/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 70/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 71/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 72/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 73/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 74/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 75/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 76/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 77/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 78/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 79/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 80/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 81/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 82/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 83/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 84/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 85/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 86/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 87/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 88/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 89/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 90/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 91/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 92/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 93/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 94/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 95/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 96/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 97/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 98/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 99/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 100/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 101/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 102/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 103/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 104/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 105/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 106/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 107/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 108/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 109/275\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 110/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 111/275\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 112/275\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 113/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 114/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 115/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 116/275\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 117/275\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 118/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 119/275\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 120/275\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 121/275\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 122/275\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 123/275\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 124/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 125/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 126/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 127/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 128/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 129/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 130/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 131/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 132/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 133/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 134/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 135/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 136/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 137/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 138/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 139/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 140/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 141/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 142/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 143/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 144/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 145/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 146/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 147/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 148/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 149/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 150/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 151/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 152/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 153/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 154/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 155/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 156/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 157/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 158/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 159/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 160/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 161/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 162/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 163/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 164/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 165/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 166/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 167/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 168/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 169/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 170/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 171/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 172/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 173/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 174/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 175/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 176/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 177/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 178/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 179/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 180/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 181/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 182/275\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 183/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 184/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 185/275\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 186/275\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 187/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 188/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 189/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 190/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 191/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 192/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 193/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 194/275\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 195/275\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 196/275\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 197/275\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 198/275\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 199/275\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 200/275\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 201/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 202/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 203/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 204/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 205/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 206/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 207/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 208/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 209/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 210/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 211/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 212/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 213/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 214/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 215/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 216/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 217/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 218/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 219/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 220/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 221/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 222/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 223/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 224/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 225/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 226/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 227/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 228/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 229/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 230/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 231/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 232/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 233/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 234/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 235/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 236/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 237/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 238/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 239/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 240/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 241/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 242/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 243/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 244/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 245/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 246/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 247/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 248/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 249/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 250/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 251/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 252/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 253/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 254/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 255/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 256/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 257/275\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 258/275\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 259/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 260/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 261/275\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 262/275\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 263/275\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 264/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 265/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 266/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 267/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 268/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 269/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 270/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 271/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 272/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 273/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 274/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
            "Epoch 275/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 35 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6dd7507040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 651ms/step\n",
            "Epoch 1/275\n",
            "12/12 [==============================] - 3s 13ms/step - loss: 1.7921 - accuracy: 0.5000\n",
            "Epoch 2/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.8851 - accuracy: 0.5125\n",
            "Epoch 3/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.0040 - accuracy: 0.5125\n",
            "Epoch 4/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.8041 - accuracy: 0.5125\n",
            "Epoch 5/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7629 - accuracy: 0.6125\n",
            "Epoch 6/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.9029 - accuracy: 0.6500\n",
            "Epoch 7/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.3317 - accuracy: 0.5875\n",
            "Epoch 8/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.8095 - accuracy: 0.5500\n",
            "Epoch 9/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.8128 - accuracy: 0.5500\n",
            "Epoch 10/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7727 - accuracy: 0.5625\n",
            "Epoch 11/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7863 - accuracy: 0.5625\n",
            "Epoch 12/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.9298 - accuracy: 0.5375\n",
            "Epoch 13/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7663 - accuracy: 0.5500\n",
            "Epoch 14/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7323 - accuracy: 0.5375\n",
            "Epoch 15/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7347 - accuracy: 0.5875\n",
            "Epoch 16/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.7773 - accuracy: 0.5875\n",
            "Epoch 17/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.9524 - accuracy: 0.4875\n",
            "Epoch 18/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.0250 - accuracy: 0.4750\n",
            "Epoch 19/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1.0109 - accuracy: 0.4875\n",
            "Epoch 20/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.9164 - accuracy: 0.4750\n",
            "Epoch 21/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.8665 - accuracy: 0.4375\n",
            "Epoch 22/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7891 - accuracy: 0.5125\n",
            "Epoch 23/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.8632 - accuracy: 0.5000\n",
            "Epoch 24/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7422 - accuracy: 0.6000\n",
            "Epoch 25/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7522 - accuracy: 0.6000\n",
            "Epoch 26/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7272 - accuracy: 0.6000\n",
            "Epoch 27/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.8068 - accuracy: 0.5000\n",
            "Epoch 28/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.9465 - accuracy: 0.5375\n",
            "Epoch 29/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.8181 - accuracy: 0.5500\n",
            "Epoch 30/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.9143 - accuracy: 0.6000\n",
            "Epoch 31/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7806 - accuracy: 0.5500\n",
            "Epoch 32/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7877 - accuracy: 0.5625\n",
            "Epoch 33/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7912 - accuracy: 0.5375\n",
            "Epoch 34/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7676 - accuracy: 0.5750\n",
            "Epoch 35/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7237 - accuracy: 0.5875\n",
            "Epoch 36/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.9115 - accuracy: 0.6125\n",
            "Epoch 37/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.9813 - accuracy: 0.6125\n",
            "Epoch 38/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6985 - accuracy: 0.6125\n",
            "Epoch 39/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.7526 - accuracy: 0.5875\n",
            "Epoch 40/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.7446 - accuracy: 0.5500\n",
            "Epoch 41/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.7403 - accuracy: 0.6000\n",
            "Epoch 42/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.7042 - accuracy: 0.5875\n",
            "Epoch 43/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.7643 - accuracy: 0.5500\n",
            "Epoch 44/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.7715 - accuracy: 0.5500\n",
            "Epoch 45/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.7247 - accuracy: 0.5750\n",
            "Epoch 46/275\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.7628 - accuracy: 0.5625\n",
            "Epoch 47/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.7633 - accuracy: 0.5500\n",
            "Epoch 48/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.7782 - accuracy: 0.4625\n",
            "Epoch 49/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.7509 - accuracy: 0.5250\n",
            "Epoch 50/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.7708 - accuracy: 0.5125\n",
            "Epoch 51/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.7301 - accuracy: 0.5875\n",
            "Epoch 52/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.7427 - accuracy: 0.5500\n",
            "Epoch 53/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7397 - accuracy: 0.5500\n",
            "Epoch 54/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6981 - accuracy: 0.6625\n",
            "Epoch 55/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6826 - accuracy: 0.6750\n",
            "Epoch 56/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.7552 - accuracy: 0.5250\n",
            "Epoch 57/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7284 - accuracy: 0.5625\n",
            "Epoch 58/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6974 - accuracy: 0.6250\n",
            "Epoch 59/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.8782 - accuracy: 0.6125\n",
            "Epoch 60/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.6655 - accuracy: 0.6375\n",
            "Epoch 61/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7771 - accuracy: 0.5000\n",
            "Epoch 62/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6537 - accuracy: 0.6750\n",
            "Epoch 63/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7274 - accuracy: 0.6000\n",
            "Epoch 64/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7380 - accuracy: 0.5875\n",
            "Epoch 65/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7636 - accuracy: 0.5750\n",
            "Epoch 66/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6996 - accuracy: 0.6125\n",
            "Epoch 67/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7270 - accuracy: 0.5750\n",
            "Epoch 68/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6827 - accuracy: 0.5625\n",
            "Epoch 69/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7622 - accuracy: 0.5875\n",
            "Epoch 70/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7020 - accuracy: 0.5875\n",
            "Epoch 71/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7072 - accuracy: 0.6375\n",
            "Epoch 72/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.7087 - accuracy: 0.6250\n",
            "Epoch 73/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.8801 - accuracy: 0.6375\n",
            "Epoch 74/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6686 - accuracy: 0.6625\n",
            "Epoch 75/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6851 - accuracy: 0.6750\n",
            "Epoch 76/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7059 - accuracy: 0.6500\n",
            "Epoch 77/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6866 - accuracy: 0.6375\n",
            "Epoch 78/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7685 - accuracy: 0.5875\n",
            "Epoch 79/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.8298 - accuracy: 0.5000\n",
            "Epoch 80/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.8692 - accuracy: 0.5125\n",
            "Epoch 81/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.8942 - accuracy: 0.5000\n",
            "Epoch 82/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.8152 - accuracy: 0.4875\n",
            "Epoch 83/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.8220 - accuracy: 0.4250\n",
            "Epoch 84/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.8082 - accuracy: 0.4750\n",
            "Epoch 85/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.9348 - accuracy: 0.5125\n",
            "Epoch 86/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7717 - accuracy: 0.5375\n",
            "Epoch 87/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7026 - accuracy: 0.6500\n",
            "Epoch 88/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7763 - accuracy: 0.6000\n",
            "Epoch 89/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7260 - accuracy: 0.5750\n",
            "Epoch 90/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.8192 - accuracy: 0.4375\n",
            "Epoch 91/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7199 - accuracy: 0.5875\n",
            "Epoch 92/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7324 - accuracy: 0.6250\n",
            "Epoch 93/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.7305 - accuracy: 0.5750\n",
            "Epoch 94/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6831 - accuracy: 0.6500\n",
            "Epoch 95/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6910 - accuracy: 0.7000\n",
            "Epoch 96/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.7159 - accuracy: 0.6375\n",
            "Epoch 97/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6452 - accuracy: 0.6875\n",
            "Epoch 98/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.6720 - accuracy: 0.6875\n",
            "Epoch 99/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6940 - accuracy: 0.6375\n",
            "Epoch 100/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.7083 - accuracy: 0.6500\n",
            "Epoch 101/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6963 - accuracy: 0.6125\n",
            "Epoch 102/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.7024 - accuracy: 0.6125\n",
            "Epoch 103/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7656 - accuracy: 0.5375\n",
            "Epoch 104/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6924 - accuracy: 0.6375\n",
            "Epoch 105/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6942 - accuracy: 0.6500\n",
            "Epoch 106/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.8836 - accuracy: 0.6500\n",
            "Epoch 107/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6716 - accuracy: 0.6250\n",
            "Epoch 108/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6988 - accuracy: 0.5625\n",
            "Epoch 109/275\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.6629 - accuracy: 0.7125\n",
            "Epoch 110/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6536 - accuracy: 0.7000\n",
            "Epoch 111/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.7064 - accuracy: 0.6125\n",
            "Epoch 112/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6741 - accuracy: 0.6625\n",
            "Epoch 113/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6892 - accuracy: 0.6125\n",
            "Epoch 114/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.6600 - accuracy: 0.6000\n",
            "Epoch 115/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.6872 - accuracy: 0.6250\n",
            "Epoch 116/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6634 - accuracy: 0.6250\n",
            "Epoch 117/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6536 - accuracy: 0.6875\n",
            "Epoch 118/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.8083 - accuracy: 0.6625\n",
            "Epoch 119/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.6724 - accuracy: 0.6500\n",
            "Epoch 120/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6629 - accuracy: 0.7125\n",
            "Epoch 121/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.7360 - accuracy: 0.5625\n",
            "Epoch 122/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.7154 - accuracy: 0.6000\n",
            "Epoch 123/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.6919 - accuracy: 0.6125\n",
            "Epoch 124/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.7233 - accuracy: 0.5875\n",
            "Epoch 125/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.6815 - accuracy: 0.6125\n",
            "Epoch 126/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6612 - accuracy: 0.6250\n",
            "Epoch 127/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6324 - accuracy: 0.6500\n",
            "Epoch 128/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7835 - accuracy: 0.5125\n",
            "Epoch 129/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.9283 - accuracy: 0.5000\n",
            "Epoch 130/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.8852 - accuracy: 0.5000\n",
            "Epoch 131/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.8037 - accuracy: 0.5125\n",
            "Epoch 132/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7628 - accuracy: 0.5250\n",
            "Epoch 133/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6988 - accuracy: 0.6375\n",
            "Epoch 134/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6534 - accuracy: 0.6500\n",
            "Epoch 135/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6517 - accuracy: 0.6625\n",
            "Epoch 136/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7220 - accuracy: 0.7125\n",
            "Epoch 137/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.7009 - accuracy: 0.6375\n",
            "Epoch 138/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6881 - accuracy: 0.6250\n",
            "Epoch 139/275\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.6856 - accuracy: 0.6500\n",
            "Epoch 140/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6432 - accuracy: 0.6375\n",
            "Epoch 141/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7118 - accuracy: 0.6000\n",
            "Epoch 142/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6947 - accuracy: 0.5875\n",
            "Epoch 143/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6947 - accuracy: 0.5875\n",
            "Epoch 144/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6631 - accuracy: 0.6375\n",
            "Epoch 145/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6709 - accuracy: 0.6250\n",
            "Epoch 146/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6346 - accuracy: 0.7000\n",
            "Epoch 147/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6639 - accuracy: 0.6375\n",
            "Epoch 148/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5926 - accuracy: 0.7250\n",
            "Epoch 149/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6009 - accuracy: 0.7250\n",
            "Epoch 150/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.8372 - accuracy: 0.6375\n",
            "Epoch 151/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6412 - accuracy: 0.6875\n",
            "Epoch 152/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6252 - accuracy: 0.6875\n",
            "Epoch 153/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.8802 - accuracy: 0.5875\n",
            "Epoch 154/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6021 - accuracy: 0.6875\n",
            "Epoch 155/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.5620 - accuracy: 0.7375\n",
            "Epoch 156/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7518 - accuracy: 0.6875\n",
            "Epoch 157/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5870 - accuracy: 0.7000\n",
            "Epoch 158/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6287 - accuracy: 0.7250\n",
            "Epoch 159/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5325 - accuracy: 0.7875\n",
            "Epoch 160/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7516 - accuracy: 0.7750\n",
            "Epoch 161/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5652 - accuracy: 0.7500\n",
            "Epoch 162/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5643 - accuracy: 0.7500\n",
            "Epoch 163/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.6072 - accuracy: 0.7000\n",
            "Epoch 164/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5768 - accuracy: 0.7250\n",
            "Epoch 165/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5312 - accuracy: 0.7625\n",
            "Epoch 166/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5116 - accuracy: 0.7750\n",
            "Epoch 167/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7576 - accuracy: 0.7250\n",
            "Epoch 168/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.5729 - accuracy: 0.6750\n",
            "Epoch 169/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.5271 - accuracy: 0.8125\n",
            "Epoch 170/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.5253 - accuracy: 0.7500\n",
            "Epoch 171/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.4742 - accuracy: 0.8125\n",
            "Epoch 172/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5616 - accuracy: 0.7250\n",
            "Epoch 173/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4525 - accuracy: 0.8000\n",
            "Epoch 174/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7406 - accuracy: 0.7750\n",
            "Epoch 175/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6104 - accuracy: 0.7000\n",
            "Epoch 176/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5727 - accuracy: 0.7250\n",
            "Epoch 177/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7039 - accuracy: 0.8000\n",
            "Epoch 178/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6891 - accuracy: 0.7500\n",
            "Epoch 179/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7164 - accuracy: 0.8000\n",
            "Epoch 180/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6619 - accuracy: 0.8250\n",
            "Epoch 181/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.4952 - accuracy: 0.7875\n",
            "Epoch 182/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6735 - accuracy: 0.7250\n",
            "Epoch 183/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.4110 - accuracy: 0.8000\n",
            "Epoch 184/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6158 - accuracy: 0.7250\n",
            "Epoch 185/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.8199 - accuracy: 0.6000\n",
            "Epoch 186/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.7806 - accuracy: 0.6125\n",
            "Epoch 187/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.8815 - accuracy: 0.6125\n",
            "Epoch 188/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.7741 - accuracy: 0.7000\n",
            "Epoch 189/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.5291 - accuracy: 0.7625\n",
            "Epoch 190/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.6838 - accuracy: 0.7375\n",
            "Epoch 191/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4782 - accuracy: 0.8000\n",
            "Epoch 192/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.6808 - accuracy: 0.8000\n",
            "Epoch 193/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4300 - accuracy: 0.8250\n",
            "Epoch 194/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4112 - accuracy: 0.8625\n",
            "Epoch 195/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.8318 - accuracy: 0.7875\n",
            "Epoch 196/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.6905 - accuracy: 0.7500\n",
            "Epoch 197/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4983 - accuracy: 0.7875\n",
            "Epoch 198/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.4300 - accuracy: 0.8250\n",
            "Epoch 199/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7008 - accuracy: 0.7500\n",
            "Epoch 200/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4509 - accuracy: 0.7875\n",
            "Epoch 201/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.5847 - accuracy: 0.8000\n",
            "Epoch 202/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4211 - accuracy: 0.8375\n",
            "Epoch 203/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4193 - accuracy: 0.8375\n",
            "Epoch 204/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.7710 - accuracy: 0.7875\n",
            "Epoch 205/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.3603 - accuracy: 0.8750\n",
            "Epoch 206/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.5592 - accuracy: 0.9000\n",
            "Epoch 207/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.5004 - accuracy: 0.7625\n",
            "Epoch 208/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.5744 - accuracy: 0.7125\n",
            "Epoch 209/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.4687 - accuracy: 0.7625\n",
            "Epoch 210/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.4098 - accuracy: 0.8000\n",
            "Epoch 211/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.3775 - accuracy: 0.8375\n",
            "Epoch 212/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.4860 - accuracy: 0.7625\n",
            "Epoch 213/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.5375 - accuracy: 0.7250\n",
            "Epoch 214/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.5496 - accuracy: 0.7750\n",
            "Epoch 215/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.4923 - accuracy: 0.7625\n",
            "Epoch 216/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5159 - accuracy: 0.7375\n",
            "Epoch 217/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.4598 - accuracy: 0.8250\n",
            "Epoch 218/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3963 - accuracy: 0.8000\n",
            "Epoch 219/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.3813 - accuracy: 0.8375\n",
            "Epoch 220/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4129 - accuracy: 0.8000\n",
            "Epoch 221/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.5747 - accuracy: 0.8000\n",
            "Epoch 222/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.3887 - accuracy: 0.7750\n",
            "Epoch 223/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.3349 - accuracy: 0.8625\n",
            "Epoch 224/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.5408 - accuracy: 0.8250\n",
            "Epoch 225/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3453 - accuracy: 0.8000\n",
            "Epoch 226/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.5277 - accuracy: 0.8375\n",
            "Epoch 227/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.3120 - accuracy: 0.8625\n",
            "Epoch 228/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.8609 - accuracy: 0.7250\n",
            "Epoch 229/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.9161 - accuracy: 0.6875\n",
            "Epoch 230/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.7863 - accuracy: 0.7250\n",
            "Epoch 231/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.4812 - accuracy: 0.8125\n",
            "Epoch 232/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.5834 - accuracy: 0.8125\n",
            "Epoch 233/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.3603 - accuracy: 0.8625\n",
            "Epoch 234/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3902 - accuracy: 0.8000\n",
            "Epoch 235/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.3567 - accuracy: 0.8625\n",
            "Epoch 236/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4922 - accuracy: 0.8875\n",
            "Epoch 237/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3647 - accuracy: 0.8500\n",
            "Epoch 238/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.3498 - accuracy: 0.8750\n",
            "Epoch 239/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.3857 - accuracy: 0.8000\n",
            "Epoch 240/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3394 - accuracy: 0.8750\n",
            "Epoch 241/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.3307 - accuracy: 0.8500\n",
            "Epoch 242/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.3742 - accuracy: 0.8500\n",
            "Epoch 243/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.3683 - accuracy: 0.8375\n",
            "Epoch 244/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3092 - accuracy: 0.9000\n",
            "Epoch 245/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.3337 - accuracy: 0.8250\n",
            "Epoch 246/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.2930 - accuracy: 0.8625\n",
            "Epoch 247/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.3357 - accuracy: 0.8625\n",
            "Epoch 248/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3289 - accuracy: 0.8125\n",
            "Epoch 249/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4969 - accuracy: 0.8500\n",
            "Epoch 250/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3132 - accuracy: 0.8625\n",
            "Epoch 251/275\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.4974 - accuracy: 0.8375\n",
            "Epoch 252/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.3294 - accuracy: 0.8625\n",
            "Epoch 253/275\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.3030 - accuracy: 0.8750\n",
            "Epoch 254/275\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3078 - accuracy: 0.8500\n",
            "Epoch 255/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.2697 - accuracy: 0.8625\n",
            "Epoch 256/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.3070 - accuracy: 0.8500\n",
            "Epoch 257/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.3224 - accuracy: 0.8750\n",
            "Epoch 258/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.3203 - accuracy: 0.8500\n",
            "Epoch 259/275\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.3042 - accuracy: 0.8500\n",
            "Epoch 260/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.3313 - accuracy: 0.8750\n",
            "Epoch 261/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.3326 - accuracy: 0.8500\n",
            "Epoch 262/275\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.2877 - accuracy: 0.8375\n",
            "Epoch 263/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4511 - accuracy: 0.8500\n",
            "Epoch 264/275\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.2842 - accuracy: 0.8625\n",
            "Epoch 265/275\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2866 - accuracy: 0.8875\n",
            "Epoch 266/275\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.2890 - accuracy: 0.9000\n",
            "Epoch 267/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.2288 - accuracy: 0.8875\n",
            "Epoch 268/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.2760 - accuracy: 0.8375\n",
            "Epoch 269/275\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.3005 - accuracy: 0.8750\n",
            "Epoch 270/275\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.2378 - accuracy: 0.9125\n",
            "Epoch 271/275\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.4715 - accuracy: 0.8500\n",
            "Epoch 272/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.2684 - accuracy: 0.8875\n",
            "Epoch 273/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.2679 - accuracy: 0.8875\n",
            "Epoch 274/275\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.2218 - accuracy: 0.9000\n",
            "Epoch 275/275\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.2366 - accuracy: 0.9000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 36 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6dd7c3f550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 459ms/step\n",
            "[0.55 0.5  0.5  0.5  0.5 ]\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    data, encoded_labels = make_classification()\n",
        "    clf = KerasModel()\n",
        "    print(cross_val_score(clf, data, encoded_labels))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
