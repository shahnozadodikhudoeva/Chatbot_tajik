{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import random\n",
        "import nltk\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, Input, LSTM, Embedding\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "7hRDYI9osHQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZgBjD18yfuI",
        "outputId": "706fd07c-ec2e-4e04-e506-9144c6e94afd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwVTDAa_ybw9",
        "outputId": "6f6a3082-baf5-491d-942e-7031f952482b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UivAs_SIeMR2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b15ced6-4deb-4730-b76e-50d180d79e49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "109/109 [==============================] - 6s 32ms/step - loss: 3.5793 - accuracy: 0.0986 - val_loss: 3.4824 - val_accuracy: 0.1078\n",
            "Epoch 2/200\n",
            "109/109 [==============================] - 3s 27ms/step - loss: 3.5227 - accuracy: 0.0940 - val_loss: 3.4673 - val_accuracy: 0.1078\n",
            "Epoch 3/200\n",
            "109/109 [==============================] - 3s 27ms/step - loss: 3.4995 - accuracy: 0.0975 - val_loss: 3.4703 - val_accuracy: 0.1078\n",
            "Epoch 4/200\n",
            "109/109 [==============================] - 4s 36ms/step - loss: 3.4949 - accuracy: 0.1101 - val_loss: 3.4697 - val_accuracy: 0.1078\n",
            "Epoch 5/200\n",
            "109/109 [==============================] - 3s 27ms/step - loss: 3.4978 - accuracy: 0.1009 - val_loss: 3.4699 - val_accuracy: 0.1078\n",
            "Epoch 6/200\n",
            "109/109 [==============================] - 3s 27ms/step - loss: 3.4877 - accuracy: 0.1078 - val_loss: 3.4649 - val_accuracy: 0.1078\n",
            "Epoch 7/200\n",
            "109/109 [==============================] - 3s 27ms/step - loss: 3.4923 - accuracy: 0.1101 - val_loss: 3.4622 - val_accuracy: 0.1078\n",
            "Epoch 8/200\n",
            "109/109 [==============================] - 4s 39ms/step - loss: 3.4895 - accuracy: 0.1067 - val_loss: 3.4699 - val_accuracy: 0.1078\n",
            "Epoch 9/200\n",
            "109/109 [==============================] - 3s 27ms/step - loss: 3.4876 - accuracy: 0.1067 - val_loss: 3.4684 - val_accuracy: 0.1078\n",
            "Epoch 10/200\n",
            "109/109 [==============================] - 3s 27ms/step - loss: 3.4834 - accuracy: 0.1055 - val_loss: 3.4639 - val_accuracy: 0.1078\n",
            "Epoch 11/200\n",
            "109/109 [==============================] - 3s 28ms/step - loss: 3.4895 - accuracy: 0.1067 - val_loss: 3.4616 - val_accuracy: 0.1078\n",
            "Epoch 12/200\n",
            "109/109 [==============================] - 4s 36ms/step - loss: 3.4836 - accuracy: 0.1044 - val_loss: 3.4694 - val_accuracy: 0.1078\n",
            "Epoch 13/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 3.4836 - accuracy: 0.1089 - val_loss: 3.4605 - val_accuracy: 0.1078\n",
            "Epoch 14/200\n",
            "109/109 [==============================] - 3s 31ms/step - loss: 3.4822 - accuracy: 0.1067 - val_loss: 3.4619 - val_accuracy: 0.1078\n",
            "Epoch 15/200\n",
            "109/109 [==============================] - 4s 40ms/step - loss: 3.4869 - accuracy: 0.1078 - val_loss: 3.4604 - val_accuracy: 0.1078\n",
            "Epoch 16/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 3.4820 - accuracy: 0.1078 - val_loss: 3.4603 - val_accuracy: 0.1078\n",
            "Epoch 17/200\n",
            "109/109 [==============================] - 4s 36ms/step - loss: 3.4835 - accuracy: 0.1089 - val_loss: 3.4604 - val_accuracy: 0.1078\n",
            "Epoch 18/200\n",
            "109/109 [==============================] - 4s 36ms/step - loss: 3.4765 - accuracy: 0.1078 - val_loss: 3.4624 - val_accuracy: 0.1078\n",
            "Epoch 19/200\n",
            "109/109 [==============================] - 5s 48ms/step - loss: 3.4790 - accuracy: 0.1078 - val_loss: 3.4595 - val_accuracy: 0.1078\n",
            "Epoch 20/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 3.4731 - accuracy: 0.1078 - val_loss: 3.4597 - val_accuracy: 0.1078\n",
            "Epoch 21/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 3.4800 - accuracy: 0.1067 - val_loss: 3.4638 - val_accuracy: 0.1078\n",
            "Epoch 22/200\n",
            "109/109 [==============================] - 4s 39ms/step - loss: 3.4791 - accuracy: 0.1078 - val_loss: 3.4600 - val_accuracy: 0.1078\n",
            "Epoch 23/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 3.4792 - accuracy: 0.1078 - val_loss: 3.4595 - val_accuracy: 0.1078\n",
            "Epoch 24/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 3.4804 - accuracy: 0.1101 - val_loss: 3.4603 - val_accuracy: 0.1078\n",
            "Epoch 25/200\n",
            "109/109 [==============================] - 4s 37ms/step - loss: 3.4768 - accuracy: 0.1078 - val_loss: 3.4599 - val_accuracy: 0.1078\n",
            "Epoch 26/200\n",
            "109/109 [==============================] - 4s 40ms/step - loss: 3.4775 - accuracy: 0.1078 - val_loss: 3.4589 - val_accuracy: 0.1078\n",
            "Epoch 27/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 3.4763 - accuracy: 0.1078 - val_loss: 3.4585 - val_accuracy: 0.1078\n",
            "Epoch 28/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 3.4756 - accuracy: 0.1078 - val_loss: 3.4590 - val_accuracy: 0.1078\n",
            "Epoch 29/200\n",
            "109/109 [==============================] - 5s 48ms/step - loss: 3.4736 - accuracy: 0.1055 - val_loss: 3.4575 - val_accuracy: 0.1078\n",
            "Epoch 30/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 3.4707 - accuracy: 0.1078 - val_loss: 3.4526 - val_accuracy: 0.1078\n",
            "Epoch 31/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 3.4588 - accuracy: 0.1078 - val_loss: 3.3933 - val_accuracy: 0.1078\n",
            "Epoch 32/200\n",
            "109/109 [==============================] - 4s 37ms/step - loss: 3.4073 - accuracy: 0.0963 - val_loss: 3.3926 - val_accuracy: 0.1067\n",
            "Epoch 33/200\n",
            "109/109 [==============================] - 4s 32ms/step - loss: 3.3804 - accuracy: 0.1021 - val_loss: 3.2867 - val_accuracy: 0.1067\n",
            "Epoch 34/200\n",
            "109/109 [==============================] - 4s 34ms/step - loss: 3.3364 - accuracy: 0.1021 - val_loss: 3.2412 - val_accuracy: 0.1067\n",
            "Epoch 35/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 3.3020 - accuracy: 0.0963 - val_loss: 3.2069 - val_accuracy: 0.1216\n",
            "Epoch 36/200\n",
            "109/109 [==============================] - 4s 39ms/step - loss: 3.2315 - accuracy: 0.1032 - val_loss: 3.1717 - val_accuracy: 0.1239\n",
            "Epoch 37/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 3.2693 - accuracy: 0.1067 - val_loss: 3.1794 - val_accuracy: 0.1067\n",
            "Epoch 38/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 3.1182 - accuracy: 0.1353 - val_loss: 3.0528 - val_accuracy: 0.1433\n",
            "Epoch 39/200\n",
            "109/109 [==============================] - 4s 33ms/step - loss: 3.0742 - accuracy: 0.1216 - val_loss: 2.9707 - val_accuracy: 0.1502\n",
            "Epoch 40/200\n",
            "109/109 [==============================] - 4s 34ms/step - loss: 3.2175 - accuracy: 0.1044 - val_loss: 3.0808 - val_accuracy: 0.1606\n",
            "Epoch 41/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 3.0242 - accuracy: 0.1319 - val_loss: 2.8690 - val_accuracy: 0.1525\n",
            "Epoch 42/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 2.9350 - accuracy: 0.1514 - val_loss: 2.7894 - val_accuracy: 0.1674\n",
            "Epoch 43/200\n",
            "109/109 [==============================] - 5s 45ms/step - loss: 2.8654 - accuracy: 0.1686 - val_loss: 2.8293 - val_accuracy: 0.1778\n",
            "Epoch 44/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 2.8389 - accuracy: 0.1674 - val_loss: 2.8350 - val_accuracy: 0.1755\n",
            "Epoch 45/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 2.8260 - accuracy: 0.1651 - val_loss: 2.6329 - val_accuracy: 0.2167\n",
            "Epoch 46/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 2.7707 - accuracy: 0.1743 - val_loss: 2.5923 - val_accuracy: 0.2397\n",
            "Epoch 47/200\n",
            "109/109 [==============================] - 4s 39ms/step - loss: 2.7043 - accuracy: 0.1950 - val_loss: 2.5253 - val_accuracy: 0.2362\n",
            "Epoch 48/200\n",
            "109/109 [==============================] - 3s 29ms/step - loss: 2.6723 - accuracy: 0.1915 - val_loss: 2.5997 - val_accuracy: 0.2248\n",
            "Epoch 49/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 3.1321 - accuracy: 0.1399 - val_loss: 3.3647 - val_accuracy: 0.1239\n",
            "Epoch 50/200\n",
            "109/109 [==============================] - 4s 38ms/step - loss: 3.2166 - accuracy: 0.1284 - val_loss: 2.8771 - val_accuracy: 0.1823\n",
            "Epoch 51/200\n",
            "109/109 [==============================] - 3s 31ms/step - loss: 2.9299 - accuracy: 0.1720 - val_loss: 2.7417 - val_accuracy: 0.2007\n",
            "Epoch 52/200\n",
            "109/109 [==============================] - 4s 34ms/step - loss: 2.9047 - accuracy: 0.1548 - val_loss: 2.6363 - val_accuracy: 0.2282\n",
            "Epoch 53/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 2.8276 - accuracy: 0.1846 - val_loss: 2.7058 - val_accuracy: 0.2030\n",
            "Epoch 54/200\n",
            "109/109 [==============================] - 4s 39ms/step - loss: 2.7422 - accuracy: 0.2030 - val_loss: 2.5191 - val_accuracy: 0.2248\n",
            "Epoch 55/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 2.7047 - accuracy: 0.2110 - val_loss: 2.5087 - val_accuracy: 0.2489\n",
            "Epoch 56/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 2.6562 - accuracy: 0.2144 - val_loss: 2.4512 - val_accuracy: 0.2683\n",
            "Epoch 57/200\n",
            "109/109 [==============================] - 4s 34ms/step - loss: 2.6200 - accuracy: 0.2271 - val_loss: 2.4159 - val_accuracy: 0.2592\n",
            "Epoch 58/200\n",
            "109/109 [==============================] - 4s 34ms/step - loss: 2.5639 - accuracy: 0.2259 - val_loss: 2.4111 - val_accuracy: 0.2649\n",
            "Epoch 59/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 2.5284 - accuracy: 0.2190 - val_loss: 2.3754 - val_accuracy: 0.2569\n",
            "Epoch 60/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 2.5275 - accuracy: 0.2259 - val_loss: 2.3062 - val_accuracy: 0.2729\n",
            "Epoch 61/200\n",
            "109/109 [==============================] - 5s 43ms/step - loss: 2.4279 - accuracy: 0.2294 - val_loss: 2.3679 - val_accuracy: 0.2603\n",
            "Epoch 62/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 2.3978 - accuracy: 0.2477 - val_loss: 2.2201 - val_accuracy: 0.3108\n",
            "Epoch 63/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 2.3592 - accuracy: 0.2592 - val_loss: 2.2531 - val_accuracy: 0.2810\n",
            "Epoch 64/200\n",
            "109/109 [==============================] - 4s 36ms/step - loss: 2.3631 - accuracy: 0.2443 - val_loss: 2.2030 - val_accuracy: 0.3016\n",
            "Epoch 65/200\n",
            "109/109 [==============================] - 4s 35ms/step - loss: 2.3477 - accuracy: 0.2741 - val_loss: 2.1796 - val_accuracy: 0.2947\n",
            "Epoch 66/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 2.3380 - accuracy: 0.2592 - val_loss: 2.1546 - val_accuracy: 0.3050\n",
            "Epoch 67/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 2.3049 - accuracy: 0.2569 - val_loss: 2.0976 - val_accuracy: 0.3303\n",
            "Epoch 68/200\n",
            "109/109 [==============================] - 4s 39ms/step - loss: 2.2556 - accuracy: 0.2947 - val_loss: 2.0910 - val_accuracy: 0.3498\n",
            "Epoch 69/200\n",
            "109/109 [==============================] - 4s 36ms/step - loss: 2.2570 - accuracy: 0.3085 - val_loss: 2.0344 - val_accuracy: 0.3521\n",
            "Epoch 70/200\n",
            "109/109 [==============================] - 4s 36ms/step - loss: 2.1977 - accuracy: 0.2970 - val_loss: 2.3807 - val_accuracy: 0.2661\n",
            "Epoch 71/200\n",
            "109/109 [==============================] - 4s 39ms/step - loss: 2.2330 - accuracy: 0.2959 - val_loss: 2.0605 - val_accuracy: 0.3257\n",
            "Epoch 72/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 2.2169 - accuracy: 0.2913 - val_loss: 2.0506 - val_accuracy: 0.3429\n",
            "Epoch 73/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 2.2548 - accuracy: 0.2878 - val_loss: 2.0838 - val_accuracy: 0.3268\n",
            "Epoch 74/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 2.2256 - accuracy: 0.2970 - val_loss: 2.0245 - val_accuracy: 0.3372\n",
            "Epoch 75/200\n",
            "109/109 [==============================] - 4s 39ms/step - loss: 2.1173 - accuracy: 0.3177 - val_loss: 1.9473 - val_accuracy: 0.3853\n",
            "Epoch 76/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 2.1144 - accuracy: 0.3165 - val_loss: 1.9056 - val_accuracy: 0.3612\n",
            "Epoch 77/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 2.0821 - accuracy: 0.3417 - val_loss: 2.0373 - val_accuracy: 0.3222\n",
            "Epoch 78/200\n",
            "109/109 [==============================] - 5s 43ms/step - loss: 2.0504 - accuracy: 0.3360 - val_loss: 1.9227 - val_accuracy: 0.3624\n",
            "Epoch 79/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 2.1262 - accuracy: 0.3200 - val_loss: 2.0119 - val_accuracy: 0.3360\n",
            "Epoch 80/200\n",
            "109/109 [==============================] - 4s 36ms/step - loss: 2.1073 - accuracy: 0.3268 - val_loss: 1.9446 - val_accuracy: 0.3601\n",
            "Epoch 81/200\n",
            "109/109 [==============================] - 3s 29ms/step - loss: 2.0919 - accuracy: 0.3222 - val_loss: 1.9185 - val_accuracy: 0.3727\n",
            "Epoch 82/200\n",
            "109/109 [==============================] - 4s 35ms/step - loss: 2.0204 - accuracy: 0.3360 - val_loss: 2.0224 - val_accuracy: 0.3635\n",
            "Epoch 83/200\n",
            "109/109 [==============================] - 3s 28ms/step - loss: 2.0394 - accuracy: 0.3440 - val_loss: 1.8352 - val_accuracy: 0.3842\n",
            "Epoch 84/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 2.0020 - accuracy: 0.3544 - val_loss: 1.9637 - val_accuracy: 0.3876\n",
            "Epoch 85/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 2.0252 - accuracy: 0.3509 - val_loss: 1.7852 - val_accuracy: 0.4518\n",
            "Epoch 86/200\n",
            "109/109 [==============================] - 4s 34ms/step - loss: 1.9676 - accuracy: 0.3727 - val_loss: 1.8281 - val_accuracy: 0.3888\n",
            "Epoch 87/200\n",
            "109/109 [==============================] - 3s 31ms/step - loss: 2.0100 - accuracy: 0.3567 - val_loss: 1.7805 - val_accuracy: 0.4312\n",
            "Epoch 88/200\n",
            "109/109 [==============================] - 3s 28ms/step - loss: 1.9447 - accuracy: 0.3509 - val_loss: 1.7704 - val_accuracy: 0.4358\n",
            "Epoch 89/200\n",
            "109/109 [==============================] - 4s 39ms/step - loss: 2.0926 - accuracy: 0.3268 - val_loss: 1.9073 - val_accuracy: 0.4083\n",
            "Epoch 90/200\n",
            "109/109 [==============================] - 3s 28ms/step - loss: 2.3418 - accuracy: 0.2947 - val_loss: 1.9913 - val_accuracy: 0.3612\n",
            "Epoch 91/200\n",
            "109/109 [==============================] - 3s 28ms/step - loss: 2.0425 - accuracy: 0.3498 - val_loss: 1.8304 - val_accuracy: 0.4025\n",
            "Epoch 92/200\n",
            "109/109 [==============================] - 3s 28ms/step - loss: 1.9512 - accuracy: 0.3739 - val_loss: 1.7478 - val_accuracy: 0.4369\n",
            "Epoch 93/200\n",
            "109/109 [==============================] - 4s 37ms/step - loss: 1.8736 - accuracy: 0.3911 - val_loss: 1.7004 - val_accuracy: 0.4530\n",
            "Epoch 94/200\n",
            "109/109 [==============================] - 3s 28ms/step - loss: 1.9157 - accuracy: 0.3956 - val_loss: 1.8133 - val_accuracy: 0.3888\n",
            "Epoch 95/200\n",
            "109/109 [==============================] - 3s 28ms/step - loss: 1.9115 - accuracy: 0.3658 - val_loss: 1.6722 - val_accuracy: 0.4576\n",
            "Epoch 96/200\n",
            "109/109 [==============================] - 3s 32ms/step - loss: 1.8261 - accuracy: 0.4312 - val_loss: 1.6853 - val_accuracy: 0.4553\n",
            "Epoch 97/200\n",
            "109/109 [==============================] - 4s 36ms/step - loss: 1.8565 - accuracy: 0.4117 - val_loss: 1.6644 - val_accuracy: 0.4725\n",
            "Epoch 98/200\n",
            "109/109 [==============================] - 3s 28ms/step - loss: 1.8261 - accuracy: 0.4083 - val_loss: 1.6740 - val_accuracy: 0.4530\n",
            "Epoch 99/200\n",
            "109/109 [==============================] - 3s 28ms/step - loss: 1.8224 - accuracy: 0.4071 - val_loss: 1.6754 - val_accuracy: 0.4427\n",
            "Epoch 100/200\n",
            "109/109 [==============================] - 4s 34ms/step - loss: 1.7856 - accuracy: 0.4174 - val_loss: 1.7527 - val_accuracy: 0.4151\n",
            "Epoch 101/200\n",
            "109/109 [==============================] - 3s 31ms/step - loss: 1.7877 - accuracy: 0.4128 - val_loss: 1.6331 - val_accuracy: 0.4656\n",
            "Epoch 102/200\n",
            "109/109 [==============================] - 3s 28ms/step - loss: 1.9887 - accuracy: 0.4186 - val_loss: 5.1461 - val_accuracy: 0.1112\n",
            "Epoch 103/200\n",
            "109/109 [==============================] - 3s 28ms/step - loss: 3.6040 - accuracy: 0.1239 - val_loss: 3.2936 - val_accuracy: 0.1640\n",
            "Epoch 104/200\n",
            "109/109 [==============================] - 4s 33ms/step - loss: 3.3919 - accuracy: 0.1250 - val_loss: 3.2427 - val_accuracy: 0.1651\n",
            "Epoch 105/200\n",
            "109/109 [==============================] - 3s 31ms/step - loss: 3.3219 - accuracy: 0.1296 - val_loss: 3.1950 - val_accuracy: 0.1743\n",
            "Epoch 106/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 3.2768 - accuracy: 0.1353 - val_loss: 3.1994 - val_accuracy: 0.1709\n",
            "Epoch 107/200\n",
            "109/109 [==============================] - 3s 28ms/step - loss: 3.2988 - accuracy: 0.1319 - val_loss: 3.2091 - val_accuracy: 0.1720\n",
            "Epoch 108/200\n",
            "109/109 [==============================] - 4s 36ms/step - loss: 3.2779 - accuracy: 0.1296 - val_loss: 3.1620 - val_accuracy: 0.1709\n",
            "Epoch 109/200\n",
            "109/109 [==============================] - 3s 28ms/step - loss: 3.2629 - accuracy: 0.1261 - val_loss: 3.1837 - val_accuracy: 0.1709\n",
            "Epoch 110/200\n",
            "109/109 [==============================] - 3s 29ms/step - loss: 3.2788 - accuracy: 0.1330 - val_loss: 3.1373 - val_accuracy: 0.1606\n",
            "Epoch 111/200\n",
            "109/109 [==============================] - 3s 28ms/step - loss: 3.2505 - accuracy: 0.1399 - val_loss: 3.1502 - val_accuracy: 0.1342\n",
            "Epoch 112/200\n",
            "109/109 [==============================] - 4s 37ms/step - loss: 3.2400 - accuracy: 0.1399 - val_loss: 3.1176 - val_accuracy: 0.1709\n",
            "Epoch 113/200\n",
            "109/109 [==============================] - 3s 31ms/step - loss: 3.2627 - accuracy: 0.1342 - val_loss: 3.1040 - val_accuracy: 0.1709\n",
            "Epoch 114/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 3.2187 - accuracy: 0.1399 - val_loss: 3.0827 - val_accuracy: 0.1663\n",
            "Epoch 115/200\n",
            "109/109 [==============================] - 5s 42ms/step - loss: 3.2158 - accuracy: 0.1307 - val_loss: 3.0808 - val_accuracy: 0.1720\n",
            "Epoch 116/200\n",
            "109/109 [==============================] - 4s 39ms/step - loss: 3.2064 - accuracy: 0.1342 - val_loss: 3.0572 - val_accuracy: 0.1743\n",
            "Epoch 117/200\n",
            "109/109 [==============================] - 4s 40ms/step - loss: 3.1687 - accuracy: 0.1514 - val_loss: 3.0376 - val_accuracy: 0.1640\n",
            "Epoch 118/200\n",
            "109/109 [==============================] - 6s 52ms/step - loss: 3.1526 - accuracy: 0.1502 - val_loss: 3.0189 - val_accuracy: 0.1720\n",
            "Epoch 119/200\n",
            "109/109 [==============================] - 3s 32ms/step - loss: 3.1428 - accuracy: 0.1548 - val_loss: 2.9972 - val_accuracy: 0.1755\n",
            "Epoch 120/200\n",
            "109/109 [==============================] - 3s 31ms/step - loss: 3.1100 - accuracy: 0.1651 - val_loss: 2.9578 - val_accuracy: 0.1709\n",
            "Epoch 121/200\n",
            "109/109 [==============================] - 4s 32ms/step - loss: 3.0956 - accuracy: 0.1583 - val_loss: 2.9149 - val_accuracy: 0.2225\n",
            "Epoch 122/200\n",
            "109/109 [==============================] - 5s 49ms/step - loss: 3.0611 - accuracy: 0.1617 - val_loss: 2.8756 - val_accuracy: 0.2248\n",
            "Epoch 123/200\n",
            "109/109 [==============================] - 3s 31ms/step - loss: 3.0150 - accuracy: 0.1743 - val_loss: 2.8405 - val_accuracy: 0.2225\n",
            "Epoch 124/200\n",
            "109/109 [==============================] - 3s 31ms/step - loss: 2.9586 - accuracy: 0.1778 - val_loss: 2.8041 - val_accuracy: 0.2156\n",
            "Epoch 125/200\n",
            "109/109 [==============================] - 4s 39ms/step - loss: 2.9719 - accuracy: 0.1617 - val_loss: 2.7671 - val_accuracy: 0.2213\n",
            "Epoch 126/200\n",
            "109/109 [==============================] - 3s 31ms/step - loss: 2.9716 - accuracy: 0.1686 - val_loss: 2.7604 - val_accuracy: 0.2213\n",
            "Epoch 127/200\n",
            "109/109 [==============================] - 3s 31ms/step - loss: 2.9490 - accuracy: 0.1755 - val_loss: 2.7343 - val_accuracy: 0.2213\n",
            "Epoch 128/200\n",
            "109/109 [==============================] - 4s 34ms/step - loss: 2.8872 - accuracy: 0.1789 - val_loss: 2.7027 - val_accuracy: 0.2156\n",
            "Epoch 129/200\n",
            "109/109 [==============================] - 5s 42ms/step - loss: 2.9024 - accuracy: 0.1835 - val_loss: 2.6832 - val_accuracy: 0.2271\n",
            "Epoch 130/200\n",
            "109/109 [==============================] - 5s 43ms/step - loss: 2.9146 - accuracy: 0.1732 - val_loss: 2.6705 - val_accuracy: 0.2259\n",
            "Epoch 131/200\n",
            "109/109 [==============================] - 4s 39ms/step - loss: 2.8364 - accuracy: 0.1823 - val_loss: 2.6513 - val_accuracy: 0.2546\n",
            "Epoch 132/200\n",
            "109/109 [==============================] - 4s 33ms/step - loss: 2.9689 - accuracy: 0.1835 - val_loss: 2.7232 - val_accuracy: 0.2156\n",
            "Epoch 133/200\n",
            "109/109 [==============================] - 3s 31ms/step - loss: 2.8682 - accuracy: 0.1915 - val_loss: 2.6904 - val_accuracy: 0.2133\n",
            "Epoch 134/200\n",
            "109/109 [==============================] - 4s 37ms/step - loss: 2.8661 - accuracy: 0.1881 - val_loss: 2.6319 - val_accuracy: 0.2339\n",
            "Epoch 135/200\n",
            "109/109 [==============================] - 4s 38ms/step - loss: 2.8307 - accuracy: 0.1881 - val_loss: 2.6292 - val_accuracy: 0.2271\n",
            "Epoch 136/200\n",
            "109/109 [==============================] - 3s 31ms/step - loss: 2.8373 - accuracy: 0.1927 - val_loss: 2.5958 - val_accuracy: 0.2259\n",
            "Epoch 137/200\n",
            "109/109 [==============================] - 3s 31ms/step - loss: 2.7943 - accuracy: 0.1961 - val_loss: 2.5573 - val_accuracy: 0.2271\n",
            "Epoch 138/200\n",
            "109/109 [==============================] - 5s 42ms/step - loss: 2.7765 - accuracy: 0.2018 - val_loss: 2.5861 - val_accuracy: 0.2339\n",
            "Epoch 139/200\n",
            "109/109 [==============================] - 4s 39ms/step - loss: 2.7730 - accuracy: 0.1927 - val_loss: 2.5453 - val_accuracy: 0.2248\n",
            "Epoch 140/200\n",
            "109/109 [==============================] - 4s 37ms/step - loss: 2.7363 - accuracy: 0.1823 - val_loss: 2.5613 - val_accuracy: 0.2454\n",
            "Epoch 141/200\n",
            "109/109 [==============================] - 5s 41ms/step - loss: 2.8212 - accuracy: 0.1938 - val_loss: 2.5708 - val_accuracy: 0.2374\n",
            "Epoch 142/200\n",
            "109/109 [==============================] - 4s 38ms/step - loss: 2.7484 - accuracy: 0.2030 - val_loss: 2.5370 - val_accuracy: 0.2282\n",
            "Epoch 143/200\n",
            "109/109 [==============================] - 3s 31ms/step - loss: 2.7013 - accuracy: 0.2259 - val_loss: 2.4692 - val_accuracy: 0.2385\n",
            "Epoch 144/200\n",
            "109/109 [==============================] - 4s 40ms/step - loss: 2.6621 - accuracy: 0.2076 - val_loss: 2.4114 - val_accuracy: 0.2775\n",
            "Epoch 145/200\n",
            "109/109 [==============================] - 4s 33ms/step - loss: 2.6128 - accuracy: 0.2397 - val_loss: 2.4203 - val_accuracy: 0.2466\n",
            "Epoch 146/200\n",
            "109/109 [==============================] - 4s 39ms/step - loss: 2.6108 - accuracy: 0.2431 - val_loss: 2.3966 - val_accuracy: 0.2729\n",
            "Epoch 147/200\n",
            "109/109 [==============================] - 4s 38ms/step - loss: 2.6011 - accuracy: 0.2190 - val_loss: 2.3651 - val_accuracy: 0.2706\n",
            "Epoch 148/200\n",
            "109/109 [==============================] - 4s 35ms/step - loss: 2.5263 - accuracy: 0.2339 - val_loss: 2.3109 - val_accuracy: 0.2718\n",
            "Epoch 149/200\n",
            "109/109 [==============================] - 4s 40ms/step - loss: 2.5216 - accuracy: 0.2477 - val_loss: 2.3264 - val_accuracy: 0.2982\n",
            "Epoch 150/200\n",
            "109/109 [==============================] - 4s 40ms/step - loss: 2.4763 - accuracy: 0.2615 - val_loss: 2.2647 - val_accuracy: 0.2764\n",
            "Epoch 151/200\n",
            "109/109 [==============================] - 4s 35ms/step - loss: 2.5054 - accuracy: 0.2477 - val_loss: 2.3091 - val_accuracy: 0.2420\n",
            "Epoch 152/200\n",
            "109/109 [==============================] - 4s 37ms/step - loss: 2.4953 - accuracy: 0.2374 - val_loss: 2.2601 - val_accuracy: 0.3028\n",
            "Epoch 153/200\n",
            "109/109 [==============================] - 4s 37ms/step - loss: 2.4495 - accuracy: 0.2523 - val_loss: 2.2318 - val_accuracy: 0.2878\n",
            "Epoch 154/200\n",
            "109/109 [==============================] - 5s 41ms/step - loss: 2.4265 - accuracy: 0.2454 - val_loss: 2.2156 - val_accuracy: 0.3005\n",
            "Epoch 155/200\n",
            "109/109 [==============================] - 3s 31ms/step - loss: 2.4021 - accuracy: 0.2695 - val_loss: 2.2326 - val_accuracy: 0.2798\n",
            "Epoch 156/200\n",
            "109/109 [==============================] - 4s 38ms/step - loss: 2.4032 - accuracy: 0.2466 - val_loss: 2.1975 - val_accuracy: 0.2901\n",
            "Epoch 157/200\n",
            "109/109 [==============================] - 4s 40ms/step - loss: 2.3619 - accuracy: 0.2706 - val_loss: 2.1584 - val_accuracy: 0.2867\n",
            "Epoch 158/200\n",
            "109/109 [==============================] - 3s 32ms/step - loss: 2.3831 - accuracy: 0.2431 - val_loss: 2.2310 - val_accuracy: 0.2993\n",
            "Epoch 159/200\n",
            "109/109 [==============================] - 3s 31ms/step - loss: 2.3992 - accuracy: 0.2546 - val_loss: 2.1735 - val_accuracy: 0.3119\n",
            "Epoch 160/200\n",
            "109/109 [==============================] - 4s 41ms/step - loss: 2.3588 - accuracy: 0.2477 - val_loss: 2.2106 - val_accuracy: 0.3050\n",
            "Epoch 161/200\n",
            "109/109 [==============================] - 4s 37ms/step - loss: 2.4060 - accuracy: 0.2626 - val_loss: 2.1406 - val_accuracy: 0.3062\n",
            "Epoch 162/200\n",
            "109/109 [==============================] - 4s 35ms/step - loss: 2.3636 - accuracy: 0.2867 - val_loss: 2.2395 - val_accuracy: 0.3119\n",
            "Epoch 163/200\n",
            "109/109 [==============================] - 4s 36ms/step - loss: 2.3824 - accuracy: 0.2546 - val_loss: 2.1386 - val_accuracy: 0.2947\n",
            "Epoch 164/200\n",
            "109/109 [==============================] - 4s 35ms/step - loss: 2.3407 - accuracy: 0.2741 - val_loss: 2.1177 - val_accuracy: 0.3108\n",
            "Epoch 165/200\n",
            "109/109 [==============================] - 3s 31ms/step - loss: 2.3288 - accuracy: 0.2615 - val_loss: 2.1084 - val_accuracy: 0.3108\n",
            "Epoch 166/200\n",
            "109/109 [==============================] - 3s 32ms/step - loss: 2.3318 - accuracy: 0.2569 - val_loss: 2.1427 - val_accuracy: 0.3200\n",
            "Epoch 167/200\n",
            "109/109 [==============================] - 4s 40ms/step - loss: 2.3109 - accuracy: 0.2477 - val_loss: 2.0863 - val_accuracy: 0.3131\n",
            "Epoch 168/200\n",
            "109/109 [==============================] - 3s 31ms/step - loss: 2.3012 - accuracy: 0.2603 - val_loss: 2.1972 - val_accuracy: 0.2959\n",
            "Epoch 169/200\n",
            "109/109 [==============================] - 4s 37ms/step - loss: 2.3184 - accuracy: 0.2683 - val_loss: 2.1299 - val_accuracy: 0.2936\n",
            "Epoch 170/200\n",
            "109/109 [==============================] - 4s 41ms/step - loss: 2.3159 - accuracy: 0.2546 - val_loss: 2.0774 - val_accuracy: 0.2982\n",
            "Epoch 171/200\n",
            "109/109 [==============================] - 4s 36ms/step - loss: 2.2823 - accuracy: 0.2695 - val_loss: 2.4534 - val_accuracy: 0.2798\n",
            "Epoch 172/200\n",
            "109/109 [==============================] - 3s 31ms/step - loss: 2.3785 - accuracy: 0.2557 - val_loss: 2.0934 - val_accuracy: 0.3119\n",
            "Epoch 173/200\n",
            "109/109 [==============================] - 4s 37ms/step - loss: 2.2918 - accuracy: 0.2798 - val_loss: 2.0457 - val_accuracy: 0.3268\n",
            "Epoch 174/200\n",
            "109/109 [==============================] - 4s 38ms/step - loss: 2.2469 - accuracy: 0.2638 - val_loss: 2.0537 - val_accuracy: 0.3050\n",
            "Epoch 175/200\n",
            "109/109 [==============================] - 3s 31ms/step - loss: 2.2460 - accuracy: 0.2752 - val_loss: 2.0328 - val_accuracy: 0.3245\n",
            "Epoch 176/200\n",
            "109/109 [==============================] - 4s 37ms/step - loss: 2.2276 - accuracy: 0.2913 - val_loss: 2.2844 - val_accuracy: 0.2718\n",
            "Epoch 177/200\n",
            "109/109 [==============================] - 4s 40ms/step - loss: 2.2818 - accuracy: 0.2901 - val_loss: 2.0434 - val_accuracy: 0.2959\n",
            "Epoch 178/200\n",
            "109/109 [==============================] - 4s 38ms/step - loss: 2.2113 - accuracy: 0.2741 - val_loss: 2.0166 - val_accuracy: 0.3268\n",
            "Epoch 179/200\n",
            "109/109 [==============================] - 4s 38ms/step - loss: 2.2136 - accuracy: 0.2718 - val_loss: 2.0206 - val_accuracy: 0.3337\n",
            "Epoch 180/200\n",
            "109/109 [==============================] - 5s 46ms/step - loss: 2.1701 - accuracy: 0.2867 - val_loss: 2.0000 - val_accuracy: 0.3291\n",
            "Epoch 181/200\n",
            "109/109 [==============================] - 4s 37ms/step - loss: 2.2515 - accuracy: 0.2741 - val_loss: 2.2723 - val_accuracy: 0.2752\n",
            "Epoch 182/200\n",
            "109/109 [==============================] - 4s 32ms/step - loss: 2.2671 - accuracy: 0.2821 - val_loss: 2.0492 - val_accuracy: 0.3050\n",
            "Epoch 183/200\n",
            "109/109 [==============================] - 5s 44ms/step - loss: 2.1958 - accuracy: 0.2787 - val_loss: 2.0326 - val_accuracy: 0.3314\n",
            "Epoch 184/200\n",
            "109/109 [==============================] - 4s 38ms/step - loss: 2.1950 - accuracy: 0.2718 - val_loss: 1.9725 - val_accuracy: 0.3360\n",
            "Epoch 185/200\n",
            "109/109 [==============================] - 4s 38ms/step - loss: 2.1877 - accuracy: 0.3050 - val_loss: 1.9549 - val_accuracy: 0.3165\n",
            "Epoch 186/200\n",
            "109/109 [==============================] - 5s 48ms/step - loss: 2.1578 - accuracy: 0.2936 - val_loss: 1.9619 - val_accuracy: 0.3234\n",
            "Epoch 187/200\n",
            "109/109 [==============================] - 4s 37ms/step - loss: 2.1510 - accuracy: 0.2867 - val_loss: 1.9676 - val_accuracy: 0.3073\n",
            "Epoch 188/200\n",
            "109/109 [==============================] - 4s 37ms/step - loss: 2.1950 - accuracy: 0.2901 - val_loss: 1.9864 - val_accuracy: 0.2844\n",
            "Epoch 189/200\n",
            "109/109 [==============================] - 4s 40ms/step - loss: 2.1451 - accuracy: 0.3062 - val_loss: 1.9470 - val_accuracy: 0.2936\n",
            "Epoch 190/200\n",
            "109/109 [==============================] - 3s 31ms/step - loss: 2.1542 - accuracy: 0.2856 - val_loss: 2.0335 - val_accuracy: 0.2798\n",
            "Epoch 191/200\n",
            "109/109 [==============================] - 4s 37ms/step - loss: 2.1423 - accuracy: 0.2741 - val_loss: 1.9626 - val_accuracy: 0.3268\n",
            "Epoch 192/200\n",
            "109/109 [==============================] - 4s 36ms/step - loss: 2.1350 - accuracy: 0.2913 - val_loss: 1.9342 - val_accuracy: 0.3394\n",
            "Epoch 193/200\n",
            "109/109 [==============================] - 4s 39ms/step - loss: 2.1065 - accuracy: 0.2936 - val_loss: 1.9160 - val_accuracy: 0.3337\n",
            "Epoch 194/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 2.1052 - accuracy: 0.2936 - val_loss: 1.9030 - val_accuracy: 0.3280\n",
            "Epoch 195/200\n",
            "109/109 [==============================] - 4s 33ms/step - loss: 2.0997 - accuracy: 0.2993 - val_loss: 1.9576 - val_accuracy: 0.2821\n",
            "Epoch 196/200\n",
            "109/109 [==============================] - 4s 38ms/step - loss: 2.0902 - accuracy: 0.2970 - val_loss: 1.8948 - val_accuracy: 0.3394\n",
            "Epoch 197/200\n",
            "109/109 [==============================] - 3s 29ms/step - loss: 2.0944 - accuracy: 0.2867 - val_loss: 1.9054 - val_accuracy: 0.3280\n",
            "Epoch 198/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 2.0917 - accuracy: 0.3028 - val_loss: 1.8970 - val_accuracy: 0.3257\n",
            "Epoch 199/200\n",
            "109/109 [==============================] - 4s 40ms/step - loss: 2.0841 - accuracy: 0.2890 - val_loss: 1.8650 - val_accuracy: 0.3406\n",
            "Epoch 200/200\n",
            "109/109 [==============================] - 3s 30ms/step - loss: 2.1019 - accuracy: 0.3016 - val_loss: 1.8873 - val_accuracy: 0.3440\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Load the intents file\n",
        "with open('intents.json', 'r') as f:\n",
        "    intents = json.load(f)\n",
        "\n",
        "# Extract the patterns and their tags\n",
        "patterns = []\n",
        "tags = []\n",
        "for intent in intents['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        patterns.append(pattern.lower())\n",
        "        tags.append(intent['tag'])\n",
        "\n",
        "# Tokenize the patterns\n",
        "word_tokens = []\n",
        "for pattern in patterns:\n",
        "    word_tokens.append(nltk.word_tokenize(pattern))\n",
        "\n",
        "# Lemmatize the words and remove duplicates\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "words = set()\n",
        "for tokens in word_tokens:\n",
        "    words.update([lemmatizer.lemmatize(w.lower()) for w in tokens if w.isalpha()])\n",
        "\n",
        "# Create a dictionary to map words to integers\n",
        "word_dict = {}\n",
        "for i, word in enumerate(words):\n",
        "    word_dict[word] = i + 1\n",
        "\n",
        "# Create a dictionary to map tags to integers\n",
        "tag_dict = {}\n",
        "for i, tag in enumerate(set(tags)):\n",
        "    tag_dict[tag] = i\n",
        "\n",
        "# Convert patterns and tags to integer sequences\n",
        "pattern_sequences = []\n",
        "tag_sequences = []\n",
        "for i, tokens in enumerate(word_tokens):\n",
        "    pattern_sequence = [word_dict[lemmatizer.lemmatize(w.lower())] for w in tokens if w.isalpha()]\n",
        "    pattern_sequences.append(pattern_sequence)\n",
        "    tag_sequences.append(tag_dict[tags[i]])\n",
        "\n",
        "# Pad pattern sequences to ensure they are all the same length\n",
        "max_len = max([len(seq) for seq in pattern_sequences])\n",
        "padded_pattern_sequences = pad_sequences(pattern_sequences, padding='post', maxlen=max_len)\n",
        "\n",
        "# Convert tag sequences to one-hot encoding\n",
        "tag_one_hot = keras.utils.to_categorical(tag_sequences)\n",
        "\n",
        "# Define the model\n",
        "input_layer = Input(shape=(max_len,))\n",
        "embedding_layer = Embedding(len(word_dict) + 1, 128, input_length=max_len)(input_layer)\n",
        "lstm_layer = LSTM(128)(embedding_layer)\n",
        "dropout_layer = Dropout(0.5)(lstm_layer)\n",
        "output_layer = Dense(len(tag_dict), activation='softmax')(dropout_layer)\n",
        "model = Model(inputs=[input_layer], outputs=[output_layer])\n",
        "\n",
        "# Compile the model\n",
        "sgd = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# Load the test data\n",
        "with open('intents_testing.json', 'r') as f:\n",
        "    intents_testing = json.load(f)\n",
        "\n",
        "# Extract the patterns and their tags\n",
        "patterns_testing = []\n",
        "tags_testing = []\n",
        "for intent in intents_testing['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        patterns_testing.append(pattern.lower())\n",
        "        tags_testing.append(intent['tag'])\n",
        "\n",
        "# Tokenize the patterns\n",
        "word_tokens_testing = []\n",
        "for pattern in patterns_testing:\n",
        "    word_tokens_testing.append(nltk.word_tokenize(pattern))\n",
        "\n",
        "# Convert patterns and tags to integer sequences\n",
        "pattern_sequences_testing = []\n",
        "tag_sequences_testing = []\n",
        "for i, tokens in enumerate(word_tokens_testing):\n",
        "    pattern_sequence_testing = [word_dict.get(lemmatizer.lemmatize(w.lower()), 0) for w in tokens if w.isalpha()]\n",
        "    pattern_sequences_testing.append(pattern_sequence_testing)\n",
        "    tag_sequences_testing.append(tag_dict[tags_testing[i]])\n",
        "\n",
        "# Pad pattern sequences to ensure they are all the same length\n",
        "padded_pattern_sequences_testing = pad_sequences(pattern_sequences_testing, padding='post', maxlen=max_len)\n",
        "\n",
        "# Convert tag sequences to one-hot encoding\n",
        "tag_one_hot_testing = keras.utils.to_categorical(tag_sequences_testing)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNYWh9_9jwFb",
        "outputId": "f3ab72a4-db33-45e4-c6de-0d54f78dc149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 3.500, accuracy: 0.105\n",
            "3/3 [==============================] - 1s 13ms/step\n",
            "Precision: 0.039, recall: 0.105, F1-score: 0.051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist=model.fit(padded_pattern_sequences, tag_one_hot,validation_data=(padded_pattern_sequences_testing, tag_one_hot_testing), epochs=200, batch_size=8)\n"
      ],
      "metadata": {
        "id": "7Dw7PnJWsxO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate the model on test set\n",
        "loss, accuracy = model.evaluate(padded_pattern_sequences_testing, tag_one_hot_testing, verbose=0)\n",
        "print(f'Test loss: {loss:.3f}, accuracy: {accuracy:.3f}')\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "y_true = np.argmax(tag_one_hot_testing, axis=1)\n",
        "y_pred = np.argmax(model.predict(padded_pattern_sequences_testing), axis=1)\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
        "print(f'Precision: {precision:.3f}, recall: {recall:.3f}, F1-score: {f1_score:.3f}')"
      ],
      "metadata": {
        "id": "KmcPmII0suoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Generate predictions on the training data\n",
        "train_pred = np.argmax(model.predict(padded_pattern_sequences), axis=1)\n",
        "\n",
        "# Convert one-hot encoded predictions to tag sequences\n",
        "# train_pred_tags = [tag_dict[idx] for idx in np.argmax(train_pred, axis=1)]\n",
        "\n",
        "# Compute metrics\n",
        "train_report = classification_report(tag_sequences, train_pred)\n",
        "\n",
        "print(\"Training data metrics:\\n\", train_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAyDKtN5o18m",
        "outputId": "5bb6755b-c044-4e9c-a957-134b3bc5a02f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28/28 [==============================] - 0s 15ms/step\n",
            "Training data metrics:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.94      0.65        94\n",
            "           1       0.00      0.00      0.00        19\n",
            "           2       0.00      0.00      0.00        13\n",
            "           3       0.00      0.00      0.00        11\n",
            "           4       0.00      0.00      0.00         9\n",
            "           5       0.00      0.00      0.00        10\n",
            "           6       0.00      0.00      0.00        13\n",
            "           7       0.00      0.00      0.00        11\n",
            "           8       0.00      0.00      0.00        11\n",
            "           9       0.40      0.04      0.07        52\n",
            "          10       0.19      0.10      0.13        42\n",
            "          11       0.00      0.00      0.00        11\n",
            "          12       0.00      0.00      0.00         6\n",
            "          13       0.23      0.87      0.36        38\n",
            "          14       0.00      0.00      0.00        20\n",
            "          15       0.00      0.00      0.00        11\n",
            "          16       0.00      0.00      0.00        11\n",
            "          17       0.31      1.00      0.47        24\n",
            "          18       0.06      0.25      0.09        16\n",
            "          19       0.27      0.19      0.22        16\n",
            "          20       0.00      0.00      0.00        16\n",
            "          21       0.00      0.00      0.00        17\n",
            "          22       0.60      0.94      0.73        64\n",
            "          23       0.30      0.92      0.46        36\n",
            "          24       0.00      0.00      0.00        21\n",
            "          25       0.00      0.00      0.00        10\n",
            "          26       1.00      0.08      0.14        13\n",
            "          27       0.21      1.00      0.34        25\n",
            "          28       0.00      0.00      0.00        26\n",
            "          29       0.00      0.00      0.00        13\n",
            "          30       0.20      0.05      0.08        20\n",
            "          31       0.00      0.00      0.00        12\n",
            "          32       0.00      0.00      0.00         9\n",
            "          33       0.00      0.00      0.00         9\n",
            "          34       0.00      0.00      0.00        10\n",
            "          35       0.00      0.00      0.00        20\n",
            "          36       0.00      0.00      0.00        20\n",
            "          37       0.81      0.52      0.64        42\n",
            "          38       0.00      0.00      0.00        24\n",
            "          39       0.00      0.00      0.00        27\n",
            "\n",
            "    accuracy                           0.34       872\n",
            "   macro avg       0.13      0.17      0.11       872\n",
            "weighted avg       0.23      0.34      0.23       872\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the training and validation accuracy over time\n",
        "plt.plot(hist.history['accuracy'], label='Training accuracy')\n",
        "plt.plot(hist.history['val_accuracy'], label='Validation accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "o_NKpDF2qAy5",
        "outputId": "185248d8-b898-42c0-809b-2faed6bf77e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training and validation loss over time\n",
        "plt.plot(hist.history['loss'], label='Training loss')\n",
        "plt.plot(hist.history['val_loss'], label='Validation loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "bsedvB5_r_sj",
        "outputId": "01e72f5b-e4b8-488a-ec77-371a17c3f013"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fc9b3caa490>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "confusion_matrix = tf.math.confusion_matrix(y_true, y_pred, num_classes=len(tag_dict)).numpy()\n",
        "\n",
        "# Get the indices for true positive, true negative, false positive, and false negative\n",
        "tp_idx = np.diag(confusion_matrix)\n",
        "tn_idx = np.diag(np.fliplr(confusion_matrix))\n",
        "fp_idx = np.sum(confusion_matrix, axis=0) - tp_idx\n",
        "fn_idx = np.sum(confusion_matrix, axis=1) - tp_idx\n",
        "\n",
        "# Compute true positive, true negative, false positive, and false negative\n",
        "tp = np.sum(tp_idx)\n",
        "tn = np.sum(tn_idx)\n",
        "fp = np.sum(fp_idx)\n",
        "fn = np.sum(fn_idx)\n",
        "\n",
        "print('True positives:', tp)\n",
        "print('True negatives:', tn)\n",
        "print('False positives:', fp)\n",
        "print('False negatives:', fn)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQ1cQg1ovS8O",
        "outputId": "f4050bf7-f6ab-4e04-e7c8-9a5f28fa7f09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True positives: 8\n",
            "True negatives: 3\n",
            "False positives: 68\n",
            "False negatives: 68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Convert tag sequences to integer labels\n",
        "tag_labels = np.argmax(tag_one_hot, axis=1)\n",
        "\n",
        "# Define the cross-validation object\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform cross-validation\n",
        "scores = []\n",
        "for train_idx, test_idx in cv.split(padded_pattern_sequences, tag_labels):\n",
        "    # Split data into training and test sets\n",
        "    X_train, X_test = padded_pattern_sequences[train_idx], padded_pattern_sequences[test_idx]\n",
        "    y_train, y_test = tag_one_hot[train_idx], tag_one_hot[test_idx]\n",
        "\n",
        "    # Define the model\n",
        "    input_layer = Input(shape=(max_len,))\n",
        "    embedding_layer = Embedding(len(word_dict) + 1, 128, input_length=max_len)(input_layer)\n",
        "    lstm_layer = LSTM(128)(embedding_layer)\n",
        "    dropout_layer = Dropout(0.5)(lstm_layer)\n",
        "    output_layer = Dense(len(tag_dict), activation='softmax')(dropout_layer)\n",
        "    model = Model(inputs=[input_layer], outputs=[output_layer])\n",
        "\n",
        "    # Compile the model\n",
        "    sgd = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200, batch_size=8)\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    score = model.evaluate(X_test, y_test)[1]\n",
        "    scores.append(score)\n",
        "\n",
        "# Compute the mean and standard deviation of the scores\n",
        "mean_score = np.mean(scores)\n",
        "std_score = np.std(scores)\n",
        "print(\"Cross-validation accuracy: {:.2f} +/- {:.2f}\".format(mean_score, std_score))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIgX2n6MDOhO",
        "outputId": "68b43ce8-f090-4fb5-da06-384796392a80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "88/88 [==============================] - 6s 39ms/step - loss: 3.6003 - accuracy: 0.0832 - val_loss: 3.4986 - val_accuracy: 0.0743\n",
            "Epoch 2/200\n",
            "88/88 [==============================] - 2s 26ms/step - loss: 3.5324 - accuracy: 0.0818 - val_loss: 3.4848 - val_accuracy: 0.1086\n",
            "Epoch 3/200\n",
            "88/88 [==============================] - 2s 26ms/step - loss: 3.5151 - accuracy: 0.1047 - val_loss: 3.4726 - val_accuracy: 0.1086\n",
            "Epoch 4/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 3.5080 - accuracy: 0.1033 - val_loss: 3.4696 - val_accuracy: 0.1086\n",
            "Epoch 5/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.5057 - accuracy: 0.1004 - val_loss: 3.4692 - val_accuracy: 0.1086\n",
            "Epoch 6/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4963 - accuracy: 0.1019 - val_loss: 3.4640 - val_accuracy: 0.1086\n",
            "Epoch 7/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 3.4955 - accuracy: 0.0990 - val_loss: 3.4708 - val_accuracy: 0.1086\n",
            "Epoch 8/200\n",
            "88/88 [==============================] - 2s 26ms/step - loss: 3.5017 - accuracy: 0.1062 - val_loss: 3.4684 - val_accuracy: 0.1086\n",
            "Epoch 9/200\n",
            "88/88 [==============================] - 2s 26ms/step - loss: 3.4988 - accuracy: 0.1019 - val_loss: 3.4661 - val_accuracy: 0.1086\n",
            "Epoch 10/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4872 - accuracy: 0.1062 - val_loss: 3.4652 - val_accuracy: 0.1086\n",
            "Epoch 11/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4882 - accuracy: 0.1076 - val_loss: 3.4667 - val_accuracy: 0.1086\n",
            "Epoch 12/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4805 - accuracy: 0.1090 - val_loss: 3.4644 - val_accuracy: 0.1086\n",
            "Epoch 13/200\n",
            "88/88 [==============================] - 2s 26ms/step - loss: 3.4886 - accuracy: 0.1133 - val_loss: 3.4686 - val_accuracy: 0.1086\n",
            "Epoch 14/200\n",
            "88/88 [==============================] - 2s 26ms/step - loss: 3.4844 - accuracy: 0.1076 - val_loss: 3.4656 - val_accuracy: 0.1086\n",
            "Epoch 15/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 3.4790 - accuracy: 0.1062 - val_loss: 3.4637 - val_accuracy: 0.1086\n",
            "Epoch 16/200\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 3.4839 - accuracy: 0.1090 - val_loss: 3.4625 - val_accuracy: 0.1086\n",
            "Epoch 17/200\n",
            "88/88 [==============================] - 2s 26ms/step - loss: 3.4890 - accuracy: 0.1076 - val_loss: 3.4618 - val_accuracy: 0.1086\n",
            "Epoch 18/200\n",
            "88/88 [==============================] - 2s 25ms/step - loss: 3.4823 - accuracy: 0.1019 - val_loss: 3.4627 - val_accuracy: 0.1086\n",
            "Epoch 19/200\n",
            "88/88 [==============================] - 2s 25ms/step - loss: 3.4791 - accuracy: 0.1076 - val_loss: 3.4636 - val_accuracy: 0.1086\n",
            "Epoch 20/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4840 - accuracy: 0.1047 - val_loss: 3.4614 - val_accuracy: 0.1086\n",
            "Epoch 21/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4731 - accuracy: 0.1090 - val_loss: 3.4678 - val_accuracy: 0.1086\n",
            "Epoch 22/200\n",
            "88/88 [==============================] - 2s 25ms/step - loss: 3.4777 - accuracy: 0.1119 - val_loss: 3.4622 - val_accuracy: 0.1086\n",
            "Epoch 23/200\n",
            "88/88 [==============================] - 2s 26ms/step - loss: 3.4853 - accuracy: 0.1062 - val_loss: 3.4623 - val_accuracy: 0.1086\n",
            "Epoch 24/200\n",
            "88/88 [==============================] - 2s 26ms/step - loss: 3.4845 - accuracy: 0.1062 - val_loss: 3.4610 - val_accuracy: 0.1086\n",
            "Epoch 25/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 3.4750 - accuracy: 0.1090 - val_loss: 3.4637 - val_accuracy: 0.1086\n",
            "Epoch 26/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4761 - accuracy: 0.1062 - val_loss: 3.4623 - val_accuracy: 0.1086\n",
            "Epoch 27/200\n",
            "88/88 [==============================] - 2s 25ms/step - loss: 3.4818 - accuracy: 0.1004 - val_loss: 3.4653 - val_accuracy: 0.1086\n",
            "Epoch 28/200\n",
            "88/88 [==============================] - 2s 25ms/step - loss: 3.4804 - accuracy: 0.1076 - val_loss: 3.4615 - val_accuracy: 0.1086\n",
            "Epoch 29/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 3.4771 - accuracy: 0.1076 - val_loss: 3.4610 - val_accuracy: 0.1086\n",
            "Epoch 30/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4757 - accuracy: 0.1076 - val_loss: 3.4619 - val_accuracy: 0.1086\n",
            "Epoch 31/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 3.4783 - accuracy: 0.1047 - val_loss: 3.4639 - val_accuracy: 0.1086\n",
            "Epoch 32/200\n",
            "88/88 [==============================] - 2s 25ms/step - loss: 3.4785 - accuracy: 0.1076 - val_loss: 3.4630 - val_accuracy: 0.1086\n",
            "Epoch 33/200\n",
            "88/88 [==============================] - 2s 26ms/step - loss: 3.4744 - accuracy: 0.1076 - val_loss: 3.4648 - val_accuracy: 0.1086\n",
            "Epoch 34/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 3.4826 - accuracy: 0.1076 - val_loss: 3.4628 - val_accuracy: 0.1086\n",
            "Epoch 35/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4705 - accuracy: 0.1076 - val_loss: 3.4628 - val_accuracy: 0.1086\n",
            "Epoch 36/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 3.4762 - accuracy: 0.1076 - val_loss: 3.4612 - val_accuracy: 0.1086\n",
            "Epoch 37/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4727 - accuracy: 0.1076 - val_loss: 3.4603 - val_accuracy: 0.1086\n",
            "Epoch 38/200\n",
            "88/88 [==============================] - 2s 25ms/step - loss: 3.4773 - accuracy: 0.1090 - val_loss: 3.4647 - val_accuracy: 0.1086\n",
            "Epoch 39/200\n",
            "88/88 [==============================] - 2s 25ms/step - loss: 3.4758 - accuracy: 0.1076 - val_loss: 3.4626 - val_accuracy: 0.1086\n",
            "Epoch 40/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4781 - accuracy: 0.1076 - val_loss: 3.4600 - val_accuracy: 0.1086\n",
            "Epoch 41/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4750 - accuracy: 0.1076 - val_loss: 3.4617 - val_accuracy: 0.1086\n",
            "Epoch 42/200\n",
            "88/88 [==============================] - 2s 26ms/step - loss: 3.4708 - accuracy: 0.1076 - val_loss: 3.4617 - val_accuracy: 0.1086\n",
            "Epoch 43/200\n",
            "88/88 [==============================] - 2s 25ms/step - loss: 3.4731 - accuracy: 0.1076 - val_loss: 3.4607 - val_accuracy: 0.1086\n",
            "Epoch 44/200\n",
            "88/88 [==============================] - 2s 25ms/step - loss: 3.4731 - accuracy: 0.1076 - val_loss: 3.4586 - val_accuracy: 0.1086\n",
            "Epoch 45/200\n",
            "88/88 [==============================] - 2s 28ms/step - loss: 3.4734 - accuracy: 0.1076 - val_loss: 3.4563 - val_accuracy: 0.1086\n",
            "Epoch 46/200\n",
            "88/88 [==============================] - 3s 35ms/step - loss: 3.4645 - accuracy: 0.1076 - val_loss: 3.4530 - val_accuracy: 0.1086\n",
            "Epoch 47/200\n",
            "88/88 [==============================] - 2s 25ms/step - loss: 3.4607 - accuracy: 0.1033 - val_loss: 3.3734 - val_accuracy: 0.1257\n",
            "Epoch 48/200\n",
            "88/88 [==============================] - 2s 25ms/step - loss: 3.4078 - accuracy: 0.1047 - val_loss: 3.3659 - val_accuracy: 0.1143\n",
            "Epoch 49/200\n",
            "88/88 [==============================] - 2s 25ms/step - loss: 3.3972 - accuracy: 0.1033 - val_loss: 3.3127 - val_accuracy: 0.1086\n",
            "Epoch 50/200\n",
            "88/88 [==============================] - 3s 35ms/step - loss: 3.3608 - accuracy: 0.1047 - val_loss: 3.2774 - val_accuracy: 0.0971\n",
            "Epoch 51/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 3.4152 - accuracy: 0.0961 - val_loss: 3.4066 - val_accuracy: 0.1314\n",
            "Epoch 52/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 3.4653 - accuracy: 0.0890 - val_loss: 3.5009 - val_accuracy: 0.1086\n",
            "Epoch 53/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 3.5302 - accuracy: 0.1004 - val_loss: 3.4804 - val_accuracy: 0.0743\n",
            "Epoch 54/200\n",
            "88/88 [==============================] - 2s 26ms/step - loss: 3.5245 - accuracy: 0.0933 - val_loss: 3.4678 - val_accuracy: 0.1086\n",
            "Epoch 55/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4983 - accuracy: 0.0976 - val_loss: 3.4686 - val_accuracy: 0.1086\n",
            "Epoch 56/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 3.5127 - accuracy: 0.0990 - val_loss: 3.4646 - val_accuracy: 0.1086\n",
            "Epoch 57/200\n",
            "88/88 [==============================] - 2s 26ms/step - loss: 3.5031 - accuracy: 0.1019 - val_loss: 3.4665 - val_accuracy: 0.1086\n",
            "Epoch 58/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 3.5035 - accuracy: 0.0990 - val_loss: 3.4684 - val_accuracy: 0.1086\n",
            "Epoch 59/200\n",
            "88/88 [==============================] - 2s 28ms/step - loss: 3.4851 - accuracy: 0.1033 - val_loss: 3.4652 - val_accuracy: 0.1086\n",
            "Epoch 60/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4887 - accuracy: 0.1076 - val_loss: 3.4636 - val_accuracy: 0.1086\n",
            "Epoch 61/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 3.4868 - accuracy: 0.1062 - val_loss: 3.4618 - val_accuracy: 0.1086\n",
            "Epoch 62/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4898 - accuracy: 0.1090 - val_loss: 3.4637 - val_accuracy: 0.1086\n",
            "Epoch 63/200\n",
            "88/88 [==============================] - 2s 26ms/step - loss: 3.4837 - accuracy: 0.1033 - val_loss: 3.4642 - val_accuracy: 0.1086\n",
            "Epoch 64/200\n",
            "88/88 [==============================] - 2s 26ms/step - loss: 3.4908 - accuracy: 0.1133 - val_loss: 3.4624 - val_accuracy: 0.1086\n",
            "Epoch 65/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4843 - accuracy: 0.1076 - val_loss: 3.4621 - val_accuracy: 0.1086\n",
            "Epoch 66/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4823 - accuracy: 0.1047 - val_loss: 3.4644 - val_accuracy: 0.1086\n",
            "Epoch 67/200\n",
            "88/88 [==============================] - 2s 26ms/step - loss: 3.4839 - accuracy: 0.1062 - val_loss: 3.4619 - val_accuracy: 0.1086\n",
            "Epoch 68/200\n",
            "88/88 [==============================] - 2s 26ms/step - loss: 3.4815 - accuracy: 0.1062 - val_loss: 3.4624 - val_accuracy: 0.1086\n",
            "Epoch 69/200\n",
            "88/88 [==============================] - 2s 26ms/step - loss: 3.4832 - accuracy: 0.1062 - val_loss: 3.4635 - val_accuracy: 0.1086\n",
            "Epoch 70/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4808 - accuracy: 0.1076 - val_loss: 3.4617 - val_accuracy: 0.1086\n",
            "Epoch 71/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 3.4826 - accuracy: 0.1076 - val_loss: 3.4622 - val_accuracy: 0.1086\n",
            "Epoch 72/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 3.4776 - accuracy: 0.1076 - val_loss: 3.4608 - val_accuracy: 0.1086\n",
            "Epoch 73/200\n",
            "88/88 [==============================] - 2s 26ms/step - loss: 3.4738 - accuracy: 0.1076 - val_loss: 3.4597 - val_accuracy: 0.1086\n",
            "Epoch 74/200\n",
            "88/88 [==============================] - 3s 28ms/step - loss: 3.4764 - accuracy: 0.1076 - val_loss: 3.4612 - val_accuracy: 0.1086\n",
            "Epoch 75/200\n",
            "88/88 [==============================] - 4s 40ms/step - loss: 3.4732 - accuracy: 0.1076 - val_loss: 3.4622 - val_accuracy: 0.1086\n",
            "Epoch 76/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 3.4719 - accuracy: 0.1076 - val_loss: 3.4624 - val_accuracy: 0.1086\n",
            "Epoch 77/200\n",
            "88/88 [==============================] - 2s 25ms/step - loss: 3.4851 - accuracy: 0.1090 - val_loss: 3.4628 - val_accuracy: 0.1086\n",
            "Epoch 78/200\n",
            "88/88 [==============================] - 2s 26ms/step - loss: 3.4797 - accuracy: 0.1076 - val_loss: 3.4628 - val_accuracy: 0.1086\n",
            "Epoch 79/200\n",
            "88/88 [==============================] - 2s 26ms/step - loss: 3.4772 - accuracy: 0.1062 - val_loss: 3.4611 - val_accuracy: 0.1086\n",
            "Epoch 80/200\n",
            "88/88 [==============================] - 3s 35ms/step - loss: 3.4802 - accuracy: 0.1076 - val_loss: 3.4604 - val_accuracy: 0.1086\n",
            "Epoch 81/200\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 3.4766 - accuracy: 0.1076 - val_loss: 3.4589 - val_accuracy: 0.1086\n",
            "Epoch 82/200\n",
            "88/88 [==============================] - 2s 26ms/step - loss: 3.4661 - accuracy: 0.1076 - val_loss: 3.4488 - val_accuracy: 0.1086\n",
            "Epoch 83/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 3.3882 - accuracy: 0.0961 - val_loss: 3.3428 - val_accuracy: 0.1086\n",
            "Epoch 84/200\n",
            "88/88 [==============================] - 2s 28ms/step - loss: 3.3422 - accuracy: 0.0961 - val_loss: 3.2578 - val_accuracy: 0.1314\n",
            "Epoch 85/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 3.3179 - accuracy: 0.1004 - val_loss: 3.2127 - val_accuracy: 0.1029\n",
            "Epoch 86/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 3.3012 - accuracy: 0.1019 - val_loss: 3.2300 - val_accuracy: 0.1143\n",
            "Epoch 87/200\n",
            "88/88 [==============================] - 4s 42ms/step - loss: 3.2377 - accuracy: 0.1047 - val_loss: 3.1668 - val_accuracy: 0.1143\n",
            "Epoch 88/200\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 3.2051 - accuracy: 0.1119 - val_loss: 3.1956 - val_accuracy: 0.0971\n",
            "Epoch 89/200\n",
            "88/88 [==============================] - 4s 44ms/step - loss: 3.2194 - accuracy: 0.1148 - val_loss: 3.1435 - val_accuracy: 0.0914\n",
            "Epoch 90/200\n",
            "88/88 [==============================] - 2s 28ms/step - loss: 3.1695 - accuracy: 0.1090 - val_loss: 3.1732 - val_accuracy: 0.0971\n",
            "Epoch 91/200\n",
            "88/88 [==============================] - 2s 28ms/step - loss: 3.1703 - accuracy: 0.1076 - val_loss: 3.0958 - val_accuracy: 0.1771\n",
            "Epoch 92/200\n",
            "88/88 [==============================] - 2s 26ms/step - loss: 3.1227 - accuracy: 0.1119 - val_loss: 3.1496 - val_accuracy: 0.0914\n",
            "Epoch 93/200\n",
            "88/88 [==============================] - 2s 28ms/step - loss: 3.0853 - accuracy: 0.1090 - val_loss: 3.1555 - val_accuracy: 0.1371\n",
            "Epoch 94/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 3.2833 - accuracy: 0.1191 - val_loss: 3.5856 - val_accuracy: 0.1086\n",
            "Epoch 95/200\n",
            "88/88 [==============================] - 2s 26ms/step - loss: 3.4876 - accuracy: 0.1019 - val_loss: 3.7853 - val_accuracy: 0.1086\n",
            "Epoch 96/200\n",
            "88/88 [==============================] - 2s 26ms/step - loss: 3.6422 - accuracy: 0.0933 - val_loss: 3.4702 - val_accuracy: 0.1086\n",
            "Epoch 97/200\n",
            "88/88 [==============================] - 2s 26ms/step - loss: 3.5175 - accuracy: 0.0976 - val_loss: 3.4685 - val_accuracy: 0.1086\n",
            "Epoch 98/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.5110 - accuracy: 0.0976 - val_loss: 3.4646 - val_accuracy: 0.1086\n",
            "Epoch 99/200\n",
            "88/88 [==============================] - 3s 38ms/step - loss: 3.4991 - accuracy: 0.1047 - val_loss: 3.4619 - val_accuracy: 0.1086\n",
            "Epoch 100/200\n",
            "88/88 [==============================] - 2s 26ms/step - loss: 3.4999 - accuracy: 0.0990 - val_loss: 3.4631 - val_accuracy: 0.1086\n",
            "Epoch 101/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 3.5043 - accuracy: 0.1033 - val_loss: 3.4635 - val_accuracy: 0.1086\n",
            "Epoch 102/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 3.4882 - accuracy: 0.1076 - val_loss: 3.4626 - val_accuracy: 0.1086\n",
            "Epoch 103/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 3.4869 - accuracy: 0.1033 - val_loss: 3.4625 - val_accuracy: 0.1086\n",
            "Epoch 104/200\n",
            "88/88 [==============================] - 3s 38ms/step - loss: 3.4759 - accuracy: 0.1076 - val_loss: 3.4619 - val_accuracy: 0.1086\n",
            "Epoch 105/200\n",
            "88/88 [==============================] - 2s 26ms/step - loss: 3.4823 - accuracy: 0.1119 - val_loss: 3.4604 - val_accuracy: 0.1086\n",
            "Epoch 106/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 3.4773 - accuracy: 0.1033 - val_loss: 3.4595 - val_accuracy: 0.1086\n",
            "Epoch 107/200\n",
            "88/88 [==============================] - 2s 26ms/step - loss: 3.4778 - accuracy: 0.1062 - val_loss: 3.4587 - val_accuracy: 0.1086\n",
            "Epoch 108/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 3.4759 - accuracy: 0.1076 - val_loss: 3.4599 - val_accuracy: 0.1086\n",
            "Epoch 109/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 3.4668 - accuracy: 0.1047 - val_loss: 3.4590 - val_accuracy: 0.1086\n",
            "Epoch 110/200\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 3.4803 - accuracy: 0.1062 - val_loss: 3.4538 - val_accuracy: 0.1086\n",
            "Epoch 111/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4643 - accuracy: 0.1090 - val_loss: 3.4450 - val_accuracy: 0.1086\n",
            "Epoch 112/200\n",
            "88/88 [==============================] - 2s 26ms/step - loss: 3.4506 - accuracy: 0.1062 - val_loss: 3.4122 - val_accuracy: 0.1086\n",
            "Epoch 113/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 3.3998 - accuracy: 0.1047 - val_loss: 3.3317 - val_accuracy: 0.1314\n",
            "Epoch 114/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.3337 - accuracy: 0.1047 - val_loss: 3.2762 - val_accuracy: 0.1486\n",
            "Epoch 115/200\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 3.2664 - accuracy: 0.1105 - val_loss: 3.2406 - val_accuracy: 0.1486\n",
            "Epoch 116/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 3.1958 - accuracy: 0.1320 - val_loss: 3.2101 - val_accuracy: 0.1543\n",
            "Epoch 117/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 3.1908 - accuracy: 0.1105 - val_loss: 3.1744 - val_accuracy: 0.1429\n",
            "Epoch 118/200\n",
            "88/88 [==============================] - 3s 36ms/step - loss: 3.1664 - accuracy: 0.1205 - val_loss: 3.1409 - val_accuracy: 0.1429\n",
            "Epoch 119/200\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 3.0910 - accuracy: 0.1148 - val_loss: 3.1023 - val_accuracy: 0.1486\n",
            "Epoch 120/200\n",
            "88/88 [==============================] - 2s 28ms/step - loss: 3.0494 - accuracy: 0.1263 - val_loss: 3.0913 - val_accuracy: 0.1543\n",
            "Epoch 121/200\n",
            "88/88 [==============================] - 2s 26ms/step - loss: 3.0547 - accuracy: 0.1377 - val_loss: 3.0577 - val_accuracy: 0.1429\n",
            "Epoch 122/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.0148 - accuracy: 0.1449 - val_loss: 3.1881 - val_accuracy: 0.1371\n",
            "Epoch 123/200\n",
            "88/88 [==============================] - 4s 40ms/step - loss: 2.9482 - accuracy: 0.1478 - val_loss: 3.0196 - val_accuracy: 0.1314\n",
            "Epoch 124/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 2.9563 - accuracy: 0.1664 - val_loss: 3.0111 - val_accuracy: 0.1543\n",
            "Epoch 125/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 2.8955 - accuracy: 0.1650 - val_loss: 2.9930 - val_accuracy: 0.1657\n",
            "Epoch 126/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 2.8435 - accuracy: 0.1621 - val_loss: 3.0322 - val_accuracy: 0.1314\n",
            "Epoch 127/200\n",
            "88/88 [==============================] - 2s 26ms/step - loss: 2.8466 - accuracy: 0.1664 - val_loss: 3.0402 - val_accuracy: 0.1371\n",
            "Epoch 128/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 2.8696 - accuracy: 0.1664 - val_loss: 3.0328 - val_accuracy: 0.1429\n",
            "Epoch 129/200\n",
            "88/88 [==============================] - 2s 28ms/step - loss: 2.8097 - accuracy: 0.1822 - val_loss: 3.0121 - val_accuracy: 0.1771\n",
            "Epoch 130/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 2.7683 - accuracy: 0.1621 - val_loss: 3.0321 - val_accuracy: 0.1600\n",
            "Epoch 131/200\n",
            "88/88 [==============================] - 2s 28ms/step - loss: 2.7497 - accuracy: 0.1779 - val_loss: 2.9772 - val_accuracy: 0.1714\n",
            "Epoch 132/200\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 2.7139 - accuracy: 0.1851 - val_loss: 2.9585 - val_accuracy: 0.1429\n",
            "Epoch 133/200\n",
            "88/88 [==============================] - 4s 51ms/step - loss: 2.6960 - accuracy: 0.1793 - val_loss: 2.9979 - val_accuracy: 0.1143\n",
            "Epoch 134/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 2.7844 - accuracy: 0.1707 - val_loss: 2.9951 - val_accuracy: 0.1600\n",
            "Epoch 135/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 2.7005 - accuracy: 0.1851 - val_loss: 2.9974 - val_accuracy: 0.1657\n",
            "Epoch 136/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 2.6694 - accuracy: 0.1865 - val_loss: 2.9976 - val_accuracy: 0.1714\n",
            "Epoch 137/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 2.6061 - accuracy: 0.2037 - val_loss: 3.0436 - val_accuracy: 0.1657\n",
            "Epoch 138/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 2.6003 - accuracy: 0.2080 - val_loss: 3.0024 - val_accuracy: 0.1714\n",
            "Epoch 139/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 2.5881 - accuracy: 0.2095 - val_loss: 2.9863 - val_accuracy: 0.1829\n",
            "Epoch 140/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 2.5601 - accuracy: 0.1966 - val_loss: 3.0687 - val_accuracy: 0.1657\n",
            "Epoch 141/200\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 2.5992 - accuracy: 0.2052 - val_loss: 3.0472 - val_accuracy: 0.2057\n",
            "Epoch 142/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 2.5243 - accuracy: 0.2123 - val_loss: 2.9773 - val_accuracy: 0.1829\n",
            "Epoch 143/200\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 2.4807 - accuracy: 0.2382 - val_loss: 3.0222 - val_accuracy: 0.1714\n",
            "Epoch 144/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 2.5074 - accuracy: 0.2138 - val_loss: 3.0743 - val_accuracy: 0.2057\n",
            "Epoch 145/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 2.4423 - accuracy: 0.2568 - val_loss: 3.1611 - val_accuracy: 0.1714\n",
            "Epoch 146/200\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 2.4307 - accuracy: 0.2568 - val_loss: 2.9921 - val_accuracy: 0.1600\n",
            "Epoch 147/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 2.4176 - accuracy: 0.2468 - val_loss: 3.0178 - val_accuracy: 0.1829\n",
            "Epoch 148/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 2.4608 - accuracy: 0.2296 - val_loss: 2.9013 - val_accuracy: 0.2000\n",
            "Epoch 149/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 2.3541 - accuracy: 0.2525 - val_loss: 3.0223 - val_accuracy: 0.1771\n",
            "Epoch 150/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 2.2970 - accuracy: 0.2669 - val_loss: 3.0786 - val_accuracy: 0.1886\n",
            "Epoch 151/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 2.3035 - accuracy: 0.2755 - val_loss: 3.0873 - val_accuracy: 0.1943\n",
            "Epoch 152/200\n",
            "88/88 [==============================] - 3s 36ms/step - loss: 2.3133 - accuracy: 0.2726 - val_loss: 3.1493 - val_accuracy: 0.1657\n",
            "Epoch 153/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 2.2651 - accuracy: 0.2654 - val_loss: 3.1773 - val_accuracy: 0.1829\n",
            "Epoch 154/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 2.2347 - accuracy: 0.2812 - val_loss: 3.0752 - val_accuracy: 0.2057\n",
            "Epoch 155/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 2.3035 - accuracy: 0.2626 - val_loss: 3.1145 - val_accuracy: 0.1943\n",
            "Epoch 156/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 2.2367 - accuracy: 0.2912 - val_loss: 3.1794 - val_accuracy: 0.2000\n",
            "Epoch 157/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 2.1776 - accuracy: 0.3070 - val_loss: 3.1081 - val_accuracy: 0.2229\n",
            "Epoch 158/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 2.1748 - accuracy: 0.2941 - val_loss: 3.1034 - val_accuracy: 0.1771\n",
            "Epoch 159/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 2.1909 - accuracy: 0.2798 - val_loss: 3.1191 - val_accuracy: 0.2000\n",
            "Epoch 160/200\n",
            "88/88 [==============================] - 2s 28ms/step - loss: 2.1128 - accuracy: 0.3042 - val_loss: 3.1646 - val_accuracy: 0.1886\n",
            "Epoch 161/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 2.1084 - accuracy: 0.3242 - val_loss: 3.2029 - val_accuracy: 0.2171\n",
            "Epoch 162/200\n",
            "88/88 [==============================] - 3s 28ms/step - loss: 2.0965 - accuracy: 0.3185 - val_loss: 3.1286 - val_accuracy: 0.2114\n",
            "Epoch 163/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 2.1548 - accuracy: 0.2841 - val_loss: 3.1197 - val_accuracy: 0.1886\n",
            "Epoch 164/200\n",
            "88/88 [==============================] - 2s 28ms/step - loss: 2.1136 - accuracy: 0.3128 - val_loss: 3.1868 - val_accuracy: 0.1886\n",
            "Epoch 165/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 2.0462 - accuracy: 0.3443 - val_loss: 3.2335 - val_accuracy: 0.2000\n",
            "Epoch 166/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 2.0898 - accuracy: 0.2941 - val_loss: 3.2508 - val_accuracy: 0.1771\n",
            "Epoch 167/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 2.2230 - accuracy: 0.2726 - val_loss: 2.9886 - val_accuracy: 0.2114\n",
            "Epoch 168/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 2.0966 - accuracy: 0.3056 - val_loss: 3.1990 - val_accuracy: 0.2114\n",
            "Epoch 169/200\n",
            "88/88 [==============================] - 3s 35ms/step - loss: 2.0671 - accuracy: 0.3113 - val_loss: 3.1447 - val_accuracy: 0.2057\n",
            "Epoch 170/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 2.0857 - accuracy: 0.3314 - val_loss: 3.1408 - val_accuracy: 0.1886\n",
            "Epoch 171/200\n",
            "88/88 [==============================] - 3s 36ms/step - loss: 2.0544 - accuracy: 0.3142 - val_loss: 3.1384 - val_accuracy: 0.2000\n",
            "Epoch 172/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 2.0011 - accuracy: 0.3271 - val_loss: 3.1793 - val_accuracy: 0.2057\n",
            "Epoch 173/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 1.9465 - accuracy: 0.3486 - val_loss: 3.2216 - val_accuracy: 0.2400\n",
            "Epoch 174/200\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 1.9776 - accuracy: 0.3529 - val_loss: 3.2238 - val_accuracy: 0.1886\n",
            "Epoch 175/200\n",
            "88/88 [==============================] - 3s 36ms/step - loss: 1.9054 - accuracy: 0.3615 - val_loss: 3.2196 - val_accuracy: 0.2000\n",
            "Epoch 176/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.9211 - accuracy: 0.3630 - val_loss: 3.3560 - val_accuracy: 0.2000\n",
            "Epoch 177/200\n",
            "88/88 [==============================] - 2s 26ms/step - loss: 1.9807 - accuracy: 0.3601 - val_loss: 3.2700 - val_accuracy: 0.2000\n",
            "Epoch 178/200\n",
            "88/88 [==============================] - 2s 26ms/step - loss: 1.8966 - accuracy: 0.3659 - val_loss: 3.2754 - val_accuracy: 0.1886\n",
            "Epoch 179/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 1.8441 - accuracy: 0.3874 - val_loss: 3.2857 - val_accuracy: 0.2000\n",
            "Epoch 180/200\n",
            "88/88 [==============================] - 3s 38ms/step - loss: 1.9027 - accuracy: 0.3529 - val_loss: 3.2662 - val_accuracy: 0.2000\n",
            "Epoch 181/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 1.8570 - accuracy: 0.3773 - val_loss: 3.3707 - val_accuracy: 0.1829\n",
            "Epoch 182/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 1.8201 - accuracy: 0.3845 - val_loss: 3.4796 - val_accuracy: 0.1943\n",
            "Epoch 183/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 1.8464 - accuracy: 0.3687 - val_loss: 3.2776 - val_accuracy: 0.2114\n",
            "Epoch 184/200\n",
            "88/88 [==============================] - 2s 26ms/step - loss: 1.9787 - accuracy: 0.3443 - val_loss: 3.3204 - val_accuracy: 0.1943\n",
            "Epoch 185/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 1.8809 - accuracy: 0.3845 - val_loss: 3.2255 - val_accuracy: 0.2000\n",
            "Epoch 186/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 1.8455 - accuracy: 0.3859 - val_loss: 3.3606 - val_accuracy: 0.1829\n",
            "Epoch 187/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 1.7853 - accuracy: 0.3831 - val_loss: 3.3503 - val_accuracy: 0.1829\n",
            "Epoch 188/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 1.7396 - accuracy: 0.4146 - val_loss: 3.3513 - val_accuracy: 0.2114\n",
            "Epoch 189/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 1.7863 - accuracy: 0.3931 - val_loss: 3.3140 - val_accuracy: 0.1886\n",
            "Epoch 190/200\n",
            "88/88 [==============================] - 4s 40ms/step - loss: 1.7683 - accuracy: 0.3960 - val_loss: 3.5571 - val_accuracy: 0.2000\n",
            "Epoch 191/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 1.6962 - accuracy: 0.4161 - val_loss: 3.4687 - val_accuracy: 0.1886\n",
            "Epoch 192/200\n",
            "88/88 [==============================] - 2s 28ms/step - loss: 1.7732 - accuracy: 0.4118 - val_loss: 3.5356 - val_accuracy: 0.1943\n",
            "Epoch 193/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.6855 - accuracy: 0.4362 - val_loss: 3.5331 - val_accuracy: 0.1886\n",
            "Epoch 194/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.6856 - accuracy: 0.4304 - val_loss: 3.5054 - val_accuracy: 0.1600\n",
            "Epoch 195/200\n",
            "88/88 [==============================] - 3s 36ms/step - loss: 1.6329 - accuracy: 0.4792 - val_loss: 3.5045 - val_accuracy: 0.1829\n",
            "Epoch 196/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 1.6532 - accuracy: 0.4448 - val_loss: 3.4247 - val_accuracy: 0.2057\n",
            "Epoch 197/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 1.6068 - accuracy: 0.4648 - val_loss: 3.4472 - val_accuracy: 0.1886\n",
            "Epoch 198/200\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 1.5454 - accuracy: 0.4821 - val_loss: 3.6808 - val_accuracy: 0.1714\n",
            "Epoch 199/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.7269 - accuracy: 0.4491 - val_loss: 3.4124 - val_accuracy: 0.2286\n",
            "Epoch 200/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 1.6032 - accuracy: 0.4792 - val_loss: 3.3992 - val_accuracy: 0.1714\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 3.3992 - accuracy: 0.1714\n",
            "Epoch 1/200\n",
            "88/88 [==============================] - 5s 37ms/step - loss: 3.5984 - accuracy: 0.0875 - val_loss: 3.4978 - val_accuracy: 0.1086\n",
            "Epoch 2/200\n",
            "88/88 [==============================] - 4s 49ms/step - loss: 3.5344 - accuracy: 0.0990 - val_loss: 3.4755 - val_accuracy: 0.1086\n",
            "Epoch 3/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.5211 - accuracy: 0.1062 - val_loss: 3.4747 - val_accuracy: 0.1086\n",
            "Epoch 4/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.5046 - accuracy: 0.1019 - val_loss: 3.4694 - val_accuracy: 0.1086\n",
            "Epoch 5/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.5014 - accuracy: 0.1076 - val_loss: 3.4672 - val_accuracy: 0.1086\n",
            "Epoch 6/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 3.4976 - accuracy: 0.0990 - val_loss: 3.4663 - val_accuracy: 0.1086\n",
            "Epoch 7/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 3.5019 - accuracy: 0.1033 - val_loss: 3.4711 - val_accuracy: 0.1086\n",
            "Epoch 8/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4947 - accuracy: 0.1076 - val_loss: 3.4701 - val_accuracy: 0.1086\n",
            "Epoch 9/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4964 - accuracy: 0.1105 - val_loss: 3.4719 - val_accuracy: 0.1086\n",
            "Epoch 10/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4897 - accuracy: 0.1076 - val_loss: 3.4669 - val_accuracy: 0.1086\n",
            "Epoch 11/200\n",
            "88/88 [==============================] - 4s 42ms/step - loss: 3.4886 - accuracy: 0.1105 - val_loss: 3.4692 - val_accuracy: 0.1086\n",
            "Epoch 12/200\n",
            "88/88 [==============================] - 3s 35ms/step - loss: 3.4883 - accuracy: 0.1062 - val_loss: 3.4732 - val_accuracy: 0.1086\n",
            "Epoch 13/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4785 - accuracy: 0.1047 - val_loss: 3.4665 - val_accuracy: 0.1086\n",
            "Epoch 14/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4833 - accuracy: 0.1062 - val_loss: 3.4659 - val_accuracy: 0.1086\n",
            "Epoch 15/200\n",
            "88/88 [==============================] - 4s 41ms/step - loss: 3.4811 - accuracy: 0.0990 - val_loss: 3.4651 - val_accuracy: 0.1086\n",
            "Epoch 16/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4764 - accuracy: 0.1076 - val_loss: 3.4655 - val_accuracy: 0.1086\n",
            "Epoch 17/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4799 - accuracy: 0.1033 - val_loss: 3.4673 - val_accuracy: 0.1086\n",
            "Epoch 18/200\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 3.4809 - accuracy: 0.1076 - val_loss: 3.4660 - val_accuracy: 0.1086\n",
            "Epoch 19/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 3.4734 - accuracy: 0.1105 - val_loss: 3.4651 - val_accuracy: 0.1086\n",
            "Epoch 20/200\n",
            "88/88 [==============================] - 3s 38ms/step - loss: 3.4788 - accuracy: 0.1105 - val_loss: 3.4673 - val_accuracy: 0.1086\n",
            "Epoch 21/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4848 - accuracy: 0.1062 - val_loss: 3.4671 - val_accuracy: 0.1086\n",
            "Epoch 22/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4788 - accuracy: 0.1047 - val_loss: 3.4672 - val_accuracy: 0.1086\n",
            "Epoch 23/200\n",
            "88/88 [==============================] - 3s 35ms/step - loss: 3.4832 - accuracy: 0.1062 - val_loss: 3.4675 - val_accuracy: 0.1086\n",
            "Epoch 24/200\n",
            "88/88 [==============================] - 4s 43ms/step - loss: 3.4764 - accuracy: 0.1047 - val_loss: 3.4663 - val_accuracy: 0.1086\n",
            "Epoch 25/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4831 - accuracy: 0.1076 - val_loss: 3.4688 - val_accuracy: 0.1086\n",
            "Epoch 26/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4864 - accuracy: 0.1076 - val_loss: 3.4659 - val_accuracy: 0.1086\n",
            "Epoch 27/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4778 - accuracy: 0.1033 - val_loss: 3.4645 - val_accuracy: 0.1086\n",
            "Epoch 28/200\n",
            "88/88 [==============================] - 4s 41ms/step - loss: 3.4769 - accuracy: 0.1076 - val_loss: 3.4673 - val_accuracy: 0.1086\n",
            "Epoch 29/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 3.4779 - accuracy: 0.1062 - val_loss: 3.4660 - val_accuracy: 0.1086\n",
            "Epoch 30/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4801 - accuracy: 0.1076 - val_loss: 3.4649 - val_accuracy: 0.1086\n",
            "Epoch 31/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4797 - accuracy: 0.1076 - val_loss: 3.4658 - val_accuracy: 0.1086\n",
            "Epoch 32/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 3.4760 - accuracy: 0.1076 - val_loss: 3.4657 - val_accuracy: 0.1086\n",
            "Epoch 33/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 3.4704 - accuracy: 0.1076 - val_loss: 3.4659 - val_accuracy: 0.1086\n",
            "Epoch 34/200\n",
            "88/88 [==============================] - 3s 36ms/step - loss: 3.4744 - accuracy: 0.1019 - val_loss: 3.4646 - val_accuracy: 0.1086\n",
            "Epoch 35/200\n",
            "88/88 [==============================] - 3s 36ms/step - loss: 3.4793 - accuracy: 0.1076 - val_loss: 3.4657 - val_accuracy: 0.1086\n",
            "Epoch 36/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 3.4758 - accuracy: 0.1062 - val_loss: 3.4646 - val_accuracy: 0.1086\n",
            "Epoch 37/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 3.4708 - accuracy: 0.1076 - val_loss: 3.4670 - val_accuracy: 0.1086\n",
            "Epoch 38/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4779 - accuracy: 0.1076 - val_loss: 3.4652 - val_accuracy: 0.1086\n",
            "Epoch 39/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4770 - accuracy: 0.1076 - val_loss: 3.4649 - val_accuracy: 0.1086\n",
            "Epoch 40/200\n",
            "88/88 [==============================] - 4s 44ms/step - loss: 3.4761 - accuracy: 0.1076 - val_loss: 3.4649 - val_accuracy: 0.1086\n",
            "Epoch 41/200\n",
            "88/88 [==============================] - 4s 40ms/step - loss: 3.4743 - accuracy: 0.1076 - val_loss: 3.4660 - val_accuracy: 0.1086\n",
            "Epoch 42/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4757 - accuracy: 0.1076 - val_loss: 3.4655 - val_accuracy: 0.1086\n",
            "Epoch 43/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4718 - accuracy: 0.1076 - val_loss: 3.4659 - val_accuracy: 0.1086\n",
            "Epoch 44/200\n",
            "88/88 [==============================] - 3s 35ms/step - loss: 3.4744 - accuracy: 0.1076 - val_loss: 3.4659 - val_accuracy: 0.1086\n",
            "Epoch 45/200\n",
            "88/88 [==============================] - 4s 42ms/step - loss: 3.4744 - accuracy: 0.1062 - val_loss: 3.4651 - val_accuracy: 0.1086\n",
            "Epoch 46/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4742 - accuracy: 0.1076 - val_loss: 3.4648 - val_accuracy: 0.1086\n",
            "Epoch 47/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4730 - accuracy: 0.1076 - val_loss: 3.4649 - val_accuracy: 0.1086\n",
            "Epoch 48/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4713 - accuracy: 0.1076 - val_loss: 3.4663 - val_accuracy: 0.1086\n",
            "Epoch 49/200\n",
            "88/88 [==============================] - 3s 36ms/step - loss: 3.4778 - accuracy: 0.1076 - val_loss: 3.4655 - val_accuracy: 0.1086\n",
            "Epoch 50/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 3.4729 - accuracy: 0.1076 - val_loss: 3.4659 - val_accuracy: 0.1086\n",
            "Epoch 51/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4729 - accuracy: 0.1076 - val_loss: 3.4657 - val_accuracy: 0.1086\n",
            "Epoch 52/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4767 - accuracy: 0.1076 - val_loss: 3.4649 - val_accuracy: 0.1086\n",
            "Epoch 53/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4739 - accuracy: 0.1076 - val_loss: 3.4652 - val_accuracy: 0.1086\n",
            "Epoch 54/200\n",
            "88/88 [==============================] - 4s 47ms/step - loss: 3.4698 - accuracy: 0.1076 - val_loss: 3.4654 - val_accuracy: 0.1086\n",
            "Epoch 55/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4748 - accuracy: 0.1062 - val_loss: 3.4649 - val_accuracy: 0.1086\n",
            "Epoch 56/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4732 - accuracy: 0.1076 - val_loss: 3.4649 - val_accuracy: 0.1086\n",
            "Epoch 57/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4704 - accuracy: 0.1076 - val_loss: 3.4657 - val_accuracy: 0.1086\n",
            "Epoch 58/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 3.4726 - accuracy: 0.1076 - val_loss: 3.4649 - val_accuracy: 0.1086\n",
            "Epoch 59/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 3.4721 - accuracy: 0.1062 - val_loss: 3.4653 - val_accuracy: 0.1086\n",
            "Epoch 60/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4740 - accuracy: 0.1076 - val_loss: 3.4645 - val_accuracy: 0.1086\n",
            "Epoch 61/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4696 - accuracy: 0.1076 - val_loss: 3.4652 - val_accuracy: 0.1086\n",
            "Epoch 62/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4715 - accuracy: 0.1076 - val_loss: 3.4641 - val_accuracy: 0.1086\n",
            "Epoch 63/200\n",
            "88/88 [==============================] - 4s 42ms/step - loss: 3.4764 - accuracy: 0.1076 - val_loss: 3.4655 - val_accuracy: 0.1086\n",
            "Epoch 64/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4699 - accuracy: 0.1076 - val_loss: 3.4655 - val_accuracy: 0.1086\n",
            "Epoch 65/200\n",
            "88/88 [==============================] - 3s 35ms/step - loss: 3.4717 - accuracy: 0.1076 - val_loss: 3.4643 - val_accuracy: 0.1086\n",
            "Epoch 66/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4731 - accuracy: 0.1076 - val_loss: 3.4647 - val_accuracy: 0.1086\n",
            "Epoch 67/200\n",
            "88/88 [==============================] - 4s 43ms/step - loss: 3.4716 - accuracy: 0.1076 - val_loss: 3.4656 - val_accuracy: 0.1086\n",
            "Epoch 68/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4716 - accuracy: 0.1076 - val_loss: 3.4658 - val_accuracy: 0.1086\n",
            "Epoch 69/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4719 - accuracy: 0.1076 - val_loss: 3.4656 - val_accuracy: 0.1086\n",
            "Epoch 70/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4673 - accuracy: 0.1047 - val_loss: 3.4653 - val_accuracy: 0.1086\n",
            "Epoch 71/200\n",
            "88/88 [==============================] - 3s 36ms/step - loss: 3.4729 - accuracy: 0.1076 - val_loss: 3.4652 - val_accuracy: 0.1086\n",
            "Epoch 72/200\n",
            "88/88 [==============================] - 3s 36ms/step - loss: 3.4743 - accuracy: 0.1076 - val_loss: 3.4652 - val_accuracy: 0.1086\n",
            "Epoch 73/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4700 - accuracy: 0.1076 - val_loss: 3.4661 - val_accuracy: 0.1086\n",
            "Epoch 74/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4670 - accuracy: 0.1076 - val_loss: 3.4664 - val_accuracy: 0.1086\n",
            "Epoch 75/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4712 - accuracy: 0.1076 - val_loss: 3.4660 - val_accuracy: 0.1086\n",
            "Epoch 76/200\n",
            "88/88 [==============================] - 4s 45ms/step - loss: 3.4741 - accuracy: 0.1076 - val_loss: 3.4650 - val_accuracy: 0.1086\n",
            "Epoch 77/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4735 - accuracy: 0.1076 - val_loss: 3.4656 - val_accuracy: 0.1086\n",
            "Epoch 78/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4658 - accuracy: 0.1062 - val_loss: 3.4645 - val_accuracy: 0.1086\n",
            "Epoch 79/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4745 - accuracy: 0.1076 - val_loss: 3.4649 - val_accuracy: 0.1086\n",
            "Epoch 80/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4720 - accuracy: 0.1076 - val_loss: 3.4644 - val_accuracy: 0.1086\n",
            "Epoch 81/200\n",
            "88/88 [==============================] - 4s 41ms/step - loss: 3.4688 - accuracy: 0.1076 - val_loss: 3.4643 - val_accuracy: 0.1086\n",
            "Epoch 82/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4677 - accuracy: 0.1076 - val_loss: 3.4648 - val_accuracy: 0.1086\n",
            "Epoch 83/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4673 - accuracy: 0.1076 - val_loss: 3.4647 - val_accuracy: 0.1086\n",
            "Epoch 84/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4732 - accuracy: 0.1076 - val_loss: 3.4637 - val_accuracy: 0.1086\n",
            "Epoch 85/200\n",
            "88/88 [==============================] - 4s 45ms/step - loss: 3.4708 - accuracy: 0.1076 - val_loss: 3.4634 - val_accuracy: 0.1086\n",
            "Epoch 86/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4710 - accuracy: 0.1076 - val_loss: 3.4644 - val_accuracy: 0.1086\n",
            "Epoch 87/200\n",
            "88/88 [==============================] - 3s 36ms/step - loss: 3.4705 - accuracy: 0.1076 - val_loss: 3.4635 - val_accuracy: 0.1086\n",
            "Epoch 88/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4698 - accuracy: 0.1076 - val_loss: 3.4643 - val_accuracy: 0.1086\n",
            "Epoch 89/200\n",
            "88/88 [==============================] - 3s 38ms/step - loss: 3.4708 - accuracy: 0.1076 - val_loss: 3.4649 - val_accuracy: 0.1086\n",
            "Epoch 90/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 3.4697 - accuracy: 0.1076 - val_loss: 3.4652 - val_accuracy: 0.1086\n",
            "Epoch 91/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4718 - accuracy: 0.1076 - val_loss: 3.4666 - val_accuracy: 0.1086\n",
            "Epoch 92/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4723 - accuracy: 0.1076 - val_loss: 3.4658 - val_accuracy: 0.1086\n",
            "Epoch 93/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4683 - accuracy: 0.1076 - val_loss: 3.4655 - val_accuracy: 0.1086\n",
            "Epoch 94/200\n",
            "88/88 [==============================] - 4s 42ms/step - loss: 3.4692 - accuracy: 0.1076 - val_loss: 3.4659 - val_accuracy: 0.1086\n",
            "Epoch 95/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4695 - accuracy: 0.1076 - val_loss: 3.4655 - val_accuracy: 0.1086\n",
            "Epoch 96/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4718 - accuracy: 0.1076 - val_loss: 3.4655 - val_accuracy: 0.1086\n",
            "Epoch 97/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4686 - accuracy: 0.1076 - val_loss: 3.4648 - val_accuracy: 0.1086\n",
            "Epoch 98/200\n",
            "88/88 [==============================] - 5s 52ms/step - loss: 3.4681 - accuracy: 0.1076 - val_loss: 3.4645 - val_accuracy: 0.1086\n",
            "Epoch 99/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4727 - accuracy: 0.1076 - val_loss: 3.4629 - val_accuracy: 0.1086\n",
            "Epoch 100/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4690 - accuracy: 0.1076 - val_loss: 3.4639 - val_accuracy: 0.1086\n",
            "Epoch 101/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4669 - accuracy: 0.1076 - val_loss: 3.4652 - val_accuracy: 0.1086\n",
            "Epoch 102/200\n",
            "88/88 [==============================] - 3s 38ms/step - loss: 3.4722 - accuracy: 0.1076 - val_loss: 3.4660 - val_accuracy: 0.1086\n",
            "Epoch 103/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 3.4711 - accuracy: 0.1076 - val_loss: 3.4657 - val_accuracy: 0.1086\n",
            "Epoch 104/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4703 - accuracy: 0.1076 - val_loss: 3.4646 - val_accuracy: 0.1086\n",
            "Epoch 105/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 3.4655 - accuracy: 0.1076 - val_loss: 3.4642 - val_accuracy: 0.1086\n",
            "Epoch 106/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4696 - accuracy: 0.1076 - val_loss: 3.4655 - val_accuracy: 0.1086\n",
            "Epoch 107/200\n",
            "88/88 [==============================] - 4s 42ms/step - loss: 3.4695 - accuracy: 0.1076 - val_loss: 3.4650 - val_accuracy: 0.1086\n",
            "Epoch 108/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 3.4699 - accuracy: 0.1076 - val_loss: 3.4639 - val_accuracy: 0.1086\n",
            "Epoch 109/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4698 - accuracy: 0.1076 - val_loss: 3.4651 - val_accuracy: 0.1086\n",
            "Epoch 110/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 3.4667 - accuracy: 0.1076 - val_loss: 3.4652 - val_accuracy: 0.1086\n",
            "Epoch 111/200\n",
            "88/88 [==============================] - 4s 43ms/step - loss: 3.4702 - accuracy: 0.1076 - val_loss: 3.4645 - val_accuracy: 0.1086\n",
            "Epoch 112/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4677 - accuracy: 0.1076 - val_loss: 3.4651 - val_accuracy: 0.1086\n",
            "Epoch 113/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4700 - accuracy: 0.1076 - val_loss: 3.4650 - val_accuracy: 0.1086\n",
            "Epoch 114/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4675 - accuracy: 0.1076 - val_loss: 3.4643 - val_accuracy: 0.1086\n",
            "Epoch 115/200\n",
            "88/88 [==============================] - 4s 40ms/step - loss: 3.4649 - accuracy: 0.1076 - val_loss: 3.4652 - val_accuracy: 0.1086\n",
            "Epoch 116/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 3.4708 - accuracy: 0.1076 - val_loss: 3.4655 - val_accuracy: 0.1086\n",
            "Epoch 117/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4712 - accuracy: 0.1076 - val_loss: 3.4656 - val_accuracy: 0.1086\n",
            "Epoch 118/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4697 - accuracy: 0.1076 - val_loss: 3.4658 - val_accuracy: 0.1086\n",
            "Epoch 119/200\n",
            "88/88 [==============================] - 4s 42ms/step - loss: 3.4689 - accuracy: 0.1076 - val_loss: 3.4661 - val_accuracy: 0.1086\n",
            "Epoch 120/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 3.4701 - accuracy: 0.1076 - val_loss: 3.4653 - val_accuracy: 0.1086\n",
            "Epoch 121/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4682 - accuracy: 0.1076 - val_loss: 3.4658 - val_accuracy: 0.1086\n",
            "Epoch 122/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4646 - accuracy: 0.1076 - val_loss: 3.4666 - val_accuracy: 0.1086\n",
            "Epoch 123/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 3.4697 - accuracy: 0.1076 - val_loss: 3.4666 - val_accuracy: 0.1086\n",
            "Epoch 124/200\n",
            "88/88 [==============================] - 4s 43ms/step - loss: 3.4701 - accuracy: 0.1076 - val_loss: 3.4657 - val_accuracy: 0.1086\n",
            "Epoch 125/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4683 - accuracy: 0.1076 - val_loss: 3.4651 - val_accuracy: 0.1086\n",
            "Epoch 126/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4697 - accuracy: 0.1090 - val_loss: 3.4653 - val_accuracy: 0.1086\n",
            "Epoch 127/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4677 - accuracy: 0.1076 - val_loss: 3.4646 - val_accuracy: 0.1086\n",
            "Epoch 128/200\n",
            "88/88 [==============================] - 4s 43ms/step - loss: 3.4686 - accuracy: 0.1076 - val_loss: 3.4649 - val_accuracy: 0.1086\n",
            "Epoch 129/200\n",
            "88/88 [==============================] - 3s 38ms/step - loss: 3.4692 - accuracy: 0.1076 - val_loss: 3.4633 - val_accuracy: 0.1086\n",
            "Epoch 130/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4701 - accuracy: 0.1076 - val_loss: 3.4642 - val_accuracy: 0.1086\n",
            "Epoch 131/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4678 - accuracy: 0.1062 - val_loss: 3.4639 - val_accuracy: 0.1086\n",
            "Epoch 132/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 3.4691 - accuracy: 0.1076 - val_loss: 3.4634 - val_accuracy: 0.1086\n",
            "Epoch 133/200\n",
            "88/88 [==============================] - 3s 35ms/step - loss: 3.4692 - accuracy: 0.1076 - val_loss: 3.4638 - val_accuracy: 0.1086\n",
            "Epoch 134/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4702 - accuracy: 0.1076 - val_loss: 3.4643 - val_accuracy: 0.1086\n",
            "Epoch 135/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4664 - accuracy: 0.1076 - val_loss: 3.4643 - val_accuracy: 0.1086\n",
            "Epoch 136/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 3.4670 - accuracy: 0.1076 - val_loss: 3.4647 - val_accuracy: 0.1086\n",
            "Epoch 137/200\n",
            "88/88 [==============================] - 4s 40ms/step - loss: 3.4686 - accuracy: 0.1076 - val_loss: 3.4649 - val_accuracy: 0.1086\n",
            "Epoch 138/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4689 - accuracy: 0.1076 - val_loss: 3.4639 - val_accuracy: 0.1086\n",
            "Epoch 139/200\n",
            "88/88 [==============================] - 4s 40ms/step - loss: 3.4692 - accuracy: 0.1076 - val_loss: 3.4637 - val_accuracy: 0.1086\n",
            "Epoch 140/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 3.4702 - accuracy: 0.1076 - val_loss: 3.4636 - val_accuracy: 0.1086\n",
            "Epoch 141/200\n",
            "88/88 [==============================] - 4s 44ms/step - loss: 3.4657 - accuracy: 0.1076 - val_loss: 3.4618 - val_accuracy: 0.1086\n",
            "Epoch 142/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4706 - accuracy: 0.1076 - val_loss: 3.4626 - val_accuracy: 0.1086\n",
            "Epoch 143/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4664 - accuracy: 0.1076 - val_loss: 3.4622 - val_accuracy: 0.1086\n",
            "Epoch 144/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4657 - accuracy: 0.1076 - val_loss: 3.4610 - val_accuracy: 0.1086\n",
            "Epoch 145/200\n",
            "88/88 [==============================] - 4s 44ms/step - loss: 3.4638 - accuracy: 0.1076 - val_loss: 3.4573 - val_accuracy: 0.1086\n",
            "Epoch 146/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4592 - accuracy: 0.1076 - val_loss: 3.4420 - val_accuracy: 0.1086\n",
            "Epoch 147/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4408 - accuracy: 0.1033 - val_loss: 3.4475 - val_accuracy: 0.1143\n",
            "Epoch 148/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4025 - accuracy: 0.0933 - val_loss: 3.3298 - val_accuracy: 0.1086\n",
            "Epoch 149/200\n",
            "88/88 [==============================] - 4s 46ms/step - loss: 3.4015 - accuracy: 0.1004 - val_loss: 3.3515 - val_accuracy: 0.0800\n",
            "Epoch 150/200\n",
            "88/88 [==============================] - 3s 36ms/step - loss: 3.4021 - accuracy: 0.0904 - val_loss: 3.3575 - val_accuracy: 0.1257\n",
            "Epoch 151/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 3.4980 - accuracy: 0.0875 - val_loss: 3.4770 - val_accuracy: 0.1086\n",
            "Epoch 152/200\n",
            "88/88 [==============================] - 4s 42ms/step - loss: 3.4821 - accuracy: 0.1076 - val_loss: 3.4639 - val_accuracy: 0.1086\n",
            "Epoch 153/200\n",
            "88/88 [==============================] - 4s 46ms/step - loss: 3.4178 - accuracy: 0.1076 - val_loss: 3.5530 - val_accuracy: 0.1086\n",
            "Epoch 154/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 3.5198 - accuracy: 0.1004 - val_loss: 3.4677 - val_accuracy: 0.1086\n",
            "Epoch 155/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4787 - accuracy: 0.1047 - val_loss: 3.4410 - val_accuracy: 0.1086\n",
            "Epoch 156/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4410 - accuracy: 0.0947 - val_loss: 3.4819 - val_accuracy: 0.1086\n",
            "Epoch 157/200\n",
            "88/88 [==============================] - 4s 46ms/step - loss: 3.4879 - accuracy: 0.1047 - val_loss: 3.4617 - val_accuracy: 0.1086\n",
            "Epoch 158/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 3.4346 - accuracy: 0.0990 - val_loss: 3.4753 - val_accuracy: 0.1086\n",
            "Epoch 159/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 3.4723 - accuracy: 0.1076 - val_loss: 3.3736 - val_accuracy: 0.1029\n",
            "Epoch 160/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4667 - accuracy: 0.1019 - val_loss: 3.4714 - val_accuracy: 0.1086\n",
            "Epoch 161/200\n",
            "88/88 [==============================] - 3s 40ms/step - loss: 3.4902 - accuracy: 0.0947 - val_loss: 3.4637 - val_accuracy: 0.1086\n",
            "Epoch 162/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 3.4242 - accuracy: 0.1019 - val_loss: 3.3190 - val_accuracy: 0.1086\n",
            "Epoch 163/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 3.3327 - accuracy: 0.0976 - val_loss: 3.2668 - val_accuracy: 0.1029\n",
            "Epoch 164/200\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 3.3907 - accuracy: 0.1148 - val_loss: 3.4786 - val_accuracy: 0.1086\n",
            "Epoch 165/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 3.5106 - accuracy: 0.1004 - val_loss: 3.4693 - val_accuracy: 0.1086\n",
            "Epoch 166/200\n",
            "88/88 [==============================] - 4s 44ms/step - loss: 3.5106 - accuracy: 0.0846 - val_loss: 3.4761 - val_accuracy: 0.1086\n",
            "Epoch 167/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.5303 - accuracy: 0.0846 - val_loss: 3.4846 - val_accuracy: 0.1086\n",
            "Epoch 168/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.5170 - accuracy: 0.0961 - val_loss: 3.4754 - val_accuracy: 0.1086\n",
            "Epoch 169/200\n",
            "88/88 [==============================] - 4s 42ms/step - loss: 3.5183 - accuracy: 0.0947 - val_loss: 3.4694 - val_accuracy: 0.1086\n",
            "Epoch 170/200\n",
            "88/88 [==============================] - 4s 42ms/step - loss: 3.5026 - accuracy: 0.1076 - val_loss: 3.4676 - val_accuracy: 0.1086\n",
            "Epoch 171/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.5007 - accuracy: 0.1090 - val_loss: 3.4699 - val_accuracy: 0.1086\n",
            "Epoch 172/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4811 - accuracy: 0.1090 - val_loss: 3.4661 - val_accuracy: 0.1086\n",
            "Epoch 173/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4795 - accuracy: 0.1047 - val_loss: 3.4683 - val_accuracy: 0.1086\n",
            "Epoch 174/200\n",
            "88/88 [==============================] - 4s 44ms/step - loss: 3.4896 - accuracy: 0.1105 - val_loss: 3.4659 - val_accuracy: 0.1086\n",
            "Epoch 175/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4748 - accuracy: 0.1090 - val_loss: 3.4661 - val_accuracy: 0.1086\n",
            "Epoch 176/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4827 - accuracy: 0.1076 - val_loss: 3.4678 - val_accuracy: 0.1086\n",
            "Epoch 177/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4853 - accuracy: 0.1090 - val_loss: 3.4676 - val_accuracy: 0.1086\n",
            "Epoch 178/200\n",
            "88/88 [==============================] - 4s 40ms/step - loss: 3.4727 - accuracy: 0.1133 - val_loss: 3.4655 - val_accuracy: 0.1086\n",
            "Epoch 179/200\n",
            "88/88 [==============================] - 4s 40ms/step - loss: 3.4728 - accuracy: 0.1090 - val_loss: 3.4667 - val_accuracy: 0.1086\n",
            "Epoch 180/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4756 - accuracy: 0.1090 - val_loss: 3.4648 - val_accuracy: 0.1086\n",
            "Epoch 181/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4660 - accuracy: 0.1090 - val_loss: 3.4671 - val_accuracy: 0.1086\n",
            "Epoch 182/200\n",
            "88/88 [==============================] - 3s 38ms/step - loss: 3.4772 - accuracy: 0.1090 - val_loss: 3.4674 - val_accuracy: 0.1086\n",
            "Epoch 183/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 3.4727 - accuracy: 0.1076 - val_loss: 3.4651 - val_accuracy: 0.1086\n",
            "Epoch 184/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4716 - accuracy: 0.1090 - val_loss: 3.4657 - val_accuracy: 0.1086\n",
            "Epoch 185/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4638 - accuracy: 0.1090 - val_loss: 3.4650 - val_accuracy: 0.1086\n",
            "Epoch 186/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4698 - accuracy: 0.1062 - val_loss: 3.4650 - val_accuracy: 0.1086\n",
            "Epoch 187/200\n",
            "88/88 [==============================] - 4s 44ms/step - loss: 3.4661 - accuracy: 0.1090 - val_loss: 3.4648 - val_accuracy: 0.1086\n",
            "Epoch 188/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4642 - accuracy: 0.1090 - val_loss: 3.4645 - val_accuracy: 0.1086\n",
            "Epoch 189/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 3.4646 - accuracy: 0.1090 - val_loss: 3.4651 - val_accuracy: 0.1086\n",
            "Epoch 190/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 3.4627 - accuracy: 0.1090 - val_loss: 3.4650 - val_accuracy: 0.1086\n",
            "Epoch 191/200\n",
            "88/88 [==============================] - 4s 44ms/step - loss: 3.4668 - accuracy: 0.1090 - val_loss: 3.4648 - val_accuracy: 0.1086\n",
            "Epoch 192/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4682 - accuracy: 0.1090 - val_loss: 3.4653 - val_accuracy: 0.1086\n",
            "Epoch 193/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4666 - accuracy: 0.1090 - val_loss: 3.4649 - val_accuracy: 0.1086\n",
            "Epoch 194/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4688 - accuracy: 0.1090 - val_loss: 3.4640 - val_accuracy: 0.1086\n",
            "Epoch 195/200\n",
            "88/88 [==============================] - 3s 40ms/step - loss: 3.4651 - accuracy: 0.1090 - val_loss: 3.4641 - val_accuracy: 0.1086\n",
            "Epoch 196/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 3.4653 - accuracy: 0.1090 - val_loss: 3.4649 - val_accuracy: 0.1086\n",
            "Epoch 197/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4666 - accuracy: 0.1090 - val_loss: 3.4644 - val_accuracy: 0.1086\n",
            "Epoch 198/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4645 - accuracy: 0.1090 - val_loss: 3.4648 - val_accuracy: 0.1086\n",
            "Epoch 199/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4631 - accuracy: 0.1090 - val_loss: 3.4644 - val_accuracy: 0.1086\n",
            "Epoch 200/200\n",
            "88/88 [==============================] - 4s 49ms/step - loss: 3.4633 - accuracy: 0.1090 - val_loss: 3.4655 - val_accuracy: 0.1086\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 3.4655 - accuracy: 0.1086\n",
            "Epoch 1/200\n",
            "88/88 [==============================] - 5s 39ms/step - loss: 3.6037 - accuracy: 0.0860 - val_loss: 3.4906 - val_accuracy: 0.1034\n",
            "Epoch 2/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 3.5241 - accuracy: 0.0989 - val_loss: 3.4767 - val_accuracy: 0.1034\n",
            "Epoch 3/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 3.5160 - accuracy: 0.1032 - val_loss: 3.4734 - val_accuracy: 0.1034\n",
            "Epoch 4/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.5107 - accuracy: 0.1032 - val_loss: 3.4697 - val_accuracy: 0.1034\n",
            "Epoch 5/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.5045 - accuracy: 0.0960 - val_loss: 3.4715 - val_accuracy: 0.1034\n",
            "Epoch 6/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 3.4917 - accuracy: 0.0989 - val_loss: 3.4717 - val_accuracy: 0.1034\n",
            "Epoch 7/200\n",
            "88/88 [==============================] - 4s 42ms/step - loss: 3.4950 - accuracy: 0.1060 - val_loss: 3.4729 - val_accuracy: 0.1034\n",
            "Epoch 8/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.5081 - accuracy: 0.1060 - val_loss: 3.4650 - val_accuracy: 0.1034\n",
            "Epoch 9/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4966 - accuracy: 0.1089 - val_loss: 3.4670 - val_accuracy: 0.1034\n",
            "Epoch 10/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4794 - accuracy: 0.1074 - val_loss: 3.4628 - val_accuracy: 0.1034\n",
            "Epoch 11/200\n",
            "88/88 [==============================] - 4s 45ms/step - loss: 3.4940 - accuracy: 0.1103 - val_loss: 3.4721 - val_accuracy: 0.1034\n",
            "Epoch 12/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4851 - accuracy: 0.1060 - val_loss: 3.4657 - val_accuracy: 0.1034\n",
            "Epoch 13/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 3.4842 - accuracy: 0.1103 - val_loss: 3.4660 - val_accuracy: 0.1034\n",
            "Epoch 14/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4911 - accuracy: 0.1089 - val_loss: 3.4680 - val_accuracy: 0.1034\n",
            "Epoch 15/200\n",
            "88/88 [==============================] - 4s 43ms/step - loss: 3.4846 - accuracy: 0.1103 - val_loss: 3.4673 - val_accuracy: 0.1034\n",
            "Epoch 16/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 3.4849 - accuracy: 0.1046 - val_loss: 3.4649 - val_accuracy: 0.1034\n",
            "Epoch 17/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4799 - accuracy: 0.1089 - val_loss: 3.4684 - val_accuracy: 0.1034\n",
            "Epoch 18/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4828 - accuracy: 0.1074 - val_loss: 3.4633 - val_accuracy: 0.1034\n",
            "Epoch 19/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4840 - accuracy: 0.1060 - val_loss: 3.4650 - val_accuracy: 0.1034\n",
            "Epoch 20/200\n",
            "88/88 [==============================] - 4s 44ms/step - loss: 3.4757 - accuracy: 0.1089 - val_loss: 3.4633 - val_accuracy: 0.1034\n",
            "Epoch 21/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4784 - accuracy: 0.1089 - val_loss: 3.4617 - val_accuracy: 0.1034\n",
            "Epoch 22/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4773 - accuracy: 0.1089 - val_loss: 3.4616 - val_accuracy: 0.1034\n",
            "Epoch 23/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4791 - accuracy: 0.1046 - val_loss: 3.4621 - val_accuracy: 0.1034\n",
            "Epoch 24/200\n",
            "88/88 [==============================] - 4s 42ms/step - loss: 3.4803 - accuracy: 0.1089 - val_loss: 3.4645 - val_accuracy: 0.1034\n",
            "Epoch 25/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4812 - accuracy: 0.1089 - val_loss: 3.4620 - val_accuracy: 0.1034\n",
            "Epoch 26/200\n",
            "88/88 [==============================] - 3s 35ms/step - loss: 3.4739 - accuracy: 0.1089 - val_loss: 3.4621 - val_accuracy: 0.1034\n",
            "Epoch 27/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4782 - accuracy: 0.1089 - val_loss: 3.4646 - val_accuracy: 0.1034\n",
            "Epoch 28/200\n",
            "88/88 [==============================] - 3s 38ms/step - loss: 3.4829 - accuracy: 0.1089 - val_loss: 3.4635 - val_accuracy: 0.1034\n",
            "Epoch 29/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 3.4724 - accuracy: 0.1103 - val_loss: 3.4632 - val_accuracy: 0.1034\n",
            "Epoch 30/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4790 - accuracy: 0.1089 - val_loss: 3.4631 - val_accuracy: 0.1034\n",
            "Epoch 31/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4714 - accuracy: 0.1089 - val_loss: 3.4627 - val_accuracy: 0.1034\n",
            "Epoch 32/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4823 - accuracy: 0.1089 - val_loss: 3.4616 - val_accuracy: 0.1034\n",
            "Epoch 33/200\n",
            "88/88 [==============================] - 4s 44ms/step - loss: 3.4754 - accuracy: 0.1089 - val_loss: 3.4622 - val_accuracy: 0.1034\n",
            "Epoch 34/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4725 - accuracy: 0.1074 - val_loss: 3.4639 - val_accuracy: 0.1034\n",
            "Epoch 35/200\n",
            "88/88 [==============================] - 3s 35ms/step - loss: 3.4787 - accuracy: 0.1089 - val_loss: 3.4634 - val_accuracy: 0.1034\n",
            "Epoch 36/200\n",
            "88/88 [==============================] - 3s 35ms/step - loss: 3.4756 - accuracy: 0.1089 - val_loss: 3.4635 - val_accuracy: 0.1034\n",
            "Epoch 37/200\n",
            "88/88 [==============================] - 5s 52ms/step - loss: 3.4750 - accuracy: 0.1089 - val_loss: 3.4627 - val_accuracy: 0.1034\n",
            "Epoch 38/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4735 - accuracy: 0.1089 - val_loss: 3.4635 - val_accuracy: 0.1034\n",
            "Epoch 39/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4734 - accuracy: 0.1089 - val_loss: 3.4618 - val_accuracy: 0.1034\n",
            "Epoch 40/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4725 - accuracy: 0.1089 - val_loss: 3.4632 - val_accuracy: 0.1034\n",
            "Epoch 41/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 3.4765 - accuracy: 0.1089 - val_loss: 3.4624 - val_accuracy: 0.1034\n",
            "Epoch 42/200\n",
            "88/88 [==============================] - 3s 38ms/step - loss: 3.4739 - accuracy: 0.1089 - val_loss: 3.4619 - val_accuracy: 0.1034\n",
            "Epoch 43/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4778 - accuracy: 0.1089 - val_loss: 3.4627 - val_accuracy: 0.1034\n",
            "Epoch 44/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4718 - accuracy: 0.1089 - val_loss: 3.4630 - val_accuracy: 0.1034\n",
            "Epoch 45/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4783 - accuracy: 0.1089 - val_loss: 3.4629 - val_accuracy: 0.1034\n",
            "Epoch 46/200\n",
            "88/88 [==============================] - 4s 45ms/step - loss: 3.4740 - accuracy: 0.1089 - val_loss: 3.4633 - val_accuracy: 0.1034\n",
            "Epoch 47/200\n",
            "88/88 [==============================] - 3s 36ms/step - loss: 3.4777 - accuracy: 0.1089 - val_loss: 3.4621 - val_accuracy: 0.1034\n",
            "Epoch 48/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4734 - accuracy: 0.1089 - val_loss: 3.4627 - val_accuracy: 0.1034\n",
            "Epoch 49/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4746 - accuracy: 0.1089 - val_loss: 3.4624 - val_accuracy: 0.1034\n",
            "Epoch 50/200\n",
            "88/88 [==============================] - 4s 43ms/step - loss: 3.4713 - accuracy: 0.1089 - val_loss: 3.4617 - val_accuracy: 0.1034\n",
            "Epoch 51/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4738 - accuracy: 0.1089 - val_loss: 3.4622 - val_accuracy: 0.1034\n",
            "Epoch 52/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4704 - accuracy: 0.1089 - val_loss: 3.4625 - val_accuracy: 0.1034\n",
            "Epoch 53/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4699 - accuracy: 0.1089 - val_loss: 3.4627 - val_accuracy: 0.1034\n",
            "Epoch 54/200\n",
            "88/88 [==============================] - 3s 35ms/step - loss: 3.4716 - accuracy: 0.1089 - val_loss: 3.4621 - val_accuracy: 0.1034\n",
            "Epoch 55/200\n",
            "88/88 [==============================] - 4s 48ms/step - loss: 3.4721 - accuracy: 0.1089 - val_loss: 3.4613 - val_accuracy: 0.1034\n",
            "Epoch 56/200\n",
            "88/88 [==============================] - 3s 35ms/step - loss: 3.4726 - accuracy: 0.1089 - val_loss: 3.4625 - val_accuracy: 0.1034\n",
            "Epoch 57/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 3.4732 - accuracy: 0.1089 - val_loss: 3.4625 - val_accuracy: 0.1034\n",
            "Epoch 58/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 3.4711 - accuracy: 0.1089 - val_loss: 3.4629 - val_accuracy: 0.1034\n",
            "Epoch 59/200\n",
            "88/88 [==============================] - 3s 38ms/step - loss: 3.4815 - accuracy: 0.1089 - val_loss: 3.4621 - val_accuracy: 0.1034\n",
            "Epoch 60/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4670 - accuracy: 0.1089 - val_loss: 3.4630 - val_accuracy: 0.1034\n",
            "Epoch 61/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4729 - accuracy: 0.1089 - val_loss: 3.4625 - val_accuracy: 0.1034\n",
            "Epoch 62/200\n",
            "88/88 [==============================] - 3s 35ms/step - loss: 3.4738 - accuracy: 0.1089 - val_loss: 3.4630 - val_accuracy: 0.1034\n",
            "Epoch 63/200\n",
            "88/88 [==============================] - 4s 41ms/step - loss: 3.4665 - accuracy: 0.1089 - val_loss: 3.4625 - val_accuracy: 0.1034\n",
            "Epoch 64/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 3.4742 - accuracy: 0.1089 - val_loss: 3.4626 - val_accuracy: 0.1034\n",
            "Epoch 65/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 3.4722 - accuracy: 0.1089 - val_loss: 3.4622 - val_accuracy: 0.1034\n",
            "Epoch 66/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4723 - accuracy: 0.1089 - val_loss: 3.4612 - val_accuracy: 0.1034\n",
            "Epoch 67/200\n",
            "88/88 [==============================] - 4s 49ms/step - loss: 3.4736 - accuracy: 0.1089 - val_loss: 3.4624 - val_accuracy: 0.1034\n",
            "Epoch 68/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4733 - accuracy: 0.1089 - val_loss: 3.4621 - val_accuracy: 0.1034\n",
            "Epoch 69/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4696 - accuracy: 0.1089 - val_loss: 3.4623 - val_accuracy: 0.1034\n",
            "Epoch 70/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4709 - accuracy: 0.1089 - val_loss: 3.4623 - val_accuracy: 0.1034\n",
            "Epoch 71/200\n",
            "88/88 [==============================] - 4s 44ms/step - loss: 3.4699 - accuracy: 0.1089 - val_loss: 3.4619 - val_accuracy: 0.1034\n",
            "Epoch 72/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4680 - accuracy: 0.1089 - val_loss: 3.4633 - val_accuracy: 0.1034\n",
            "Epoch 73/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4751 - accuracy: 0.1089 - val_loss: 3.4616 - val_accuracy: 0.1034\n",
            "Epoch 74/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4698 - accuracy: 0.1089 - val_loss: 3.4616 - val_accuracy: 0.1034\n",
            "Epoch 75/200\n",
            "88/88 [==============================] - 4s 40ms/step - loss: 3.4719 - accuracy: 0.1089 - val_loss: 3.4637 - val_accuracy: 0.1034\n",
            "Epoch 76/200\n",
            "88/88 [==============================] - 3s 36ms/step - loss: 3.4726 - accuracy: 0.1089 - val_loss: 3.4627 - val_accuracy: 0.1034\n",
            "Epoch 77/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 3.4727 - accuracy: 0.1089 - val_loss: 3.4627 - val_accuracy: 0.1034\n",
            "Epoch 78/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 3.4739 - accuracy: 0.1089 - val_loss: 3.4611 - val_accuracy: 0.1034\n",
            "Epoch 79/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 3.4651 - accuracy: 0.1089 - val_loss: 3.4616 - val_accuracy: 0.1034\n",
            "Epoch 80/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 3.4724 - accuracy: 0.1089 - val_loss: 3.4605 - val_accuracy: 0.1034\n",
            "Epoch 81/200\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 3.4710 - accuracy: 0.1089 - val_loss: 3.4610 - val_accuracy: 0.1034\n",
            "Epoch 82/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4696 - accuracy: 0.1089 - val_loss: 3.4610 - val_accuracy: 0.1034\n",
            "Epoch 83/200\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 3.4700 - accuracy: 0.1089 - val_loss: 3.4615 - val_accuracy: 0.1034\n",
            "Epoch 84/200\n",
            "88/88 [==============================] - 4s 41ms/step - loss: 3.4727 - accuracy: 0.1089 - val_loss: 3.4616 - val_accuracy: 0.1034\n",
            "Epoch 85/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 3.4712 - accuracy: 0.1089 - val_loss: 3.4621 - val_accuracy: 0.1034\n",
            "Epoch 86/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 3.4660 - accuracy: 0.1089 - val_loss: 3.4618 - val_accuracy: 0.1034\n",
            "Epoch 87/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 3.4719 - accuracy: 0.1089 - val_loss: 3.4617 - val_accuracy: 0.1034\n",
            "Epoch 88/200\n",
            "88/88 [==============================] - 4s 43ms/step - loss: 3.4720 - accuracy: 0.1089 - val_loss: 3.4623 - val_accuracy: 0.1034\n",
            "Epoch 89/200\n",
            "88/88 [==============================] - 4s 42ms/step - loss: 3.4675 - accuracy: 0.1089 - val_loss: 3.4620 - val_accuracy: 0.1034\n",
            "Epoch 90/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4685 - accuracy: 0.1089 - val_loss: 3.4620 - val_accuracy: 0.1034\n",
            "Epoch 91/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4738 - accuracy: 0.1089 - val_loss: 3.4620 - val_accuracy: 0.1034\n",
            "Epoch 92/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 3.4735 - accuracy: 0.1089 - val_loss: 3.4619 - val_accuracy: 0.1034\n",
            "Epoch 93/200\n",
            "88/88 [==============================] - 4s 47ms/step - loss: 3.4725 - accuracy: 0.1089 - val_loss: 3.4624 - val_accuracy: 0.1034\n",
            "Epoch 94/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4684 - accuracy: 0.1089 - val_loss: 3.4621 - val_accuracy: 0.1034\n",
            "Epoch 95/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4729 - accuracy: 0.1089 - val_loss: 3.4614 - val_accuracy: 0.1034\n",
            "Epoch 96/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4711 - accuracy: 0.1089 - val_loss: 3.4618 - val_accuracy: 0.1034\n",
            "Epoch 97/200\n",
            "88/88 [==============================] - 3s 40ms/step - loss: 3.4720 - accuracy: 0.1089 - val_loss: 3.4621 - val_accuracy: 0.1034\n",
            "Epoch 98/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 3.4680 - accuracy: 0.1089 - val_loss: 3.4622 - val_accuracy: 0.1034\n",
            "Epoch 99/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 3.4690 - accuracy: 0.1089 - val_loss: 3.4622 - val_accuracy: 0.1034\n",
            "Epoch 100/200\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 3.4673 - accuracy: 0.1089 - val_loss: 3.4618 - val_accuracy: 0.1034\n",
            "Epoch 101/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 3.4696 - accuracy: 0.1089 - val_loss: 3.4631 - val_accuracy: 0.1034\n",
            "Epoch 102/200\n",
            "88/88 [==============================] - 4s 47ms/step - loss: 3.4697 - accuracy: 0.1089 - val_loss: 3.4622 - val_accuracy: 0.1034\n",
            "Epoch 103/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4693 - accuracy: 0.1089 - val_loss: 3.4616 - val_accuracy: 0.1034\n",
            "Epoch 104/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4670 - accuracy: 0.1089 - val_loss: 3.4621 - val_accuracy: 0.1034\n",
            "Epoch 105/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4721 - accuracy: 0.1089 - val_loss: 3.4617 - val_accuracy: 0.1034\n",
            "Epoch 106/200\n",
            "88/88 [==============================] - 4s 43ms/step - loss: 3.4688 - accuracy: 0.1089 - val_loss: 3.4629 - val_accuracy: 0.1034\n",
            "Epoch 107/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4717 - accuracy: 0.1089 - val_loss: 3.4627 - val_accuracy: 0.1034\n",
            "Epoch 108/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4687 - accuracy: 0.1089 - val_loss: 3.4617 - val_accuracy: 0.1034\n",
            "Epoch 109/200\n",
            "88/88 [==============================] - 3s 35ms/step - loss: 3.4689 - accuracy: 0.1089 - val_loss: 3.4614 - val_accuracy: 0.1034\n",
            "Epoch 110/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 3.4686 - accuracy: 0.1089 - val_loss: 3.4613 - val_accuracy: 0.1034\n",
            "Epoch 111/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4681 - accuracy: 0.1089 - val_loss: 3.4615 - val_accuracy: 0.1034\n",
            "Epoch 112/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4738 - accuracy: 0.1089 - val_loss: 3.4614 - val_accuracy: 0.1034\n",
            "Epoch 113/200\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 3.4694 - accuracy: 0.1089 - val_loss: 3.4611 - val_accuracy: 0.1034\n",
            "Epoch 114/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4692 - accuracy: 0.1089 - val_loss: 3.4609 - val_accuracy: 0.1034\n",
            "Epoch 115/200\n",
            "88/88 [==============================] - 4s 40ms/step - loss: 3.4669 - accuracy: 0.1089 - val_loss: 3.4606 - val_accuracy: 0.1034\n",
            "Epoch 116/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4687 - accuracy: 0.1089 - val_loss: 3.4606 - val_accuracy: 0.1034\n",
            "Epoch 117/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4721 - accuracy: 0.1089 - val_loss: 3.4606 - val_accuracy: 0.1034\n",
            "Epoch 118/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4649 - accuracy: 0.1089 - val_loss: 3.4602 - val_accuracy: 0.1034\n",
            "Epoch 119/200\n",
            "88/88 [==============================] - 4s 42ms/step - loss: 3.4698 - accuracy: 0.1089 - val_loss: 3.4599 - val_accuracy: 0.1034\n",
            "Epoch 120/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 3.4698 - accuracy: 0.1089 - val_loss: 3.4595 - val_accuracy: 0.1034\n",
            "Epoch 121/200\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 3.4654 - accuracy: 0.1089 - val_loss: 3.4611 - val_accuracy: 0.1034\n",
            "Epoch 122/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4623 - accuracy: 0.1089 - val_loss: 3.4559 - val_accuracy: 0.1034\n",
            "Epoch 123/200\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 3.4459 - accuracy: 0.1074 - val_loss: 3.4411 - val_accuracy: 0.1149\n",
            "Epoch 124/200\n",
            "88/88 [==============================] - 4s 43ms/step - loss: 3.4164 - accuracy: 0.1060 - val_loss: 3.3871 - val_accuracy: 0.0920\n",
            "Epoch 125/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.3613 - accuracy: 0.1017 - val_loss: 3.3712 - val_accuracy: 0.1092\n",
            "Epoch 126/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4135 - accuracy: 0.1046 - val_loss: 3.3748 - val_accuracy: 0.1149\n",
            "Epoch 127/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.3628 - accuracy: 0.1003 - val_loss: 3.4322 - val_accuracy: 0.0977\n",
            "Epoch 128/200\n",
            "88/88 [==============================] - 3s 38ms/step - loss: 3.3217 - accuracy: 0.1089 - val_loss: 3.3502 - val_accuracy: 0.1149\n",
            "Epoch 129/200\n",
            "88/88 [==============================] - 3s 36ms/step - loss: 3.3347 - accuracy: 0.0874 - val_loss: 3.2827 - val_accuracy: 0.1092\n",
            "Epoch 130/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.2621 - accuracy: 0.1032 - val_loss: 3.3614 - val_accuracy: 0.0575\n",
            "Epoch 131/200\n",
            "88/88 [==============================] - 3s 36ms/step - loss: 3.2436 - accuracy: 0.1003 - val_loss: 3.3949 - val_accuracy: 0.1092\n",
            "Epoch 132/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.2212 - accuracy: 0.1189 - val_loss: 3.1887 - val_accuracy: 0.1379\n",
            "Epoch 133/200\n",
            "88/88 [==============================] - 4s 41ms/step - loss: 3.2311 - accuracy: 0.1032 - val_loss: 3.2793 - val_accuracy: 0.0862\n",
            "Epoch 134/200\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 3.1457 - accuracy: 0.1175 - val_loss: 3.1985 - val_accuracy: 0.1264\n",
            "Epoch 135/200\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 3.0928 - accuracy: 0.1203 - val_loss: 3.1745 - val_accuracy: 0.1207\n",
            "Epoch 136/200\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 3.0016 - accuracy: 0.1246 - val_loss: 3.2897 - val_accuracy: 0.1264\n",
            "Epoch 137/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 2.9574 - accuracy: 0.1361 - val_loss: 3.0767 - val_accuracy: 0.1264\n",
            "Epoch 138/200\n",
            "88/88 [==============================] - 3s 38ms/step - loss: 3.0378 - accuracy: 0.1203 - val_loss: 3.3704 - val_accuracy: 0.0977\n",
            "Epoch 139/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.0042 - accuracy: 0.1246 - val_loss: 3.1334 - val_accuracy: 0.1264\n",
            "Epoch 140/200\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 2.9972 - accuracy: 0.1390 - val_loss: 3.1931 - val_accuracy: 0.1149\n",
            "Epoch 141/200\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 3.0099 - accuracy: 0.1232 - val_loss: 3.1345 - val_accuracy: 0.1437\n",
            "Epoch 142/200\n",
            "88/88 [==============================] - 3s 40ms/step - loss: 2.8966 - accuracy: 0.1418 - val_loss: 3.4985 - val_accuracy: 0.1034\n",
            "Epoch 143/200\n",
            "88/88 [==============================] - 3s 38ms/step - loss: 2.8866 - accuracy: 0.1404 - val_loss: 3.3492 - val_accuracy: 0.1322\n",
            "Epoch 144/200\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 2.8126 - accuracy: 0.1476 - val_loss: 3.0487 - val_accuracy: 0.1552\n",
            "Epoch 145/200\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 2.7495 - accuracy: 0.1662 - val_loss: 2.9968 - val_accuracy: 0.1437\n",
            "Epoch 146/200\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 2.7069 - accuracy: 0.1819 - val_loss: 3.0565 - val_accuracy: 0.1207\n",
            "Epoch 147/200\n",
            "88/88 [==============================] - 4s 41ms/step - loss: 2.6619 - accuracy: 0.1934 - val_loss: 3.0327 - val_accuracy: 0.1437\n",
            "Epoch 148/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 2.6179 - accuracy: 0.2034 - val_loss: 2.9929 - val_accuracy: 0.1379\n",
            "Epoch 149/200\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 2.6034 - accuracy: 0.2077 - val_loss: 3.1329 - val_accuracy: 0.1667\n",
            "Epoch 150/200\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 2.5817 - accuracy: 0.2120 - val_loss: 2.9739 - val_accuracy: 0.1552\n",
            "Epoch 151/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.1049 - accuracy: 0.1490 - val_loss: 3.5780 - val_accuracy: 0.1034\n",
            "Epoch 152/200\n",
            "88/88 [==============================] - 4s 42ms/step - loss: 3.5211 - accuracy: 0.1003 - val_loss: 3.4768 - val_accuracy: 0.0690\n",
            "Epoch 153/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4029 - accuracy: 0.1046 - val_loss: 3.2594 - val_accuracy: 0.1322\n",
            "Epoch 154/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 3.1455 - accuracy: 0.1074 - val_loss: 3.2022 - val_accuracy: 0.1379\n",
            "Epoch 155/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 2.9478 - accuracy: 0.1404 - val_loss: 3.0356 - val_accuracy: 0.1264\n",
            "Epoch 156/200\n",
            "88/88 [==============================] - 3s 40ms/step - loss: 2.7739 - accuracy: 0.1748 - val_loss: 2.9842 - val_accuracy: 0.1552\n",
            "Epoch 157/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 2.7256 - accuracy: 0.1676 - val_loss: 3.0926 - val_accuracy: 0.1667\n",
            "Epoch 158/200\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 2.6469 - accuracy: 0.1948 - val_loss: 2.9624 - val_accuracy: 0.1437\n",
            "Epoch 159/200\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 2.5866 - accuracy: 0.2006 - val_loss: 2.9467 - val_accuracy: 0.1552\n",
            "Epoch 160/200\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 2.5721 - accuracy: 0.2192 - val_loss: 3.0971 - val_accuracy: 0.1609\n",
            "Epoch 161/200\n",
            "88/88 [==============================] - 4s 41ms/step - loss: 2.5232 - accuracy: 0.2120 - val_loss: 3.0220 - val_accuracy: 0.1667\n",
            "Epoch 162/200\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 2.4882 - accuracy: 0.2307 - val_loss: 2.9984 - val_accuracy: 0.1552\n",
            "Epoch 163/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 2.4443 - accuracy: 0.2364 - val_loss: 3.1023 - val_accuracy: 0.1264\n",
            "Epoch 164/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 2.4255 - accuracy: 0.2464 - val_loss: 3.0706 - val_accuracy: 0.1494\n",
            "Epoch 165/200\n",
            "88/88 [==============================] - 3s 36ms/step - loss: 2.3966 - accuracy: 0.2249 - val_loss: 3.1931 - val_accuracy: 0.1667\n",
            "Epoch 166/200\n",
            "88/88 [==============================] - 4s 42ms/step - loss: 2.4360 - accuracy: 0.2292 - val_loss: 3.1120 - val_accuracy: 0.1609\n",
            "Epoch 167/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 2.3702 - accuracy: 0.2536 - val_loss: 3.3125 - val_accuracy: 0.1839\n",
            "Epoch 168/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 2.2924 - accuracy: 0.2607 - val_loss: 3.1978 - val_accuracy: 0.1379\n",
            "Epoch 169/200\n",
            "88/88 [==============================] - 4s 44ms/step - loss: 2.3274 - accuracy: 0.2378 - val_loss: 3.1591 - val_accuracy: 0.1494\n",
            "Epoch 170/200\n",
            "88/88 [==============================] - 4s 42ms/step - loss: 2.2682 - accuracy: 0.2693 - val_loss: 3.3424 - val_accuracy: 0.1552\n",
            "Epoch 171/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 2.2825 - accuracy: 0.2607 - val_loss: 3.2069 - val_accuracy: 0.1379\n",
            "Epoch 172/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 2.2473 - accuracy: 0.2708 - val_loss: 3.1689 - val_accuracy: 0.1667\n",
            "Epoch 173/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 2.1933 - accuracy: 0.2693 - val_loss: 3.2525 - val_accuracy: 0.1782\n",
            "Epoch 174/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 2.2243 - accuracy: 0.2894 - val_loss: 3.3046 - val_accuracy: 0.2069\n",
            "Epoch 175/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 2.2674 - accuracy: 0.2822 - val_loss: 3.1541 - val_accuracy: 0.2241\n",
            "Epoch 176/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 2.1919 - accuracy: 0.2808 - val_loss: 3.2683 - val_accuracy: 0.1379\n",
            "Epoch 177/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 2.2150 - accuracy: 0.2923 - val_loss: 3.4496 - val_accuracy: 0.1609\n",
            "Epoch 178/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 2.1491 - accuracy: 0.2980 - val_loss: 3.4043 - val_accuracy: 0.1954\n",
            "Epoch 179/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 2.1185 - accuracy: 0.3023 - val_loss: 3.2086 - val_accuracy: 0.2011\n",
            "Epoch 180/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 2.1374 - accuracy: 0.2923 - val_loss: 3.3060 - val_accuracy: 0.2126\n",
            "Epoch 181/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 2.1004 - accuracy: 0.2951 - val_loss: 3.5163 - val_accuracy: 0.1954\n",
            "Epoch 182/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 2.0336 - accuracy: 0.3109 - val_loss: 3.6082 - val_accuracy: 0.1552\n",
            "Epoch 183/200\n",
            "88/88 [==============================] - 4s 43ms/step - loss: 2.0145 - accuracy: 0.3095 - val_loss: 3.4640 - val_accuracy: 0.1839\n",
            "Epoch 184/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 2.0236 - accuracy: 0.3367 - val_loss: 3.4505 - val_accuracy: 0.1782\n",
            "Epoch 185/200\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 2.0034 - accuracy: 0.3381 - val_loss: 3.4221 - val_accuracy: 0.2011\n",
            "Epoch 186/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 1.9834 - accuracy: 0.3352 - val_loss: 3.4387 - val_accuracy: 0.2126\n",
            "Epoch 187/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 1.9948 - accuracy: 0.3252 - val_loss: 3.5115 - val_accuracy: 0.2069\n",
            "Epoch 188/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 1.9589 - accuracy: 0.3524 - val_loss: 3.7596 - val_accuracy: 0.2126\n",
            "Epoch 189/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 1.9820 - accuracy: 0.3381 - val_loss: 3.5723 - val_accuracy: 0.2011\n",
            "Epoch 190/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 1.9363 - accuracy: 0.3381 - val_loss: 3.6061 - val_accuracy: 0.2069\n",
            "Epoch 191/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 1.9412 - accuracy: 0.3653 - val_loss: 3.5659 - val_accuracy: 0.2011\n",
            "Epoch 192/200\n",
            "88/88 [==============================] - 4s 41ms/step - loss: 1.9365 - accuracy: 0.3739 - val_loss: 3.6411 - val_accuracy: 0.1839\n",
            "Epoch 193/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.9689 - accuracy: 0.3281 - val_loss: 3.5671 - val_accuracy: 0.2069\n",
            "Epoch 194/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 1.9306 - accuracy: 0.3840 - val_loss: 3.4643 - val_accuracy: 0.2356\n",
            "Epoch 195/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 1.9255 - accuracy: 0.3524 - val_loss: 3.5934 - val_accuracy: 0.1954\n",
            "Epoch 196/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 1.9106 - accuracy: 0.3797 - val_loss: 3.5245 - val_accuracy: 0.1954\n",
            "Epoch 197/200\n",
            "88/88 [==============================] - 4s 44ms/step - loss: 1.8625 - accuracy: 0.3897 - val_loss: 3.6550 - val_accuracy: 0.1782\n",
            "Epoch 198/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 1.8319 - accuracy: 0.3782 - val_loss: 3.7271 - val_accuracy: 0.1609\n",
            "Epoch 199/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.8437 - accuracy: 0.3610 - val_loss: 3.8523 - val_accuracy: 0.2126\n",
            "Epoch 200/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 1.8921 - accuracy: 0.3711 - val_loss: 3.4946 - val_accuracy: 0.2069\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 3.4946 - accuracy: 0.2069\n",
            "Epoch 1/200\n",
            "88/88 [==============================] - 6s 38ms/step - loss: 3.5944 - accuracy: 0.0960 - val_loss: 3.4906 - val_accuracy: 0.1092\n",
            "Epoch 2/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.5310 - accuracy: 0.1032 - val_loss: 3.4767 - val_accuracy: 0.1092\n",
            "Epoch 3/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.5145 - accuracy: 0.1017 - val_loss: 3.4769 - val_accuracy: 0.1092\n",
            "Epoch 4/200\n",
            "88/88 [==============================] - 4s 40ms/step - loss: 3.5016 - accuracy: 0.1017 - val_loss: 3.4786 - val_accuracy: 0.1092\n",
            "Epoch 5/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.5027 - accuracy: 0.1032 - val_loss: 3.4731 - val_accuracy: 0.1092\n",
            "Epoch 6/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4970 - accuracy: 0.0974 - val_loss: 3.4737 - val_accuracy: 0.1092\n",
            "Epoch 7/200\n",
            "88/88 [==============================] - 3s 35ms/step - loss: 3.4884 - accuracy: 0.1074 - val_loss: 3.4751 - val_accuracy: 0.1092\n",
            "Epoch 8/200\n",
            "88/88 [==============================] - 4s 41ms/step - loss: 3.5002 - accuracy: 0.0931 - val_loss: 3.4759 - val_accuracy: 0.1092\n",
            "Epoch 9/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4902 - accuracy: 0.0931 - val_loss: 3.4699 - val_accuracy: 0.1092\n",
            "Epoch 10/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4853 - accuracy: 0.1017 - val_loss: 3.4720 - val_accuracy: 0.1092\n",
            "Epoch 11/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4834 - accuracy: 0.1046 - val_loss: 3.4693 - val_accuracy: 0.1092\n",
            "Epoch 12/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 3.4781 - accuracy: 0.1060 - val_loss: 3.4682 - val_accuracy: 0.1092\n",
            "Epoch 13/200\n",
            "88/88 [==============================] - 3s 40ms/step - loss: 3.4836 - accuracy: 0.1074 - val_loss: 3.4715 - val_accuracy: 0.1092\n",
            "Epoch 14/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4833 - accuracy: 0.0974 - val_loss: 3.4705 - val_accuracy: 0.1092\n",
            "Epoch 15/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4881 - accuracy: 0.1074 - val_loss: 3.4695 - val_accuracy: 0.1092\n",
            "Epoch 16/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4867 - accuracy: 0.1060 - val_loss: 3.4683 - val_accuracy: 0.1092\n",
            "Epoch 17/200\n",
            "88/88 [==============================] - 4s 41ms/step - loss: 3.4782 - accuracy: 0.1074 - val_loss: 3.4670 - val_accuracy: 0.1092\n",
            "Epoch 18/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 3.4799 - accuracy: 0.1074 - val_loss: 3.4700 - val_accuracy: 0.1092\n",
            "Epoch 19/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4841 - accuracy: 0.1060 - val_loss: 3.4688 - val_accuracy: 0.1092\n",
            "Epoch 20/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4781 - accuracy: 0.1074 - val_loss: 3.4685 - val_accuracy: 0.1092\n",
            "Epoch 21/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4749 - accuracy: 0.1074 - val_loss: 3.4672 - val_accuracy: 0.1092\n",
            "Epoch 22/200\n",
            "88/88 [==============================] - 4s 43ms/step - loss: 3.4794 - accuracy: 0.1060 - val_loss: 3.4687 - val_accuracy: 0.1092\n",
            "Epoch 23/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4818 - accuracy: 0.1074 - val_loss: 3.4690 - val_accuracy: 0.1092\n",
            "Epoch 24/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4766 - accuracy: 0.1074 - val_loss: 3.4685 - val_accuracy: 0.1092\n",
            "Epoch 25/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4822 - accuracy: 0.1074 - val_loss: 3.4691 - val_accuracy: 0.1092\n",
            "Epoch 26/200\n",
            "88/88 [==============================] - 3s 35ms/step - loss: 3.4770 - accuracy: 0.1074 - val_loss: 3.4692 - val_accuracy: 0.1092\n",
            "Epoch 27/200\n",
            "88/88 [==============================] - 3s 38ms/step - loss: 3.4780 - accuracy: 0.1074 - val_loss: 3.4671 - val_accuracy: 0.1092\n",
            "Epoch 28/200\n",
            "88/88 [==============================] - 3s 36ms/step - loss: 3.4774 - accuracy: 0.1074 - val_loss: 3.4672 - val_accuracy: 0.1092\n",
            "Epoch 29/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 3.4662 - accuracy: 0.1074 - val_loss: 3.4706 - val_accuracy: 0.1092\n",
            "Epoch 30/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4829 - accuracy: 0.1060 - val_loss: 3.4693 - val_accuracy: 0.1092\n",
            "Epoch 31/200\n",
            "88/88 [==============================] - 4s 43ms/step - loss: 3.4797 - accuracy: 0.1074 - val_loss: 3.4685 - val_accuracy: 0.1092\n",
            "Epoch 32/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4710 - accuracy: 0.1074 - val_loss: 3.4688 - val_accuracy: 0.1092\n",
            "Epoch 33/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4712 - accuracy: 0.1074 - val_loss: 3.4679 - val_accuracy: 0.1092\n",
            "Epoch 34/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4760 - accuracy: 0.1074 - val_loss: 3.4664 - val_accuracy: 0.1092\n",
            "Epoch 35/200\n",
            "88/88 [==============================] - 3s 38ms/step - loss: 3.4755 - accuracy: 0.1074 - val_loss: 3.4663 - val_accuracy: 0.1092\n",
            "Epoch 36/200\n",
            "88/88 [==============================] - 3s 35ms/step - loss: 3.4736 - accuracy: 0.1074 - val_loss: 3.4655 - val_accuracy: 0.1092\n",
            "Epoch 37/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4738 - accuracy: 0.1074 - val_loss: 3.4622 - val_accuracy: 0.1092\n",
            "Epoch 38/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4602 - accuracy: 0.1060 - val_loss: 3.4235 - val_accuracy: 0.1092\n",
            "Epoch 39/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 3.4137 - accuracy: 0.1060 - val_loss: 3.4331 - val_accuracy: 0.0805\n",
            "Epoch 40/200\n",
            "88/88 [==============================] - 4s 40ms/step - loss: 3.3907 - accuracy: 0.1132 - val_loss: 3.3572 - val_accuracy: 0.0805\n",
            "Epoch 41/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.3671 - accuracy: 0.0831 - val_loss: 3.3403 - val_accuracy: 0.1092\n",
            "Epoch 42/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.3614 - accuracy: 0.0974 - val_loss: 3.3053 - val_accuracy: 0.0575\n",
            "Epoch 43/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.3161 - accuracy: 0.0946 - val_loss: 3.2975 - val_accuracy: 0.1207\n",
            "Epoch 44/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 3.3003 - accuracy: 0.0931 - val_loss: 3.2914 - val_accuracy: 0.1264\n",
            "Epoch 45/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 3.2396 - accuracy: 0.1046 - val_loss: 3.2626 - val_accuracy: 0.1264\n",
            "Epoch 46/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.2006 - accuracy: 0.1232 - val_loss: 3.2666 - val_accuracy: 0.0977\n",
            "Epoch 47/200\n",
            "88/88 [==============================] - 3s 36ms/step - loss: 3.2016 - accuracy: 0.1060 - val_loss: 3.2172 - val_accuracy: 0.1092\n",
            "Epoch 48/200\n",
            "88/88 [==============================] - 3s 35ms/step - loss: 3.1132 - accuracy: 0.1261 - val_loss: 3.1595 - val_accuracy: 0.1379\n",
            "Epoch 49/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 3.0878 - accuracy: 0.1160 - val_loss: 3.0854 - val_accuracy: 0.1264\n",
            "Epoch 50/200\n",
            "88/88 [==============================] - 3s 35ms/step - loss: 3.0179 - accuracy: 0.1246 - val_loss: 3.1806 - val_accuracy: 0.1034\n",
            "Epoch 51/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.0137 - accuracy: 0.1275 - val_loss: 3.4345 - val_accuracy: 0.1207\n",
            "Epoch 52/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 2.9269 - accuracy: 0.1619 - val_loss: 3.0940 - val_accuracy: 0.1437\n",
            "Epoch 53/200\n",
            "88/88 [==============================] - 4s 44ms/step - loss: 2.8966 - accuracy: 0.1461 - val_loss: 3.0283 - val_accuracy: 0.1379\n",
            "Epoch 54/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 2.8431 - accuracy: 0.1447 - val_loss: 3.0471 - val_accuracy: 0.1264\n",
            "Epoch 55/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 2.8747 - accuracy: 0.1576 - val_loss: 3.1829 - val_accuracy: 0.1437\n",
            "Epoch 56/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 2.8270 - accuracy: 0.1676 - val_loss: 2.9973 - val_accuracy: 0.1379\n",
            "Epoch 57/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 2.7680 - accuracy: 0.1705 - val_loss: 3.3463 - val_accuracy: 0.1207\n",
            "Epoch 58/200\n",
            "88/88 [==============================] - 3s 38ms/step - loss: 2.7689 - accuracy: 0.1762 - val_loss: 3.1184 - val_accuracy: 0.1264\n",
            "Epoch 59/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 2.6962 - accuracy: 0.1848 - val_loss: 3.0912 - val_accuracy: 0.1437\n",
            "Epoch 60/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 2.6989 - accuracy: 0.1819 - val_loss: 3.0113 - val_accuracy: 0.1667\n",
            "Epoch 61/200\n",
            "88/88 [==============================] - 3s 35ms/step - loss: 2.6863 - accuracy: 0.1848 - val_loss: 3.0121 - val_accuracy: 0.1897\n",
            "Epoch 62/200\n",
            "88/88 [==============================] - 4s 43ms/step - loss: 2.6268 - accuracy: 0.1905 - val_loss: 3.0473 - val_accuracy: 0.1667\n",
            "Epoch 63/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 2.5699 - accuracy: 0.2092 - val_loss: 3.1337 - val_accuracy: 0.1897\n",
            "Epoch 64/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 2.6237 - accuracy: 0.2249 - val_loss: 3.0516 - val_accuracy: 0.1897\n",
            "Epoch 65/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 2.5558 - accuracy: 0.2321 - val_loss: 3.0724 - val_accuracy: 0.1724\n",
            "Epoch 66/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 2.5427 - accuracy: 0.2278 - val_loss: 3.0691 - val_accuracy: 0.1322\n",
            "Epoch 67/200\n",
            "88/88 [==============================] - 3s 35ms/step - loss: 2.5245 - accuracy: 0.2192 - val_loss: 3.3881 - val_accuracy: 0.1437\n",
            "Epoch 68/200\n",
            "88/88 [==============================] - 3s 35ms/step - loss: 2.5648 - accuracy: 0.2178 - val_loss: 3.0745 - val_accuracy: 0.1897\n",
            "Epoch 69/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 2.4423 - accuracy: 0.2321 - val_loss: 3.1018 - val_accuracy: 0.1494\n",
            "Epoch 70/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 2.3654 - accuracy: 0.2822 - val_loss: 3.4181 - val_accuracy: 0.2011\n",
            "Epoch 71/200\n",
            "88/88 [==============================] - 5s 55ms/step - loss: 2.3801 - accuracy: 0.2622 - val_loss: 3.1553 - val_accuracy: 0.1897\n",
            "Epoch 72/200\n",
            "88/88 [==============================] - 4s 43ms/step - loss: 2.3866 - accuracy: 0.2550 - val_loss: 3.1556 - val_accuracy: 0.1724\n",
            "Epoch 73/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 2.3955 - accuracy: 0.2507 - val_loss: 3.1160 - val_accuracy: 0.1609\n",
            "Epoch 74/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 2.4056 - accuracy: 0.2450 - val_loss: 3.3320 - val_accuracy: 0.1724\n",
            "Epoch 75/200\n",
            "88/88 [==============================] - 4s 42ms/step - loss: 2.3129 - accuracy: 0.2622 - val_loss: 3.2347 - val_accuracy: 0.1552\n",
            "Epoch 76/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 2.2709 - accuracy: 0.2822 - val_loss: 3.2506 - val_accuracy: 0.1954\n",
            "Epoch 77/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 2.6782 - accuracy: 0.2450 - val_loss: 3.7327 - val_accuracy: 0.1207\n",
            "Epoch 78/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 2.9088 - accuracy: 0.1891 - val_loss: 3.2039 - val_accuracy: 0.1437\n",
            "Epoch 79/200\n",
            "88/88 [==============================] - 3s 38ms/step - loss: 2.5725 - accuracy: 0.2493 - val_loss: 3.1059 - val_accuracy: 0.1782\n",
            "Epoch 80/200\n",
            "88/88 [==============================] - 4s 50ms/step - loss: 2.4398 - accuracy: 0.2407 - val_loss: 3.1420 - val_accuracy: 0.1724\n",
            "Epoch 81/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 2.3783 - accuracy: 0.2564 - val_loss: 3.1666 - val_accuracy: 0.1839\n",
            "Epoch 82/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 2.2955 - accuracy: 0.2779 - val_loss: 3.2621 - val_accuracy: 0.1782\n",
            "Epoch 83/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 2.1927 - accuracy: 0.3023 - val_loss: 3.1659 - val_accuracy: 0.2184\n",
            "Epoch 84/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 2.2065 - accuracy: 0.2994 - val_loss: 3.3458 - val_accuracy: 0.2126\n",
            "Epoch 85/200\n",
            "88/88 [==============================] - 4s 40ms/step - loss: 2.1825 - accuracy: 0.3080 - val_loss: 3.2220 - val_accuracy: 0.1954\n",
            "Epoch 86/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 2.1764 - accuracy: 0.2636 - val_loss: 3.2611 - val_accuracy: 0.2356\n",
            "Epoch 87/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 2.1370 - accuracy: 0.3109 - val_loss: 3.2042 - val_accuracy: 0.2184\n",
            "Epoch 88/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 2.1219 - accuracy: 0.3123 - val_loss: 3.3503 - val_accuracy: 0.1954\n",
            "Epoch 89/200\n",
            "88/88 [==============================] - 4s 41ms/step - loss: 2.0814 - accuracy: 0.3223 - val_loss: 3.4583 - val_accuracy: 0.1494\n",
            "Epoch 90/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 2.1559 - accuracy: 0.3066 - val_loss: 3.3920 - val_accuracy: 0.1954\n",
            "Epoch 91/200\n",
            "88/88 [==============================] - 4s 45ms/step - loss: 2.1108 - accuracy: 0.3238 - val_loss: 3.3475 - val_accuracy: 0.2069\n",
            "Epoch 92/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 1.9617 - accuracy: 0.3381 - val_loss: 3.4440 - val_accuracy: 0.2011\n",
            "Epoch 93/200\n",
            "88/88 [==============================] - 5s 53ms/step - loss: 2.0289 - accuracy: 0.3424 - val_loss: 3.4650 - val_accuracy: 0.2011\n",
            "Epoch 94/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 2.0167 - accuracy: 0.3281 - val_loss: 3.4164 - val_accuracy: 0.2356\n",
            "Epoch 95/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 2.0088 - accuracy: 0.3309 - val_loss: 3.4958 - val_accuracy: 0.2126\n",
            "Epoch 96/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.9982 - accuracy: 0.3324 - val_loss: 3.4228 - val_accuracy: 0.2011\n",
            "Epoch 97/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 1.9526 - accuracy: 0.3725 - val_loss: 3.5101 - val_accuracy: 0.1839\n",
            "Epoch 98/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 1.9448 - accuracy: 0.3524 - val_loss: 3.5001 - val_accuracy: 0.2011\n",
            "Epoch 99/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 1.9156 - accuracy: 0.3696 - val_loss: 3.6337 - val_accuracy: 0.2011\n",
            "Epoch 100/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.9849 - accuracy: 0.3367 - val_loss: 3.4740 - val_accuracy: 0.2184\n",
            "Epoch 101/200\n",
            "88/88 [==============================] - 3s 40ms/step - loss: 1.9227 - accuracy: 0.3610 - val_loss: 3.5707 - val_accuracy: 0.2069\n",
            "Epoch 102/200\n",
            "88/88 [==============================] - 4s 44ms/step - loss: 1.9268 - accuracy: 0.3496 - val_loss: 3.6323 - val_accuracy: 0.1897\n",
            "Epoch 103/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.8826 - accuracy: 0.3754 - val_loss: 3.5092 - val_accuracy: 0.2299\n",
            "Epoch 104/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.8436 - accuracy: 0.3754 - val_loss: 3.5715 - val_accuracy: 0.2126\n",
            "Epoch 105/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.9410 - accuracy: 0.3610 - val_loss: 3.6359 - val_accuracy: 0.2126\n",
            "Epoch 106/200\n",
            "88/88 [==============================] - 4s 40ms/step - loss: 2.0383 - accuracy: 0.3510 - val_loss: 3.4990 - val_accuracy: 0.2471\n",
            "Epoch 107/200\n",
            "88/88 [==============================] - 3s 35ms/step - loss: 1.8943 - accuracy: 0.3696 - val_loss: 3.5164 - val_accuracy: 0.2241\n",
            "Epoch 108/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.8555 - accuracy: 0.3754 - val_loss: 3.6594 - val_accuracy: 0.2126\n",
            "Epoch 109/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.7900 - accuracy: 0.4140 - val_loss: 3.8396 - val_accuracy: 0.1954\n",
            "Epoch 110/200\n",
            "88/88 [==============================] - 3s 35ms/step - loss: 1.7796 - accuracy: 0.4140 - val_loss: 3.6772 - val_accuracy: 0.2069\n",
            "Epoch 111/200\n",
            "88/88 [==============================] - 4s 41ms/step - loss: 1.7732 - accuracy: 0.4269 - val_loss: 3.8724 - val_accuracy: 0.2126\n",
            "Epoch 112/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 1.7333 - accuracy: 0.4269 - val_loss: 3.6679 - val_accuracy: 0.2069\n",
            "Epoch 113/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 2.4128 - accuracy: 0.2951 - val_loss: 3.2454 - val_accuracy: 0.1954\n",
            "Epoch 114/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 2.0974 - accuracy: 0.3481 - val_loss: 3.1202 - val_accuracy: 0.2126\n",
            "Epoch 115/200\n",
            "88/88 [==============================] - 4s 43ms/step - loss: 1.9112 - accuracy: 0.3739 - val_loss: 3.4335 - val_accuracy: 0.2011\n",
            "Epoch 116/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.8803 - accuracy: 0.4097 - val_loss: 3.2925 - val_accuracy: 0.2529\n",
            "Epoch 117/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.8713 - accuracy: 0.3782 - val_loss: 3.4079 - val_accuracy: 0.1839\n",
            "Epoch 118/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.7993 - accuracy: 0.4083 - val_loss: 3.4445 - val_accuracy: 0.2356\n",
            "Epoch 119/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 1.7793 - accuracy: 0.4054 - val_loss: 3.5154 - val_accuracy: 0.2069\n",
            "Epoch 120/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 1.7835 - accuracy: 0.4069 - val_loss: 3.4538 - val_accuracy: 0.2471\n",
            "Epoch 121/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.7413 - accuracy: 0.4255 - val_loss: 3.6774 - val_accuracy: 0.1954\n",
            "Epoch 122/200\n",
            "88/88 [==============================] - 3s 36ms/step - loss: 1.8146 - accuracy: 0.4011 - val_loss: 3.5392 - val_accuracy: 0.2184\n",
            "Epoch 123/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 1.7118 - accuracy: 0.4470 - val_loss: 3.5568 - val_accuracy: 0.2414\n",
            "Epoch 124/200\n",
            "88/88 [==============================] - 3s 38ms/step - loss: 1.6808 - accuracy: 0.4298 - val_loss: 3.5027 - val_accuracy: 0.2241\n",
            "Epoch 125/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 1.6897 - accuracy: 0.4513 - val_loss: 3.8032 - val_accuracy: 0.2241\n",
            "Epoch 126/200\n",
            "88/88 [==============================] - 3s 36ms/step - loss: 1.6835 - accuracy: 0.4370 - val_loss: 3.5784 - val_accuracy: 0.2356\n",
            "Epoch 127/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 1.6222 - accuracy: 0.4685 - val_loss: 3.8826 - val_accuracy: 0.2011\n",
            "Epoch 128/200\n",
            "88/88 [==============================] - 4s 41ms/step - loss: 1.6696 - accuracy: 0.4298 - val_loss: 3.7911 - val_accuracy: 0.2126\n",
            "Epoch 129/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.6051 - accuracy: 0.4527 - val_loss: 3.7937 - val_accuracy: 0.2184\n",
            "Epoch 130/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.6232 - accuracy: 0.4513 - val_loss: 3.8522 - val_accuracy: 0.2184\n",
            "Epoch 131/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.5963 - accuracy: 0.4642 - val_loss: 3.7456 - val_accuracy: 0.2356\n",
            "Epoch 132/200\n",
            "88/88 [==============================] - 4s 43ms/step - loss: 1.5882 - accuracy: 0.4685 - val_loss: 3.7064 - val_accuracy: 0.2241\n",
            "Epoch 133/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 1.7015 - accuracy: 0.4370 - val_loss: 3.6264 - val_accuracy: 0.2356\n",
            "Epoch 134/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.6522 - accuracy: 0.4613 - val_loss: 3.7270 - val_accuracy: 0.2414\n",
            "Epoch 135/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.6453 - accuracy: 0.4685 - val_loss: 4.2660 - val_accuracy: 0.2184\n",
            "Epoch 136/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.7674 - accuracy: 0.4527 - val_loss: 3.9286 - val_accuracy: 0.2414\n",
            "Epoch 137/200\n",
            "88/88 [==============================] - 4s 44ms/step - loss: 1.5387 - accuracy: 0.4814 - val_loss: 3.7930 - val_accuracy: 0.2299\n",
            "Epoch 138/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.5246 - accuracy: 0.4799 - val_loss: 4.3232 - val_accuracy: 0.2011\n",
            "Epoch 139/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.6414 - accuracy: 0.4599 - val_loss: 3.6639 - val_accuracy: 0.2471\n",
            "Epoch 140/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.4172 - accuracy: 0.5072 - val_loss: 3.9287 - val_accuracy: 0.2356\n",
            "Epoch 141/200\n",
            "88/88 [==============================] - 3s 38ms/step - loss: 1.5136 - accuracy: 0.4914 - val_loss: 4.0778 - val_accuracy: 0.2126\n",
            "Epoch 142/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 1.5516 - accuracy: 0.4628 - val_loss: 3.9913 - val_accuracy: 0.2471\n",
            "Epoch 143/200\n",
            "88/88 [==============================] - 3s 35ms/step - loss: 1.5064 - accuracy: 0.4771 - val_loss: 3.9378 - val_accuracy: 0.2184\n",
            "Epoch 144/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.7444 - accuracy: 0.4413 - val_loss: 4.1334 - val_accuracy: 0.2126\n",
            "Epoch 145/200\n",
            "88/88 [==============================] - 3s 35ms/step - loss: 1.6257 - accuracy: 0.4685 - val_loss: 4.0193 - val_accuracy: 0.2069\n",
            "Epoch 146/200\n",
            "88/88 [==============================] - 4s 40ms/step - loss: 1.5243 - accuracy: 0.4971 - val_loss: 3.9793 - val_accuracy: 0.2241\n",
            "Epoch 147/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.4554 - accuracy: 0.5415 - val_loss: 4.1585 - val_accuracy: 0.1954\n",
            "Epoch 148/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 1.3936 - accuracy: 0.5344 - val_loss: 4.2255 - val_accuracy: 0.2471\n",
            "Epoch 149/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.3811 - accuracy: 0.5201 - val_loss: 4.0611 - val_accuracy: 0.2184\n",
            "Epoch 150/200\n",
            "88/88 [==============================] - 4s 43ms/step - loss: 1.3545 - accuracy: 0.5430 - val_loss: 4.2057 - val_accuracy: 0.2299\n",
            "Epoch 151/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.5199 - accuracy: 0.4828 - val_loss: 4.1989 - val_accuracy: 0.2299\n",
            "Epoch 152/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.4066 - accuracy: 0.5158 - val_loss: 4.2693 - val_accuracy: 0.1954\n",
            "Epoch 153/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.3336 - accuracy: 0.5501 - val_loss: 4.3822 - val_accuracy: 0.2184\n",
            "Epoch 154/200\n",
            "88/88 [==============================] - 4s 43ms/step - loss: 1.3835 - accuracy: 0.5344 - val_loss: 4.3096 - val_accuracy: 0.2126\n",
            "Epoch 155/200\n",
            "88/88 [==============================] - 3s 36ms/step - loss: 1.3647 - accuracy: 0.5358 - val_loss: 4.2053 - val_accuracy: 0.2356\n",
            "Epoch 156/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.2965 - accuracy: 0.5501 - val_loss: 4.3889 - val_accuracy: 0.2184\n",
            "Epoch 157/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.3194 - accuracy: 0.5573 - val_loss: 4.2623 - val_accuracy: 0.2184\n",
            "Epoch 158/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.3169 - accuracy: 0.5745 - val_loss: 4.3130 - val_accuracy: 0.2471\n",
            "Epoch 159/200\n",
            "88/88 [==============================] - 4s 44ms/step - loss: 1.2345 - accuracy: 0.5903 - val_loss: 4.2578 - val_accuracy: 0.2241\n",
            "Epoch 160/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.2769 - accuracy: 0.5716 - val_loss: 4.3741 - val_accuracy: 0.2241\n",
            "Epoch 161/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.3215 - accuracy: 0.5573 - val_loss: 4.4624 - val_accuracy: 0.2126\n",
            "Epoch 162/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 1.3589 - accuracy: 0.5215 - val_loss: 4.2389 - val_accuracy: 0.2241\n",
            "Epoch 163/200\n",
            "88/88 [==============================] - 3s 38ms/step - loss: 1.3191 - accuracy: 0.5487 - val_loss: 4.3679 - val_accuracy: 0.2184\n",
            "Epoch 164/200\n",
            "88/88 [==============================] - 4s 41ms/step - loss: 1.2797 - accuracy: 0.5716 - val_loss: 4.4601 - val_accuracy: 0.2184\n",
            "Epoch 165/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.2915 - accuracy: 0.5630 - val_loss: 4.5438 - val_accuracy: 0.2414\n",
            "Epoch 166/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.1867 - accuracy: 0.5802 - val_loss: 4.5465 - val_accuracy: 0.2241\n",
            "Epoch 167/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.2737 - accuracy: 0.5616 - val_loss: 4.6460 - val_accuracy: 0.2299\n",
            "Epoch 168/200\n",
            "88/88 [==============================] - 4s 44ms/step - loss: 1.2969 - accuracy: 0.5659 - val_loss: 4.5685 - val_accuracy: 0.1954\n",
            "Epoch 169/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.2433 - accuracy: 0.5731 - val_loss: 4.2848 - val_accuracy: 0.2184\n",
            "Epoch 170/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.4526 - accuracy: 0.5344 - val_loss: 4.3780 - val_accuracy: 0.2356\n",
            "Epoch 171/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.4174 - accuracy: 0.5344 - val_loss: 4.2886 - val_accuracy: 0.2414\n",
            "Epoch 172/200\n",
            "88/88 [==============================] - 3s 38ms/step - loss: 1.2991 - accuracy: 0.5788 - val_loss: 4.5293 - val_accuracy: 0.2069\n",
            "Epoch 173/200\n",
            "88/88 [==============================] - 3s 36ms/step - loss: 1.2258 - accuracy: 0.5774 - val_loss: 4.5204 - val_accuracy: 0.2184\n",
            "Epoch 174/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 1.2607 - accuracy: 0.5688 - val_loss: 4.3591 - val_accuracy: 0.2184\n",
            "Epoch 175/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 1.2467 - accuracy: 0.5874 - val_loss: 4.6449 - val_accuracy: 0.2184\n",
            "Epoch 176/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 1.1760 - accuracy: 0.5989 - val_loss: 4.6534 - val_accuracy: 0.2356\n",
            "Epoch 177/200\n",
            "88/88 [==============================] - 4s 43ms/step - loss: 1.1831 - accuracy: 0.5917 - val_loss: 4.7048 - val_accuracy: 0.2471\n",
            "Epoch 178/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 1.3456 - accuracy: 0.5688 - val_loss: 5.0437 - val_accuracy: 0.1609\n",
            "Epoch 179/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.4968 - accuracy: 0.5387 - val_loss: 4.7116 - val_accuracy: 0.2126\n",
            "Epoch 180/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.2892 - accuracy: 0.5831 - val_loss: 4.6608 - val_accuracy: 0.2184\n",
            "Epoch 181/200\n",
            "88/88 [==============================] - 4s 45ms/step - loss: 1.4407 - accuracy: 0.5444 - val_loss: 4.3500 - val_accuracy: 0.1897\n",
            "Epoch 182/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.3527 - accuracy: 0.5057 - val_loss: 4.3822 - val_accuracy: 0.2126\n",
            "Epoch 183/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.2088 - accuracy: 0.5845 - val_loss: 4.5875 - val_accuracy: 0.2011\n",
            "Epoch 184/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.1905 - accuracy: 0.5960 - val_loss: 4.6221 - val_accuracy: 0.2184\n",
            "Epoch 185/200\n",
            "88/88 [==============================] - 4s 43ms/step - loss: 1.1614 - accuracy: 0.5903 - val_loss: 4.7330 - val_accuracy: 0.2126\n",
            "Epoch 186/200\n",
            "88/88 [==============================] - 4s 40ms/step - loss: 1.1993 - accuracy: 0.5759 - val_loss: 4.7791 - val_accuracy: 0.2069\n",
            "Epoch 187/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.1328 - accuracy: 0.6046 - val_loss: 4.9167 - val_accuracy: 0.1782\n",
            "Epoch 188/200\n",
            "88/88 [==============================] - 4s 43ms/step - loss: 1.1360 - accuracy: 0.6103 - val_loss: 4.9801 - val_accuracy: 0.2011\n",
            "Epoch 189/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 1.1802 - accuracy: 0.5860 - val_loss: 4.8622 - val_accuracy: 0.2069\n",
            "Epoch 190/200\n",
            "88/88 [==============================] - 3s 36ms/step - loss: 1.1724 - accuracy: 0.6218 - val_loss: 4.7365 - val_accuracy: 0.2126\n",
            "Epoch 191/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.1978 - accuracy: 0.5931 - val_loss: 4.8284 - val_accuracy: 0.2011\n",
            "Epoch 192/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.1374 - accuracy: 0.6032 - val_loss: 4.8250 - val_accuracy: 0.2299\n",
            "Epoch 193/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.2407 - accuracy: 0.5774 - val_loss: 4.8433 - val_accuracy: 0.2011\n",
            "Epoch 194/200\n",
            "88/88 [==============================] - 4s 44ms/step - loss: 1.2825 - accuracy: 0.5516 - val_loss: 4.5255 - val_accuracy: 0.2471\n",
            "Epoch 195/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 1.0939 - accuracy: 0.6160 - val_loss: 4.8037 - val_accuracy: 0.2241\n",
            "Epoch 196/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.0815 - accuracy: 0.6361 - val_loss: 4.8778 - val_accuracy: 0.2184\n",
            "Epoch 197/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.0531 - accuracy: 0.6361 - val_loss: 5.0756 - val_accuracy: 0.2126\n",
            "Epoch 198/200\n",
            "88/88 [==============================] - 4s 42ms/step - loss: 1.0543 - accuracy: 0.6433 - val_loss: 4.9565 - val_accuracy: 0.1954\n",
            "Epoch 199/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 1.0225 - accuracy: 0.6576 - val_loss: 5.0339 - val_accuracy: 0.1897\n",
            "Epoch 200/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.0607 - accuracy: 0.6447 - val_loss: 4.9620 - val_accuracy: 0.2299\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 4.9620 - accuracy: 0.2299\n",
            "Epoch 1/200\n",
            "88/88 [==============================] - 5s 41ms/step - loss: 3.5787 - accuracy: 0.0946 - val_loss: 3.4857 - val_accuracy: 0.1092\n",
            "Epoch 2/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 3.5312 - accuracy: 0.0917 - val_loss: 3.4827 - val_accuracy: 0.1092\n",
            "Epoch 3/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.5237 - accuracy: 0.1074 - val_loss: 3.4626 - val_accuracy: 0.1092\n",
            "Epoch 4/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 3.5085 - accuracy: 0.1032 - val_loss: 3.4701 - val_accuracy: 0.1092\n",
            "Epoch 5/200\n",
            "88/88 [==============================] - 3s 36ms/step - loss: 3.4947 - accuracy: 0.1074 - val_loss: 3.4702 - val_accuracy: 0.0632\n",
            "Epoch 6/200\n",
            "88/88 [==============================] - 4s 42ms/step - loss: 3.4973 - accuracy: 0.1003 - val_loss: 3.4616 - val_accuracy: 0.1092\n",
            "Epoch 7/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4973 - accuracy: 0.1017 - val_loss: 3.4592 - val_accuracy: 0.1092\n",
            "Epoch 8/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4944 - accuracy: 0.1089 - val_loss: 3.4618 - val_accuracy: 0.1092\n",
            "Epoch 9/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4984 - accuracy: 0.1060 - val_loss: 3.4630 - val_accuracy: 0.1092\n",
            "Epoch 10/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 3.4931 - accuracy: 0.1060 - val_loss: 3.4607 - val_accuracy: 0.1092\n",
            "Epoch 11/200\n",
            "88/88 [==============================] - 3s 35ms/step - loss: 3.4856 - accuracy: 0.1074 - val_loss: 3.4630 - val_accuracy: 0.1092\n",
            "Epoch 12/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4893 - accuracy: 0.1017 - val_loss: 3.4581 - val_accuracy: 0.1092\n",
            "Epoch 13/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4802 - accuracy: 0.1060 - val_loss: 3.4624 - val_accuracy: 0.1092\n",
            "Epoch 14/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 3.4911 - accuracy: 0.1032 - val_loss: 3.4565 - val_accuracy: 0.1092\n",
            "Epoch 15/200\n",
            "88/88 [==============================] - 4s 45ms/step - loss: 3.4897 - accuracy: 0.1017 - val_loss: 3.4586 - val_accuracy: 0.1092\n",
            "Epoch 16/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4926 - accuracy: 0.1046 - val_loss: 3.4576 - val_accuracy: 0.1092\n",
            "Epoch 17/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 3.4844 - accuracy: 0.1060 - val_loss: 3.4622 - val_accuracy: 0.1092\n",
            "Epoch 18/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4790 - accuracy: 0.1074 - val_loss: 3.4587 - val_accuracy: 0.1092\n",
            "Epoch 19/200\n",
            "88/88 [==============================] - 4s 40ms/step - loss: 3.4815 - accuracy: 0.1046 - val_loss: 3.4601 - val_accuracy: 0.1092\n",
            "Epoch 20/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 3.4830 - accuracy: 0.1074 - val_loss: 3.4589 - val_accuracy: 0.1092\n",
            "Epoch 21/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4881 - accuracy: 0.1074 - val_loss: 3.4590 - val_accuracy: 0.1092\n",
            "Epoch 22/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 3.4814 - accuracy: 0.1074 - val_loss: 3.4569 - val_accuracy: 0.1092\n",
            "Epoch 23/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 3.4800 - accuracy: 0.1074 - val_loss: 3.4567 - val_accuracy: 0.1092\n",
            "Epoch 24/200\n",
            "88/88 [==============================] - 4s 42ms/step - loss: 3.4812 - accuracy: 0.1074 - val_loss: 3.4573 - val_accuracy: 0.1092\n",
            "Epoch 25/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4768 - accuracy: 0.1074 - val_loss: 3.4576 - val_accuracy: 0.1092\n",
            "Epoch 26/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 3.4793 - accuracy: 0.1089 - val_loss: 3.4576 - val_accuracy: 0.1092\n",
            "Epoch 27/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4837 - accuracy: 0.1074 - val_loss: 3.4562 - val_accuracy: 0.1092\n",
            "Epoch 28/200\n",
            "88/88 [==============================] - 4s 44ms/step - loss: 3.4853 - accuracy: 0.1074 - val_loss: 3.4543 - val_accuracy: 0.1092\n",
            "Epoch 29/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4754 - accuracy: 0.1074 - val_loss: 3.4577 - val_accuracy: 0.1092\n",
            "Epoch 30/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4746 - accuracy: 0.1074 - val_loss: 3.4580 - val_accuracy: 0.1092\n",
            "Epoch 31/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4825 - accuracy: 0.1074 - val_loss: 3.4570 - val_accuracy: 0.1092\n",
            "Epoch 32/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 3.4783 - accuracy: 0.1074 - val_loss: 3.4566 - val_accuracy: 0.1092\n",
            "Epoch 33/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 3.4795 - accuracy: 0.1032 - val_loss: 3.4558 - val_accuracy: 0.1092\n",
            "Epoch 34/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4814 - accuracy: 0.1032 - val_loss: 3.4569 - val_accuracy: 0.1092\n",
            "Epoch 35/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4786 - accuracy: 0.1074 - val_loss: 3.4576 - val_accuracy: 0.1092\n",
            "Epoch 36/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.4781 - accuracy: 0.1074 - val_loss: 3.4552 - val_accuracy: 0.1092\n",
            "Epoch 37/200\n",
            "88/88 [==============================] - 4s 45ms/step - loss: 3.4755 - accuracy: 0.1074 - val_loss: 3.4566 - val_accuracy: 0.1092\n",
            "Epoch 38/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 3.4754 - accuracy: 0.1060 - val_loss: 3.4547 - val_accuracy: 0.1092\n",
            "Epoch 39/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4738 - accuracy: 0.1074 - val_loss: 3.4564 - val_accuracy: 0.1092\n",
            "Epoch 40/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4840 - accuracy: 0.1074 - val_loss: 3.4575 - val_accuracy: 0.1092\n",
            "Epoch 41/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 3.4777 - accuracy: 0.1074 - val_loss: 3.4560 - val_accuracy: 0.1092\n",
            "Epoch 42/200\n",
            "88/88 [==============================] - 4s 40ms/step - loss: 3.4807 - accuracy: 0.1074 - val_loss: 3.4550 - val_accuracy: 0.1092\n",
            "Epoch 43/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4756 - accuracy: 0.1074 - val_loss: 3.4541 - val_accuracy: 0.1092\n",
            "Epoch 44/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.4738 - accuracy: 0.1074 - val_loss: 3.4545 - val_accuracy: 0.1092\n",
            "Epoch 45/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4787 - accuracy: 0.1074 - val_loss: 3.4552 - val_accuracy: 0.1092\n",
            "Epoch 46/200\n",
            "88/88 [==============================] - 4s 41ms/step - loss: 3.4743 - accuracy: 0.1074 - val_loss: 3.4559 - val_accuracy: 0.1092\n",
            "Epoch 47/200\n",
            "88/88 [==============================] - 3s 36ms/step - loss: 3.4747 - accuracy: 0.1074 - val_loss: 3.4525 - val_accuracy: 0.1092\n",
            "Epoch 48/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 3.4741 - accuracy: 0.1074 - val_loss: 3.4495 - val_accuracy: 0.1092\n",
            "Epoch 49/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.4624 - accuracy: 0.1089 - val_loss: 3.4124 - val_accuracy: 0.0977\n",
            "Epoch 50/200\n",
            "88/88 [==============================] - 3s 36ms/step - loss: 3.3998 - accuracy: 0.1003 - val_loss: 3.3777 - val_accuracy: 0.0977\n",
            "Epoch 51/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 3.3754 - accuracy: 0.1089 - val_loss: 3.3690 - val_accuracy: 0.0747\n",
            "Epoch 52/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.3781 - accuracy: 0.1089 - val_loss: 3.3189 - val_accuracy: 0.1034\n",
            "Epoch 53/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.3199 - accuracy: 0.0974 - val_loss: 3.4076 - val_accuracy: 0.0920\n",
            "Epoch 54/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 3.3091 - accuracy: 0.1160 - val_loss: 3.2551 - val_accuracy: 0.1264\n",
            "Epoch 55/200\n",
            "88/88 [==============================] - 4s 42ms/step - loss: 3.2912 - accuracy: 0.1032 - val_loss: 3.2779 - val_accuracy: 0.1034\n",
            "Epoch 56/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 3.2140 - accuracy: 0.1160 - val_loss: 3.1860 - val_accuracy: 0.1092\n",
            "Epoch 57/200\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 3.1815 - accuracy: 0.1203 - val_loss: 3.1950 - val_accuracy: 0.1322\n",
            "Epoch 58/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 3.1286 - accuracy: 0.1189 - val_loss: 3.1929 - val_accuracy: 0.1092\n",
            "Epoch 59/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 3.1316 - accuracy: 0.1117 - val_loss: 3.2489 - val_accuracy: 0.1149\n",
            "Epoch 60/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 3.0226 - accuracy: 0.1347 - val_loss: 3.1686 - val_accuracy: 0.0977\n",
            "Epoch 61/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.0688 - accuracy: 0.1246 - val_loss: 3.1560 - val_accuracy: 0.1034\n",
            "Epoch 62/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 2.9642 - accuracy: 0.1404 - val_loss: 3.1208 - val_accuracy: 0.1264\n",
            "Epoch 63/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 2.9159 - accuracy: 0.1418 - val_loss: 3.0369 - val_accuracy: 0.1322\n",
            "Epoch 64/200\n",
            "88/88 [==============================] - 4s 44ms/step - loss: 2.8794 - accuracy: 0.1447 - val_loss: 3.0484 - val_accuracy: 0.1149\n",
            "Epoch 65/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 2.8324 - accuracy: 0.1605 - val_loss: 3.1327 - val_accuracy: 0.1609\n",
            "Epoch 66/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 2.7839 - accuracy: 0.1819 - val_loss: 3.1819 - val_accuracy: 0.1437\n",
            "Epoch 67/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 2.7903 - accuracy: 0.1834 - val_loss: 3.1425 - val_accuracy: 0.0977\n",
            "Epoch 68/200\n",
            "88/88 [==============================] - 3s 40ms/step - loss: 2.7230 - accuracy: 0.1805 - val_loss: 3.8426 - val_accuracy: 0.1264\n",
            "Epoch 69/200\n",
            "88/88 [==============================] - 4s 41ms/step - loss: 2.8019 - accuracy: 0.1533 - val_loss: 3.0997 - val_accuracy: 0.1264\n",
            "Epoch 70/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 2.6853 - accuracy: 0.1848 - val_loss: 3.0854 - val_accuracy: 0.1264\n",
            "Epoch 71/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 2.6342 - accuracy: 0.1963 - val_loss: 3.1980 - val_accuracy: 0.1724\n",
            "Epoch 72/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 2.6021 - accuracy: 0.1948 - val_loss: 3.1030 - val_accuracy: 0.1264\n",
            "Epoch 73/200\n",
            "88/88 [==============================] - 4s 40ms/step - loss: 2.5565 - accuracy: 0.2221 - val_loss: 3.1557 - val_accuracy: 0.1667\n",
            "Epoch 74/200\n",
            "88/88 [==============================] - 3s 35ms/step - loss: 2.5604 - accuracy: 0.2135 - val_loss: 3.0637 - val_accuracy: 0.1437\n",
            "Epoch 75/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 2.4893 - accuracy: 0.2321 - val_loss: 3.2626 - val_accuracy: 0.1207\n",
            "Epoch 76/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 2.4935 - accuracy: 0.2436 - val_loss: 3.5978 - val_accuracy: 0.1379\n",
            "Epoch 77/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 2.4927 - accuracy: 0.2378 - val_loss: 3.6485 - val_accuracy: 0.1322\n",
            "Epoch 78/200\n",
            "88/88 [==============================] - 4s 43ms/step - loss: 2.4759 - accuracy: 0.2479 - val_loss: 3.2564 - val_accuracy: 0.1379\n",
            "Epoch 79/200\n",
            "88/88 [==============================] - 3s 36ms/step - loss: 2.4154 - accuracy: 0.2407 - val_loss: 3.2015 - val_accuracy: 0.1494\n",
            "Epoch 80/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 2.4252 - accuracy: 0.2464 - val_loss: 3.2896 - val_accuracy: 0.1322\n",
            "Epoch 81/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 2.4060 - accuracy: 0.2350 - val_loss: 3.3021 - val_accuracy: 0.1437\n",
            "Epoch 82/200\n",
            "88/88 [==============================] - 4s 41ms/step - loss: 2.3936 - accuracy: 0.2450 - val_loss: 3.5532 - val_accuracy: 0.1552\n",
            "Epoch 83/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 2.3918 - accuracy: 0.2507 - val_loss: 3.2884 - val_accuracy: 0.1379\n",
            "Epoch 84/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 2.2811 - accuracy: 0.2837 - val_loss: 3.4938 - val_accuracy: 0.1724\n",
            "Epoch 85/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 2.2870 - accuracy: 0.2507 - val_loss: 3.4686 - val_accuracy: 0.1437\n",
            "Epoch 86/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 2.2961 - accuracy: 0.2564 - val_loss: 3.3644 - val_accuracy: 0.1322\n",
            "Epoch 87/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 2.2416 - accuracy: 0.2994 - val_loss: 3.8395 - val_accuracy: 0.1667\n",
            "Epoch 88/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 2.2637 - accuracy: 0.2665 - val_loss: 3.6048 - val_accuracy: 0.1264\n",
            "Epoch 89/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 2.4682 - accuracy: 0.2521 - val_loss: 3.3462 - val_accuracy: 0.1379\n",
            "Epoch 90/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 2.2350 - accuracy: 0.2751 - val_loss: 3.4965 - val_accuracy: 0.1552\n",
            "Epoch 91/200\n",
            "88/88 [==============================] - 4s 44ms/step - loss: 2.2107 - accuracy: 0.2822 - val_loss: 3.5424 - val_accuracy: 0.1494\n",
            "Epoch 92/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 2.1892 - accuracy: 0.3023 - val_loss: 3.5255 - val_accuracy: 0.1437\n",
            "Epoch 93/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 2.1267 - accuracy: 0.3123 - val_loss: 3.6301 - val_accuracy: 0.1437\n",
            "Epoch 94/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 3.0376 - accuracy: 0.1777 - val_loss: 3.3369 - val_accuracy: 0.1034\n",
            "Epoch 95/200\n",
            "88/88 [==============================] - 4s 40ms/step - loss: 3.1678 - accuracy: 0.1461 - val_loss: 3.2303 - val_accuracy: 0.1322\n",
            "Epoch 96/200\n",
            "88/88 [==============================] - 4s 42ms/step - loss: 2.8088 - accuracy: 0.1791 - val_loss: 3.1278 - val_accuracy: 0.1724\n",
            "Epoch 97/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 2.6017 - accuracy: 0.2550 - val_loss: 3.2909 - val_accuracy: 0.1322\n",
            "Epoch 98/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 2.5287 - accuracy: 0.2464 - val_loss: 3.3112 - val_accuracy: 0.1609\n",
            "Epoch 99/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 2.4325 - accuracy: 0.2779 - val_loss: 3.4784 - val_accuracy: 0.1264\n",
            "Epoch 100/200\n",
            "88/88 [==============================] - 4s 42ms/step - loss: 2.4450 - accuracy: 0.2837 - val_loss: 3.4395 - val_accuracy: 0.1437\n",
            "Epoch 101/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 2.4031 - accuracy: 0.2607 - val_loss: 3.3539 - val_accuracy: 0.1494\n",
            "Epoch 102/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 2.3092 - accuracy: 0.3066 - val_loss: 3.3353 - val_accuracy: 0.1667\n",
            "Epoch 103/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 2.2365 - accuracy: 0.3309 - val_loss: 3.4962 - val_accuracy: 0.1494\n",
            "Epoch 104/200\n",
            "88/88 [==============================] - 4s 41ms/step - loss: 2.1921 - accuracy: 0.3295 - val_loss: 3.4766 - val_accuracy: 0.1494\n",
            "Epoch 105/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 2.2788 - accuracy: 0.3281 - val_loss: 3.5072 - val_accuracy: 0.1724\n",
            "Epoch 106/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 2.1852 - accuracy: 0.3195 - val_loss: 3.5509 - val_accuracy: 0.1609\n",
            "Epoch 107/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 2.0990 - accuracy: 0.3524 - val_loss: 3.5910 - val_accuracy: 0.1609\n",
            "Epoch 108/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 2.1182 - accuracy: 0.3582 - val_loss: 3.5943 - val_accuracy: 0.1552\n",
            "Epoch 109/200\n",
            "88/88 [==============================] - 4s 42ms/step - loss: 2.1134 - accuracy: 0.3453 - val_loss: 3.6803 - val_accuracy: 0.1782\n",
            "Epoch 110/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 2.0513 - accuracy: 0.3711 - val_loss: 3.6577 - val_accuracy: 0.1897\n",
            "Epoch 111/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 2.1517 - accuracy: 0.3252 - val_loss: 3.5289 - val_accuracy: 0.1667\n",
            "Epoch 112/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 2.4592 - accuracy: 0.2693 - val_loss: 3.1690 - val_accuracy: 0.1782\n",
            "Epoch 113/200\n",
            "88/88 [==============================] - 4s 45ms/step - loss: 2.0645 - accuracy: 0.3639 - val_loss: 3.3310 - val_accuracy: 0.1552\n",
            "Epoch 114/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 2.1034 - accuracy: 0.3252 - val_loss: 3.4744 - val_accuracy: 0.1609\n",
            "Epoch 115/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 2.0001 - accuracy: 0.3610 - val_loss: 3.4630 - val_accuracy: 0.1897\n",
            "Epoch 116/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.9268 - accuracy: 0.3997 - val_loss: 3.6254 - val_accuracy: 0.1782\n",
            "Epoch 117/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 1.9475 - accuracy: 0.3940 - val_loss: 3.6121 - val_accuracy: 0.1494\n",
            "Epoch 118/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 1.9168 - accuracy: 0.3840 - val_loss: 3.6126 - val_accuracy: 0.1552\n",
            "Epoch 119/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.8149 - accuracy: 0.4083 - val_loss: 3.7057 - val_accuracy: 0.1609\n",
            "Epoch 120/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 1.8158 - accuracy: 0.4011 - val_loss: 3.6706 - val_accuracy: 0.1552\n",
            "Epoch 121/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 1.9630 - accuracy: 0.3782 - val_loss: 3.6537 - val_accuracy: 0.1552\n",
            "Epoch 122/200\n",
            "88/88 [==============================] - 4s 42ms/step - loss: 1.8923 - accuracy: 0.3897 - val_loss: 3.6918 - val_accuracy: 0.1667\n",
            "Epoch 123/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.9021 - accuracy: 0.3840 - val_loss: 4.0128 - val_accuracy: 0.1609\n",
            "Epoch 124/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 2.1805 - accuracy: 0.3238 - val_loss: 3.5429 - val_accuracy: 0.1724\n",
            "Epoch 125/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.8511 - accuracy: 0.4054 - val_loss: 3.5516 - val_accuracy: 0.1782\n",
            "Epoch 126/200\n",
            "88/88 [==============================] - 4s 45ms/step - loss: 1.8461 - accuracy: 0.3854 - val_loss: 3.5993 - val_accuracy: 0.1724\n",
            "Epoch 127/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 1.7355 - accuracy: 0.4298 - val_loss: 3.7623 - val_accuracy: 0.1494\n",
            "Epoch 128/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.7195 - accuracy: 0.4384 - val_loss: 3.7879 - val_accuracy: 0.1609\n",
            "Epoch 129/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.9421 - accuracy: 0.3868 - val_loss: 3.8036 - val_accuracy: 0.1839\n",
            "Epoch 130/200\n",
            "88/88 [==============================] - 3s 37ms/step - loss: 1.7595 - accuracy: 0.4198 - val_loss: 3.8092 - val_accuracy: 0.1667\n",
            "Epoch 131/200\n",
            "88/88 [==============================] - 4s 45ms/step - loss: 1.7432 - accuracy: 0.4255 - val_loss: 3.8429 - val_accuracy: 0.1667\n",
            "Epoch 132/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.6562 - accuracy: 0.4556 - val_loss: 3.8602 - val_accuracy: 0.1322\n",
            "Epoch 133/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.7972 - accuracy: 0.4241 - val_loss: 3.8350 - val_accuracy: 0.1437\n",
            "Epoch 134/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.7929 - accuracy: 0.4241 - val_loss: 3.7016 - val_accuracy: 0.2126\n",
            "Epoch 135/200\n",
            "88/88 [==============================] - 4s 44ms/step - loss: 1.7350 - accuracy: 0.4527 - val_loss: 3.7992 - val_accuracy: 0.1897\n",
            "Epoch 136/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.6712 - accuracy: 0.4441 - val_loss: 3.8951 - val_accuracy: 0.1552\n",
            "Epoch 137/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.5602 - accuracy: 0.4914 - val_loss: 3.9829 - val_accuracy: 0.1667\n",
            "Epoch 138/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.6076 - accuracy: 0.4699 - val_loss: 4.3610 - val_accuracy: 0.1322\n",
            "Epoch 139/200\n",
            "88/88 [==============================] - 4s 42ms/step - loss: 2.2191 - accuracy: 0.3352 - val_loss: 3.7580 - val_accuracy: 0.2069\n",
            "Epoch 140/200\n",
            "88/88 [==============================] - 3s 36ms/step - loss: 1.8970 - accuracy: 0.4040 - val_loss: 3.8001 - val_accuracy: 0.1494\n",
            "Epoch 141/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 1.6893 - accuracy: 0.4613 - val_loss: 3.8346 - val_accuracy: 0.1782\n",
            "Epoch 142/200\n",
            "88/88 [==============================] - 3s 35ms/step - loss: 1.6183 - accuracy: 0.4842 - val_loss: 3.9220 - val_accuracy: 0.1667\n",
            "Epoch 143/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 1.5331 - accuracy: 0.4986 - val_loss: 3.9088 - val_accuracy: 0.1782\n",
            "Epoch 144/200\n",
            "88/88 [==============================] - 3s 38ms/step - loss: 1.5913 - accuracy: 0.4857 - val_loss: 3.9017 - val_accuracy: 0.1667\n",
            "Epoch 145/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 1.5931 - accuracy: 0.4713 - val_loss: 4.0420 - val_accuracy: 0.1379\n",
            "Epoch 146/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.5997 - accuracy: 0.4771 - val_loss: 4.0309 - val_accuracy: 0.1609\n",
            "Epoch 147/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.5624 - accuracy: 0.4928 - val_loss: 4.0785 - val_accuracy: 0.1609\n",
            "Epoch 148/200\n",
            "88/88 [==============================] - 4s 43ms/step - loss: 1.5576 - accuracy: 0.4842 - val_loss: 4.1126 - val_accuracy: 0.1839\n",
            "Epoch 149/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.5111 - accuracy: 0.5043 - val_loss: 4.0030 - val_accuracy: 0.1609\n",
            "Epoch 150/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.4853 - accuracy: 0.5172 - val_loss: 4.0537 - val_accuracy: 0.1609\n",
            "Epoch 151/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.5082 - accuracy: 0.4943 - val_loss: 4.0665 - val_accuracy: 0.1954\n",
            "Epoch 152/200\n",
            "88/88 [==============================] - 4s 41ms/step - loss: 1.5152 - accuracy: 0.4900 - val_loss: 4.0952 - val_accuracy: 0.1724\n",
            "Epoch 153/200\n",
            "88/88 [==============================] - 4s 40ms/step - loss: 1.5299 - accuracy: 0.5029 - val_loss: 4.0314 - val_accuracy: 0.2126\n",
            "Epoch 154/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 1.5148 - accuracy: 0.4928 - val_loss: 3.8823 - val_accuracy: 0.1897\n",
            "Epoch 155/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.5140 - accuracy: 0.5029 - val_loss: 3.9112 - val_accuracy: 0.1954\n",
            "Epoch 156/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.5011 - accuracy: 0.4957 - val_loss: 4.0088 - val_accuracy: 0.1897\n",
            "Epoch 157/200\n",
            "88/88 [==============================] - 4s 42ms/step - loss: 1.5631 - accuracy: 0.4928 - val_loss: 4.0166 - val_accuracy: 0.1782\n",
            "Epoch 158/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 1.4642 - accuracy: 0.5201 - val_loss: 4.1418 - val_accuracy: 0.1609\n",
            "Epoch 159/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.4354 - accuracy: 0.5029 - val_loss: 3.9611 - val_accuracy: 0.2011\n",
            "Epoch 160/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 1.4183 - accuracy: 0.5315 - val_loss: 4.1518 - val_accuracy: 0.1667\n",
            "Epoch 161/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 1.4632 - accuracy: 0.5115 - val_loss: 4.2214 - val_accuracy: 0.1897\n",
            "Epoch 162/200\n",
            "88/88 [==============================] - 4s 45ms/step - loss: 1.4442 - accuracy: 0.5172 - val_loss: 4.0533 - val_accuracy: 0.1954\n",
            "Epoch 163/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.4084 - accuracy: 0.5272 - val_loss: 4.2828 - val_accuracy: 0.1782\n",
            "Epoch 164/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.3962 - accuracy: 0.5401 - val_loss: 4.2259 - val_accuracy: 0.1839\n",
            "Epoch 165/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 1.4567 - accuracy: 0.5330 - val_loss: 4.2388 - val_accuracy: 0.1724\n",
            "Epoch 166/200\n",
            "88/88 [==============================] - 4s 42ms/step - loss: 1.3906 - accuracy: 0.5358 - val_loss: 4.1978 - val_accuracy: 0.1897\n",
            "Epoch 167/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 1.3576 - accuracy: 0.5430 - val_loss: 4.2002 - val_accuracy: 0.1897\n",
            "Epoch 168/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.3524 - accuracy: 0.5315 - val_loss: 4.3306 - val_accuracy: 0.1897\n",
            "Epoch 169/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.3822 - accuracy: 0.5430 - val_loss: 4.2556 - val_accuracy: 0.1782\n",
            "Epoch 170/200\n",
            "88/88 [==============================] - 4s 42ms/step - loss: 1.3301 - accuracy: 0.5616 - val_loss: 4.4168 - val_accuracy: 0.1724\n",
            "Epoch 171/200\n",
            "88/88 [==============================] - 3s 35ms/step - loss: 1.4661 - accuracy: 0.5100 - val_loss: 4.1882 - val_accuracy: 0.1839\n",
            "Epoch 172/200\n",
            "88/88 [==============================] - 3s 33ms/step - loss: 1.4687 - accuracy: 0.5415 - val_loss: 4.3480 - val_accuracy: 0.1782\n",
            "Epoch 173/200\n",
            "88/88 [==============================] - 3s 38ms/step - loss: 1.3605 - accuracy: 0.5559 - val_loss: 4.1009 - val_accuracy: 0.2011\n",
            "Epoch 174/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 1.3723 - accuracy: 0.5501 - val_loss: 4.1949 - val_accuracy: 0.1897\n",
            "Epoch 175/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 1.3460 - accuracy: 0.5487 - val_loss: 4.2972 - val_accuracy: 0.1379\n",
            "Epoch 176/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.2763 - accuracy: 0.5802 - val_loss: 4.4192 - val_accuracy: 0.1667\n",
            "Epoch 177/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.2844 - accuracy: 0.5731 - val_loss: 4.4164 - val_accuracy: 0.1839\n",
            "Epoch 178/200\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 1.2652 - accuracy: 0.5974 - val_loss: 4.3542 - val_accuracy: 0.1667\n",
            "Epoch 179/200\n",
            "88/88 [==============================] - 4s 46ms/step - loss: 1.2169 - accuracy: 0.6032 - val_loss: 4.6471 - val_accuracy: 0.2011\n",
            "Epoch 180/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 1.3027 - accuracy: 0.5745 - val_loss: 4.3866 - val_accuracy: 0.1724\n",
            "Epoch 181/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.2731 - accuracy: 0.5831 - val_loss: 4.5013 - val_accuracy: 0.1839\n",
            "Epoch 182/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.2471 - accuracy: 0.5688 - val_loss: 4.4333 - val_accuracy: 0.2069\n",
            "Epoch 183/200\n",
            "88/88 [==============================] - 4s 44ms/step - loss: 1.2461 - accuracy: 0.5989 - val_loss: 4.5607 - val_accuracy: 0.1839\n",
            "Epoch 184/200\n",
            "88/88 [==============================] - 3s 39ms/step - loss: 1.2176 - accuracy: 0.5759 - val_loss: 4.4650 - val_accuracy: 0.1897\n",
            "Epoch 185/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.2246 - accuracy: 0.5960 - val_loss: 4.4625 - val_accuracy: 0.1839\n",
            "Epoch 186/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.2116 - accuracy: 0.6032 - val_loss: 4.5231 - val_accuracy: 0.2011\n",
            "Epoch 187/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 1.1230 - accuracy: 0.6404 - val_loss: 4.6257 - val_accuracy: 0.1839\n",
            "Epoch 188/200\n",
            "88/88 [==============================] - 4s 45ms/step - loss: 1.2351 - accuracy: 0.5989 - val_loss: 4.7388 - val_accuracy: 0.1609\n",
            "Epoch 189/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.1925 - accuracy: 0.6103 - val_loss: 4.6102 - val_accuracy: 0.1609\n",
            "Epoch 190/200\n",
            "88/88 [==============================] - 3s 34ms/step - loss: 1.2389 - accuracy: 0.6017 - val_loss: 4.5649 - val_accuracy: 0.2011\n",
            "Epoch 191/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.1772 - accuracy: 0.6117 - val_loss: 4.5797 - val_accuracy: 0.1667\n",
            "Epoch 192/200\n",
            "88/88 [==============================] - 4s 42ms/step - loss: 1.2677 - accuracy: 0.5817 - val_loss: 4.5209 - val_accuracy: 0.1897\n",
            "Epoch 193/200\n",
            "88/88 [==============================] - 4s 43ms/step - loss: 1.2207 - accuracy: 0.6060 - val_loss: 4.5302 - val_accuracy: 0.1839\n",
            "Epoch 194/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.1375 - accuracy: 0.6189 - val_loss: 4.6605 - val_accuracy: 0.1609\n",
            "Epoch 195/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.1116 - accuracy: 0.6246 - val_loss: 4.7119 - val_accuracy: 0.1839\n",
            "Epoch 196/200\n",
            "88/88 [==============================] - 3s 35ms/step - loss: 1.0783 - accuracy: 0.6347 - val_loss: 4.7793 - val_accuracy: 0.1897\n",
            "Epoch 197/200\n",
            "88/88 [==============================] - 4s 42ms/step - loss: 1.0999 - accuracy: 0.6261 - val_loss: 4.7527 - val_accuracy: 0.1954\n",
            "Epoch 198/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.1868 - accuracy: 0.6060 - val_loss: 4.7167 - val_accuracy: 0.1897\n",
            "Epoch 199/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.1599 - accuracy: 0.6117 - val_loss: 4.6584 - val_accuracy: 0.1667\n",
            "Epoch 200/200\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 1.1192 - accuracy: 0.6361 - val_loss: 4.5967 - val_accuracy: 0.1954\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 4.5967 - accuracy: 0.1954\n",
            "Cross-validation accuracy: 0.18 +/- 0.04\n"
          ]
        }
      ]
    }
  ]
}